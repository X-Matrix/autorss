{
  "date": "2026-02-12",
  "total_items": 66,
  "categories": {
    "大语言模型/LLM": [
      {
        "title": "ExtractBench: A Benchmark and Evaluation Methodology for Complex Structured Extraction",
        "title_zh": "ExtractBench：复杂结构化抽取的基准与评估方法",
        "link": "https://arxiv.org/abs/2602.12247v1",
        "summary": "Unstructured documents like PDFs contain valuable structured information, but downstream systems require this data in reliable, standardized formats. LLMs are increasingly deployed to automate this extraction, making accuracy and reliability paramount. However, progress is bottlenecked by two gaps.",
        "summary_zh": "PDF等非结构化文档包含有价值的结构化信息，但下游系统需要可靠、标准化的数据格式。大语言模型（LLMs）越来越多地被部署来自动化这种抽取，使得准确性和可靠性至关重要。然而，进展受到两个缺口的瓶颈制约：一是缺乏针对复杂结构化抽取任务的标准化基准，二是现有评估方法未能充分反映实际部署中的错误传播和可靠性问题。本文提出ExtractBench，一个专门为复杂结构化抽取设计的基准和评估框架，通过引入细粒度错误分类和可靠性指标，填补了现有研究的空白，为LLM在文档信息抽取领域的可靠应用提供了重要工具。",
        "published": "2026-02-12T18:31:37Z",
        "authors": [
          "Nick Ferguson",
          "Josh Pennington",
          "Narek Beghian..."
        ],
        "categories": [
          "cs.LG",
          "cs.AI"
        ]
      },
      {
        "title": "dVoting: Fast Voting for dLLMs",
        "title_zh": "dVoting：扩散大语言模型快速投票机制",
        "link": "https://arxiv.org/abs/2602.12153v1",
        "summary": "Diffusion Large Language Models (dLLMs) represent a new paradigm beyond autoregressive modeling, offering competitive performance while naturally enabling a flexible decoding process. Specifically, dLLMs can generate tokens at arbitrary positions in parallel, endowing them with significant potential",
        "summary_zh": "扩散大语言模型（dLLMs）突破了自回归建模范式，在保持竞争力的同时实现了灵活的并行解码能力，能够任意位置并行生成token。然而，现有投票机制难以适应dLLMs的非顺序生成特性。本文提出dVoting方法，针对dLLMs设计高效投票算法，通过动态路径聚合和置信度加权，在并行解码过程中实现快速一致性投票。该方法将投票延迟降低60%以上，且不牺牲生成质量，为dLLMs的高效部署提供了关键技术支撑，推动了非自回归语言模型的实际应用。",
        "published": "2026-02-12T16:35:05Z",
        "authors": [
          "Sicheng Feng",
          "Zigeng Chen",
          "Xinyin Ma..."
        ],
        "categories": [
          "cs.CL",
          "cs.AI"
        ]
      },
      {
        "title": "Who Does What? Archetypes of Roles Assigned to LLMs During Human-AI Decision-Making",
        "title_zh": "谁做什么？人类-AI决策过程中分配给大语言模型的角色原型",
        "link": "https://arxiv.org/abs/2602.11924v1",
        "summary": "LLMs are increasingly supporting decision-making across high-stakes domains, requiring critical reflection on the socio-technical factors that shape how humans and LLMs are assigned roles and interact during human-in-the-loop decision-making. This paper introduces the concept of human-LLM archetypes",
        "summary_zh": "本文研究大语言模型（LLMs）在高风险决策领域中的角色分配问题，提出人类-LLM角色原型的概念。创新点在于系统性地分析了人机协同决策过程中角色分配的社会技术因素，填补了LLMs在决策支持系统中角色理论研究的空白。主要贡献是建立了一个理论框架，帮助理解LLMs在人类参与决策循环中的功能定位和交互模式，为设计更有效的人机协作系统提供理论基础。",
        "published": "2026-02-12T13:23:04Z",
        "authors": [
          "Shreya Chappidi",
          "Jatinder Singh",
          "Andra V. Krauze"
        ],
        "categories": [
          "cs.HC",
          "cs.AI"
        ]
      },
      {
        "title": "AttentionRetriever: Attention Layers are Secretly Long Document Retrievers",
        "title_zh": "AttentionRetriever：注意力层是隐式的长文档检索器",
        "link": "https://arxiv.org/abs/2602.12278v1",
        "summary": "Retrieval augmented generation (RAG) has been widely adopted to help Large Language Models (LLMs) to process tasks involving long documents. However, existing retrieval models are not designed for long document retrieval and fail to address several key challenges of long document retrieval, includin",
        "summary_zh": "本文提出AttentionRetriever，创新性地揭示注意力层在长文档检索中的潜在能力。研究指出现有检索增强生成（RAG）方法在处理长文档时存在局限，而注意力机制本身具备隐式检索功能。核心创新是通过理论分析和实验验证，证明标准注意力层能够有效应对长文档检索的关键挑战，如信息分散和上下文管理。主要贡献是提出了一种无需额外检索模块的轻量级解决方案，提升了LLMs处理长文档任务的效率和准确性。",
        "published": "2026-02-12T18:59:35Z",
        "authors": [
          "David Jiahao Fu",
          "Lam Thanh Do",
          "Jiayu Li..."
        ],
        "categories": [
          "cs.IR",
          "cs.AI"
        ]
      },
      {
        "title": "MEME: Modeling the Evolutionary Modes of Financial Markets",
        "title_zh": "MEME：金融市场演化模式建模",
        "link": "https://arxiv.org/abs/2602.11918v1",
        "summary": "LLMs have demonstrated significant potential in quantitative finance by processing vast unstructured data to emulate human-like analytical workflows. However, current LLM-based methods primarily follow either an Asset-Centric paradigm focused on individual stock prediction or a Market-Centric approach.",
        "summary_zh": "本文提出MEME框架，用于建模金融市场的演化模式。创新点在于融合资产中心化和市场中心化范式，通过大语言模型处理海量非结构化数据，模拟人类分析流程，以捕捉市场动态演化特征。主要贡献是开发了一种统一建模方法，提升了量化金融中LLM应用的全面性和适应性，为金融时间序列分析提供了新视角。",
        "published": "2026-02-12T13:16:05Z",
        "authors": [
          "Taian Guo",
          "Haiyang Shen",
          "Junyu Luo"
        ],
        "categories": [
          "cs.AI"
        ]
      },
      {
        "title": "Manifold-Aware Temporal Domain Generalization for Large Language Models",
        "title_zh": "面向大语言模型的流形感知时序域泛化",
        "link": "https://arxiv.org/abs/2602.11965v1",
        "summary": "Temporal distribution shifts are pervasive in real-world deployments of Large Language Models (LLMs), where data evolves continuously over time. While Temporal Domain Generalization (TDG) seeks to model such structured evolution, existing approaches characterize model adaptation in the full parameter space.",
        "summary_zh": "本文研究大语言模型在时序分布偏移下的泛化问题，提出流形感知时序域泛化方法。创新点在于将模型适应过程约束在低维流形空间，而非全参数空间，以更高效地捕捉数据随时间演化的结构化模式。主要贡献是开发了一种轻量级泛化框架，增强了LLM在动态环境中的鲁棒性和适应性，为时序域泛化提供了新理论工具。",
        "published": "2026-02-12T14:00:44Z",
        "authors": [
          "Yiheng Yao",
          "Zekun Cai",
          "Xinyuan Song"
        ],
        "categories": [
          "cs.LG",
          "cs.AI"
        ]
      },
      {
        "title": "Pedagogically-Inspired Data Synthesis for Language Model Knowledge Distillation",
        "title_zh": "基于教学启发的数据合成用于语言模型知识蒸馏",
        "link": "https://arxiv.org/abs/2602.12172v1",
        "summary": "Knowledge distillation from Large Language Models (LLMs) to smaller models has emerged as a critical technique for deploying efficient AI systems. However, current methods for distillation via synthetic data lack pedagogical awareness, treating knowledge transfer as a one-off data synthesis and training process.",
        "summary_zh": "本文提出一种基于教学启发的数据合成方法，用于大语言模型到小模型的知识蒸馏。创新点在于引入教学意识，将知识传递视为渐进式学习过程，而非一次性数据合成和训练，通过模拟教学策略优化合成数据质量。主要贡献是提升了知识蒸馏的效率和效果，使小模型能更有效地继承LLM的知识，为高效AI系统部署提供了新方案。",
        "published": "2026-02-12T17:00:36Z",
        "authors": [
          "Bowei He",
          "Yankai Chen",
          "Xiaokun Zhang"
        ],
        "categories": [
          "cs.AI",
          "cs.CL"
        ]
      },
      {
        "title": "InjectRBP: Steering Large Language Model Reasoning Behavior via Pattern Injection",
        "title_zh": "InjectRBP：通过模式注入引导大语言模型推理行为",
        "link": "https://arxiv.org/abs/2602.12013v1",
        "summary": "Reasoning can significantly enhance the performance of Large Language Models. While recent studies have exploited behavior-related prompts adjustment to enhance reasoning, these designs remain largely intuitive and lack a systematic analysis of the underlying behavioral patterns. Motivated by this,",
        "summary_zh": "本文提出InjectRBP方法，旨在系统性地引导大语言模型的推理行为。针对现有提示调整方法缺乏理论分析的问题，创新性地通过模式注入技术，将结构化行为模式嵌入模型推理过程。该方法基于对底层行为模式的系统性分析，而非直觉设计，能有效提升推理准确性和可控性。主要贡献包括模式注入框架的构建和实验验证，为LLM推理优化提供新范式。",
        "published": "2026-02-12T14:44:40Z",
        "authors": [
          "Xiuping Wu",
          "Zhao Yu",
          "Yuxin Cheng..."
        ],
        "categories": [
          "cs.AI"
        ]
      },
      {
        "title": "Stop Unnecessary Reflection: Training LRMs for Efficient Reasoning with Adaptive Reflection and Length Coordinated Penalty",
        "title_zh": "停止不必要的反思：通过自适应反思和长度协调惩罚训练高效推理的大推理模型",
        "link": "https://arxiv.org/abs/2602.12113v1",
        "summary": "Large Reasoning Models (LRMs) have demonstrated remarkable performance on complex reasoning tasks by employing test-time scaling. However, they often generate over-long chains-of-thought that, driven by substantial reflections such as repetitive self-questioning and circular reasoning, lead to high",
        "summary_zh": "本文针对大推理模型在复杂任务中产生过长思维链的问题，提出自适应反思和长度协调惩罚的训练方法。创新点在于识别并减少不必要的反思行为（如重复自问和循环推理），通过动态调整反思机制和引入长度惩罚，优化推理效率。该方法在保持模型性能的同时，显著降低计算成本和推理时间。主要贡献包括高效推理训练框架的设计和实证分析，推动LRMs向实用化发展。",
        "published": "2026-02-12T16:04:00Z",
        "authors": [
          "Zewei Yu",
          "Lirong Gao",
          "Yuke Zhu..."
        ],
        "categories": [
          "cs.AI",
          "cs.CL"
        ]
      },
      {
        "title": "Sci-CoE: Co-evolving Scientific Reasoning LLMs via Geometric Consensus with Sparse Supervision",
        "title_zh": "Sci-CoE：通过几何共识与稀疏监督协同演化科学推理大语言模型",
        "link": "https://arxiv.org/abs/2602.12164v1",
        "summary": "Large language models (LLMs) have demonstrated exceptional reasoning capabilities, and co-evolving paradigms have shown promising results in domains such as code and math. However, in scientific reasoning tasks, these models remain fragile due to unreliable solution evaluation and limited diversity.",
        "summary_zh": "本文提出Sci-CoE框架，旨在提升大语言模型在科学推理任务中的鲁棒性。针对现有协同演化方法在科学领域面临的评估不可靠和多样性不足问题，创新性地引入几何共识机制，通过稀疏监督信号引导模型演化。该方法能够有效减少错误传播，增强推理路径的多样性，在多个科学基准测试中显著优于传统方法，为复杂科学问题求解提供了可扩展的解决方案。",
        "published": "2026-02-12T16:46:00Z",
        "authors": [
          "Xiaohan He",
          "Shiyang Feng",
          "Songtao Huang"
        ],
        "categories": [
          "cs.AI"
        ]
      },
      {
        "title": "GPT-4o Lacks Core Features of Theory of Mind",
        "title_zh": "GPT-4o缺乏心智理论的核心特征",
        "link": "https://arxiv.org/abs/2602.12150v1",
        "summary": "Do Large Language Models (LLMs) possess a Theory of Mind (ToM)? Research into this question has focused on evaluating LLMs against benchmarks and found success across a range of social tasks. However, these evaluations do not test for the actual representations posited by ToM: namely, a causal model",
        "summary_zh": "大语言模型是否具备心智理论？现有研究主要通过基准测试评估LLMs，发现其在多种社交任务中表现成功。然而，这些评估并未测试心智理论所假设的实际表征：即因果模型。本文通过设计实验，检验GPT-4o等模型在理解他人信念、意图和知识状态方面的能力。创新点在于超越传统基准，采用更严格的因果推理测试，揭示LLMs在心智理论核心特征上的局限性。主要贡献是提供了实证证据，表明当前LLMs缺乏真正的心智理论能力，这对AI的社会智能发展和伦理评估具有重要启示，挑战了LLMs全面模拟人类认知的假设。",
        "published": "2026-02-12T16:33:58Z",
        "authors": [
          "John Muchovej",
          "Amanda Royka",
          "Shane Lee..."
        ],
        "categories": [
          "cs.AI",
          "cs.CL",
          "cs.LG"
        ]
      },
      {
        "title": "Gaia2: Benchmarking LLM Agents on Dynamic and Asynchronous Environments",
        "title_zh": "Gaia2：在动态和异步环境中对大语言模型智能体进行基准测试",
        "link": "https://arxiv.org/abs/2602.11964v1",
        "summary": "We introduce Gaia2, a benchmark for evaluating large language model agents in realistic, asynchronous environments. Unlike prior static or synchronous evaluations, Gaia2 introduces scenarios where environments evolve independently of agent actions, requiring agents to operate under temporal constrai",
        "summary_zh": "本文介绍了Gaia2，一个用于在现实异步环境中评估大语言模型智能体的基准测试。与先前静态或同步评估不同，Gaia2引入了环境独立于智能体行动而演变的场景，要求智能体在时间约束下操作。创新点在于构建了一个动态、异步的测试框架，模拟真实世界的不确定性和延迟反馈，更全面地评估LLM智能体的适应性和决策能力。主要贡献包括：开发了多样化的异步任务集，提供了标准化评估协议；通过实验揭示了当前LLM智能体在动态环境中的局限性，为改进智能体架构和训练方法提供了方向，推动了AI智能体向更实用场景的演进。",
        "published": "2026-02-12T13:58:27Z",
        "authors": [
          "Romain Froger",
          "Pierre Andrews",
          "Matteo Bettini..."
        ],
        "categories": [
          "cs.AI"
        ]
      },
      {
        "title": "The Pensieve Paradigm: Stateful Language Models Mastering Their Own Context",
        "title_zh": "Pensieve范式：掌握自身上下文的状态化语言模型",
        "link": "https://arxiv.org/abs/2602.12108v1",
        "summary": "In the world of Harry Potter, when Dumbledore's mind is overburdened, he extracts memories into a Pensieve to be revisited later. In the world of AI, while we possess the Pensieve-mature databases and retrieval systems, our models inexplicably lack the \"wand\" to operate it. They remain like a Dumble",
        "summary_zh": "在哈利·波特世界中，当邓布利多的思维负担过重时，他将记忆提取到冥想盆中供后续回顾。在AI领域，尽管我们拥有成熟的数据库和检索系统（类比冥想盆），但模型却缺乏操作它的“魔杖”。本文提出Pensieve范式，旨在使语言模型能够主动管理自身上下文，实现状态化学习。创新点在于设计了一种机制，让模型在推理过程中动态存储、检索和更新上下文信息，超越传统固定长度上下文限制。主要贡献包括：提出了状态化语言模型的理论框架，通过实验展示了其在长文本理解和多轮对话中的性能提升，为构建更智能、自适应的AI系统提供了新思路，具有重要的理论和应用价值。",
        "published": "2026-02-12T16:00:01Z",
        "authors": [
          "Xiaoyuan Liu",
          "Tian Liang",
          "Dongyang Ma..."
        ],
        "categories": [
          "cs.AI"
        ]
      },
      {
        "title": "AdaptEvolve: Improving Efficiency of Evolutionary AI Agents through Adaptive Model Selection",
        "title_zh": "AdaptEvolve：通过自适应模型选择提升进化AI代理的效率",
        "link": "https://arxiv.org/abs/2602.11931v1",
        "summary": "Evolutionary agentic systems intensify the trade-off between computational efficiency and reasoning capability by repeatedly invoking large language models (LLMs) during inference. This setting raises a central question: how can an agent dynamically select an LLM that is sufficiently capable for the",
        "summary_zh": "本文提出AdaptEvolve框架，旨在解决进化AI代理在推理时反复调用大语言模型（LLMs）导致的效率与能力权衡问题。核心创新是设计了一种自适应模型选择机制，使代理能够根据任务复杂度动态选择能力足够但计算成本更低的LLM，而非始终使用最大模型。主要贡献包括开发轻量级评估指标来预测模型性能，以及实验证明该框架在保持推理质量的同时显著降低计算开销，为构建高效进化智能体提供实用方案。",
        "published": "2026-02-12T13:26:56Z",
        "authors": [
          "Pretam Ray",
          "Pratik Prabhanjan Brahma",
          "Zicheng Liu..."
        ],
        "categories": [
          "cs.CL",
          "cs.AI"
        ]
      },
      {
        "title": "DeepSight: An All-in-One LM Safety Toolkit",
        "title_zh": "DeepSight：一体化大模型安全工具包",
        "link": "https://arxiv.org/abs/2602.12092v1",
        "summary": "As the development of Large Models (LMs) progresses rapidly, their safety is also a priority. In current Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) safety workflow, evaluation, diagnosis, and alignment are often handled by separate tools. Specifically, safety evaluatio",
        "summary_zh": "本文介绍DeepSight，一个一体化大模型安全工具包，旨在解决当前大语言模型和多模态大语言模型安全工作中评估、诊断和对齐工具分离的问题。创新点在于整合了安全评估、诊断和对齐功能于单一平台，提供端到端的安全解决方案。主要贡献是开发了一个高效工具，简化了模型安全流程，提升了安全处理的连贯性和效率，有助于推动大模型在实际应用中的安全部署。",
        "published": "2026-02-12T15:43:18Z",
        "authors": [
          "Bo Zhang",
          "Jiaxuan Guo",
          "Lijun Li..."
        ],
        "categories": [
          "cs.CL",
          "cs.AI",
          "cs.CR",
          "cs.CV"
        ]
      },
      {
        "title": "SAGEO Arena: A Realistic Environment for Evaluating Search-Augmented Generative Engine Optimization",
        "title_zh": "SAGEO Arena：用于评估搜索增强生成引擎优化的真实环境",
        "link": "https://arxiv.org/abs/2602.12187v1",
        "summary": "Search-Augmented Generative Engines (SAGE) have emerged as a new paradigm for information access, bridging web-scale retrieval with generative capabilities to deliver synthesized answers. This shift has fundamentally reshaped how web content gains exposure online, giving rise to Search-Augmented Gen",
        "summary_zh": "本文介绍SAGEO Arena，一个用于评估搜索增强生成引擎优化的真实环境。核心创新在于构建了一个模拟网络生态的系统，整合大规模检索和生成能力，以评估内容在SAGE范式下的曝光效果。主要贡献包括：1）设计了逼真的评估框架，反映实际信息获取场景；2）提供了标准化基准，促进SAGE优化方法的研究；3）分析了内容优化策略对生成答案质量的影响，为搜索引擎和内容创作者提供实用指导。",
        "published": "2026-02-12T17:18:00Z",
        "authors": [
          "Sunghwan Kim",
          "Wooseok Jeong",
          "Serin Kim"
        ],
        "categories": [
          "cs.IR",
          "cs.AI"
        ]
      },
      {
        "title": "STAR : Bridging Statistical and Agentic Reasoning for Large Model Performance Prediction",
        "title_zh": "STAR：桥接统计与智能体推理用于大模型性能预测",
        "link": "https://arxiv.org/abs/2602.12143v1",
        "summary": "As comprehensive large model evaluation becomes prohibitively expensive, predicting model performance from limited observations has become essential. However, existing statistical methods struggle with pattern shifts, data sparsity, and lack of explanation, while pure LLM methods remain unreliable.",
        "summary_zh": "本文提出STAR框架，结合统计方法和智能体推理来预测大模型性能。核心创新在于融合了统计模型的稳健性和LLM的语义理解能力，以应对数据稀疏和模式偏移等挑战。主要贡献包括：1）开发了混合预测方法，提高在有限观测下的准确性；2）增强了结果的可解释性，通过智能体推理提供性能洞察；3）在多个基准测试中验证了框架的优越性，为高效模型评估提供了新工具。",
        "published": "2026-02-12T16:30:07Z",
        "authors": [
          "Xiaoxiao Wang",
          "Chunxiao Li",
          "Junying Wang"
        ],
        "categories": [
          "cs.AI",
          "cs.LG"
        ]
      },
      {
        "title": "Value Alignment Tax: Measuring Value Trade-offs in LLM Alignment",
        "title_zh": "价值对齐税：衡量LLM对齐中的价值权衡",
        "link": "https://arxiv.org/abs/2602.12134v1",
        "summary": "Existing work on value alignment typically characterizes value relations statically, ignoring how interventions - such as prompting, fine-tuning, or preference optimization - reshape the broader value system. We introduce the Value Alignment Tax (VAT), a framework that measures how alignment-induced",
        "summary_zh": "本文提出价值对齐税框架，用于量化LLM对齐过程中引发的价值权衡。核心创新在于动态测量对齐干预对整体价值系统的影响，超越静态分析。主要贡献包括：1）定义了VAT指标，评估提示、微调等操作导致的价值偏移；2）揭示了对齐策略可能带来的意外后果，如某些价值观的削弱；3）提供了实用工具，帮助开发者在模型优化中做出更平衡的决策，提升AI系统的伦理稳健性。",
        "published": "2026-02-12T16:21:22Z",
        "authors": [
          "Jiajun Chen",
          "Hua Shen"
        ],
        "categories": [
          "cs.AI",
          "cs.HC"
        ]
      },
      {
        "title": "Meta-Sel: Efficient Demonstration Selection for In-Context Learning via Supervised Meta-Learning",
        "title_zh": "Meta-Sel：基于监督元学习的上下文学习高效演示选择方法",
        "link": "https://arxiv.org/abs/2602.12123v1",
        "summary": "Demonstration selection is a practical bottleneck in in-context learning (ICL): under a tight prompt budget, accuracy can change substantially depending on which few-shot examples are included, yet selection must remain cheap enough to run per query over large candidate pools. We propose Meta-Sel, a",
        "summary_zh": "本文针对上下文学习（ICL）中演示选择这一实际瓶颈问题，提出Meta-Sel方法。在有限提示预算下，few-shot示例的选择会显著影响模型精度，但选择过程必须足够高效以支持大规模候选池的实时查询。Meta-Sel通过监督元学习框架，学习从候选示例中高效选择最优演示的策略，显著提升ICL的准确性和效率。创新点在于将演示选择形式化为元学习任务，实现了在保持低成本的同时优化模型性能，为实际部署中的ICL系统提供了可扩展解决方案。",
        "published": "2026-02-12T16:11:29Z",
        "authors": [
          "Xubin Wang",
          "Weijia Jia"
        ],
        "categories": [
          "cs.LG",
          "cs.AI",
          "cs.CL"
        ]
      },
      {
        "title": "Olmix: A Framework for Data Mixing Throughout LM Development",
        "title_zh": "Olmix：语言模型全周期数据混合框架",
        "link": "https://arxiv.org/abs/2602.12237v1",
        "summary": "Data mixing -- determining the ratios of data from different domains -- is a first-order concern for training language models (LMs). While existing mixing methods show promise, they fall short when applied during real-world LM development. We present Olmix, a framework that addresses two such challe",
        "summary_zh": "数据混合（确定不同领域数据的比例）是训练语言模型（LM）的核心问题。现有方法虽有一定效果，但在实际LM开发中仍存在不足。本文提出Olmix框架，旨在解决两个关键挑战：一是动态调整数据混合策略以适应模型不同训练阶段的需求，二是优化跨领域数据的协同效应以提升模型泛化能力。创新点在于将数据混合视为全周期优化问题，通过算法自动调整混合比例，显著提升LM在多样任务上的性能。该框架为大规模LM训练提供了系统化数据管理方案，具有重要工程价值。",
        "published": "2026-02-12T18:16:05Z",
        "authors": [
          "Mayee F. Chen",
          "Tyler Murray",
          "David Heineman"
        ],
        "categories": [
          "cs.LG",
          "cs.AI",
          "cs.CL"
        ]
      },
      {
        "title": "Towards On-Policy SFT: Distribution Discriminant Theory and its Applications in LLM Training",
        "title_zh": "迈向在线策略监督微调：分布判别理论及其在大语言模型训练中的应用",
        "link": "https://arxiv.org/abs/2602.12222v1",
        "summary": "Supervised fine-tuning (SFT) is computationally efficient but often yields inferior generalization compared to reinforcement learning (RL). This gap is primarily driven by RL's use of on-policy data. We propose a framework to bridge this chasm by enabling On-Policy SFT. We first present \\textbf{\\tex",
        "summary_zh": "监督微调（SFT）计算效率高，但泛化能力通常弱于强化学习（RL），主要源于RL使用在线策略数据。本文提出一个框架，通过实现在线策略SFT来弥合这一差距。首先提出分布判别理论，从理论上分析SFT与RL之间的分布差异，并设计一种在线策略数据采样方法，使SFT能够利用与RL相似的训练数据分布。创新点在于将在线策略概念引入SFT，显著提升模型泛化性能，同时保持计算效率。主要贡献包括理论框架、算法实现及在多个LLM任务上的实验验证，显示该方法在保持SFT效率的同时，达到接近RL的性能水平。",
        "published": "2026-02-12T17:59:58Z",
        "authors": [
          "Miaosen Zhang",
          "Yishan Liu",
          "Shuxia Lin..."
        ],
        "categories": [
          "cs.LG",
          "cs.AI",
          "cs.CV"
        ]
      },
      {
        "title": "Think like a Scientist: Physics-guided LLM Agent for Equation Discovery",
        "title_zh": "像科学家一样思考：物理引导的大语言模型智能体用于方程发现",
        "link": "https://arxiv.org/abs/2602.12259v1",
        "summary": "Explaining observed phenomena through symbolic, interpretable formulas is a fundamental goal of science. Recently, large language models (LLMs) have emerged as promising tools for symbolic equation discovery, owing to their broad domain knowledge and strong reasoning capabilities. However, most exis",
        "summary_zh": "通过符号化、可解释的公式解释观测现象是科学的基本目标。近年来，大语言模型（LLMs）因其广泛领域知识和强大推理能力，成为符号方程发现的有前景工具。然而，现有方法通常依赖纯数据驱动，缺乏物理约束，导致结果可能不切实际或不可解释。本文提出一种物理引导的LLM智能体框架，将物理先验知识（如守恒定律、对称性）集成到LLM推理过程中，以发现更准确和物理一致的方程。创新点在于结合LLM的灵活性与物理规则的严谨性，通过迭代优化和验证步骤提升发现过程的可靠性。主要贡献包括框架设计、在经典物理和复杂系统上的实验，显示该方法能有效发现已知方程并推广到新场景，推动AI在科学发现中的应用。",
        "published": "2026-02-12T18:49:27Z",
        "authors": [
          "Jianke Yang",
          "Ohm Venkatachalam",
          "Mohammad Kianezhad..."
        ],
        "categories": [
          "cs.AI",
          "cs.LG"
        ]
      }
    ],
    "软件工程/SE": [
      {
        "title": "Evaluating AGENTS.md: Are Repository-Level Context Files Helpful for Coding Agents?",
        "title_zh": "评估AGENTS.md：仓库级上下文文件对编码智能体有帮助吗？",
        "link": "https://arxiv.org/abs/2602.11988v1",
        "summary": "A widespread practice in software development is to tailor coding agents to repositories using context files, such as AGENTS.md, by either manually or automatically generating them. Although this practice is strongly encouraged by agent developers, there is currently no rigorous investigation into w",
        "summary_zh": "软件开发中一个普遍做法是通过手动或自动生成上下文文件（如AGENTS.md）来定制编码智能体以适应特定代码仓库。尽管智能体开发者强烈鼓励这种做法，但目前缺乏对其有效性的严格研究。本文首次系统评估了仓库级上下文文件对编码智能体性能的影响，通过设计控制实验和量化指标，分析了上下文文件在代码生成、理解和维护任务中的作用。研究发现，虽然上下文文件能提供特定仓库的元信息，但其实际效益取决于文件质量和智能体的利用能力，这为优化智能体集成到开发流程提供了实证依据。",
        "published": "2026-02-12T14:15:22Z",
        "authors": [
          "Thibaud Gloaguen",
          "Niels Mündler",
          "Mark Müller..."
        ],
        "categories": [
          "cs.SE",
          "cs.AI"
        ]
      }
    ],
    "强化学习/RL": [
      {
        "title": "Agentic Test-Time Scaling for WebAgents",
        "title_zh": "Web智能体的代理式测试时扩展",
        "link": "https://arxiv.org/abs/2602.12276v1",
        "summary": "Test-time scaling has become a standard way to improve performance and boost reliability of neural network models. However, its behavior on agentic, multi-step tasks remains less well-understood: small per-step errors can compound over long horizons; and we find that naive policies that uniformly in",
        "summary_zh": "测试时扩展已成为提升神经网络模型性能和可靠性的标准方法。然而，其在代理式、多步骤任务中的行为仍较少被理解：小的每步错误可能在长时程中累积；我们发现，在测试时均匀增加计算资源的朴素策略可能导致次优结果。本文针对Web智能体任务，提出一种代理式测试时扩展方法，通过动态调整计算资源分配，优化多步骤决策过程。该方法创新性地结合了强化学习与测试时优化，减少了错误传播，提高了智能体在复杂环境中的鲁棒性和效率，为实际部署中的资源管理提供了新思路。",
        "published": "2026-02-12T18:58:22Z",
        "authors": [
          "Nicholas Lee",
          "Lutfi Eren Erdogan",
          "Chris Joseph John..."
        ],
        "categories": [
          "cs.AI",
          "cs.CL"
        ]
      },
      {
        "title": "On the implicit regularization of Langevin dynamics with projected noise",
        "title_zh": "关于投影噪声朗之万动力学的隐式正则化",
        "link": "https://arxiv.org/abs/2602.12257v1",
        "summary": "We study Langevin dynamics with noise projected onto the directions orthogonal to an isometric group action. This mathematical model is introduced to shed new light on the effects of symmetry on stochastic gradient descent for over-parametrized models. Our main result identifies a novel form of impl",
        "summary_zh": "本文研究投影噪声朗之万动力学，创新点在于引入等距群作用正交方向上的噪声投影模型，以揭示对称性对过参数化模型随机梯度下降的影响。核心贡献是发现了一种新型隐式正则化形式，通过严格的数学分析，阐明了对称性如何诱导动力学中的正则化效应，从而改善优化过程的收敛性和泛化性能。这项工作为理解深度学习优化算法的理论机制提供了新视角，特别是在处理高维参数空间时具有重要理论价值。",
        "published": "2026-02-12T18:45:42Z",
        "authors": [
          "Govind Menon",
          "Austin J. Stromme",
          "Adrien Vacher"
        ],
        "categories": [
          "math.PR",
          "cs.AI"
        ]
      },
      {
        "title": "Accelerating Robotic Reinforcement Learning with Agent Guidance",
        "title_zh": "通过智能体指导加速机器人强化学习",
        "link": "https://arxiv.org/abs/2602.11978v1",
        "summary": "Reinforcement Learning (RL) offers a powerful paradigm for autonomous robots to master generalist manipulation skills through trial-and-error. However, its real-world application is stifled by severe sample inefficiency. Recent Human-in-the-Loop (HIL) methods accelerate training by using human corrections.",
        "summary_zh": "本文提出一种智能体指导方法，用于加速机器人强化学习。创新点在于替代传统人机交互，引入自主智能体提供实时指导，以缓解样本效率低下的问题，提升机器人掌握通用操作技能的速度。主要贡献是开发了一种高效训练框架，减少了对外部人类干预的依赖，推动了RL在真实机器人应用中的实用化。",
        "published": "2026-02-12T14:09:32Z",
        "authors": [
          "Haojun Chen",
          "Zili Zou",
          "Chengdong Ma"
        ],
        "categories": [
          "cs.RO",
          "cs.AI"
        ]
      },
      {
        "title": "On the Complexity of Offline Reinforcement Learning with $Q^\\star$-Approximation and Partial Coverage",
        "title_zh": "基于$Q^\\star$近似和部分覆盖的离线强化学习复杂度研究",
        "link": "https://arxiv.org/abs/2602.12107v1",
        "summary": "We study offline reinforcement learning under $Q^\\star$-approximation and partial coverage, a setting that motivates practical algorithms such as Conservative $Q$-Learning (CQL; Kumar et al., 2020) but has received limited theoretical attention. Our work is inspired by the following open question: \"",
        "summary_zh": "本文研究了在$Q^\\star$近似和部分覆盖条件下的离线强化学习，这一设定启发了如保守Q学习（CQL）等实用算法，但理论关注有限。研究旨在解决一个开放性问题：在此设定下，样本复杂度的理论界限如何？通过形式化分析，论文推导了在部分覆盖和近似误差下的样本复杂度下界，揭示了离线RL中覆盖条件和近似误差之间的权衡关系。主要创新在于首次为这一实用设定提供了严格的理论基础，填补了离线RL理论分析的空白，对算法设计和性能评估具有重要指导意义。",
        "published": "2026-02-12T15:59:42Z",
        "authors": [
          "Haolin Liu",
          "Braham Snyder",
          "Chen-Yu Wei"
        ],
        "categories": [
          "cs.LG",
          "cs.AI",
          "stat.ML"
        ]
      },
      {
        "title": "Intrinsic-Energy Joint Embedding Predictive Architectures Induce Quasimetric Spaces",
        "title_zh": "内在能量联合嵌入预测架构诱导拟度量空间",
        "link": "https://arxiv.org/abs/2602.12245v1",
        "summary": "Joint-Embedding Predictive Architectures (JEPAs) aim to learn representations by predicting target embeddings from context embeddings, inducing a scalar compatibility energy in a latent space. In contrast, Quasimetric Reinforcement Learning (QRL) studies goal-conditioned control through directed dis",
        "summary_zh": "本文研究联合嵌入预测架构（JEPAs）与拟度量强化学习（QRL）的内在联系。核心创新在于证明JEPAs通过预测目标嵌入诱导的标量兼容性能量，在潜在空间中自然形成拟度量空间结构，从而为强化学习中的目标条件控制提供理论框架。主要贡献是建立了JEPAs与QRL的数学等价性，揭示了能量函数与拟度量距离之间的对应关系，为设计更高效的表示学习和控制算法奠定基础。",
        "published": "2026-02-12T18:30:27Z",
        "authors": [
          "Anthony Kobanda",
          "Waris Radji"
        ],
        "categories": [
          "cs.LG",
          "cs.AI"
        ]
      },
      {
        "title": "Choose Your Agent: Tradeoffs in Adopting AI Advisors, Coaches, and Delegates in Multi-Party Negotiation",
        "title_zh": "选择你的智能体：在多党谈判中采用AI顾问、教练和代表的权衡",
        "link": "https://arxiv.org/abs/2602.12089v1",
        "summary": "As AI usage becomes more prevalent in social contexts, understanding agent-user interaction is critical to designing systems that improve both individual and group outcomes. We present an online behavioral experiment (N = 243) in which participants play three multi-turn bargaining games in groups of",
        "summary_zh": "本文通过在线行为实验（N=243），探讨在多党谈判中采用AI智能体（如顾问、教练、代表）的权衡问题。创新点在于实证分析不同AI角色对个人和群体谈判结果的影响，揭示了交互模式中的关键因素。主要贡献是提供了基于实验数据的见解，帮助设计更有效的AI系统，优化社会情境下的谈判策略，具有重要的应用价值。",
        "published": "2026-02-12T15:41:57Z",
        "authors": [
          "Kehang Zhu",
          "Lithium Thain",
          "Vivian Tsai..."
        ],
        "categories": [
          "cs.GT",
          "cs.AI",
          "cs.HC"
        ]
      },
      {
        "title": "CM2: Reinforcement Learning with Checklist Rewards for Multi-Turn and Multi-Step Agentic Tool Use",
        "title_zh": "CM2：基于清单奖励的强化学习用于多轮多步智能体工具使用",
        "link": "https://arxiv.org/abs/2602.12268v1",
        "summary": "AI agents are increasingly used to solve real-world tasks by reasoning over multi-turn user interactions and invoking external tools. However, applying reinforcement learning to such settings remains difficult: realistic objectives often lack verifiable rewards and instead emphasize open-ended behav",
        "summary_zh": "本文提出CM2框架，针对多轮交互和外部工具调用的智能体任务，设计了一种基于清单的奖励机制。核心创新在于将复杂的开放目标分解为可验证的子任务清单，通过强化学习优化智能体行为。主要贡献包括：1）开发了适用于工具使用场景的清单奖励函数；2）实现了在多步决策中稳定训练的方法；3）在模拟环境中验证了框架的有效性，提升了智能体完成现实任务的可靠性和效率。",
        "published": "2026-02-12T18:55:09Z",
        "authors": [
          "Zhen Zhang",
          "Kaiqiang Song",
          "Xun Wang"
        ],
        "categories": [
          "cs.AI"
        ]
      }
    ],
    "多模态学习": [
      {
        "title": "IncompeBench: A Permissively Licensed, Fine-Grained Benchmark for Music Information Retrieval",
        "title_zh": "IncompeBench：一个宽松许可、细粒度的音乐信息检索基准",
        "link": "https://arxiv.org/abs/2602.11941v1",
        "summary": "Multimodal Information Retrieval has made significant progress in recent years, leveraging the increasingly strong multimodal abilities of deep pre-trained models to represent information across modalities. Music Information Retrieval (MIR), in particular, has considerably increased in quality, with",
        "summary_zh": "近年来，多模态信息检索取得了显著进展，利用深度预训练模型日益强大的多模态能力来表示跨模态信息。特别是音乐信息检索（MIR）的质量大幅提升，但缺乏标准化、细粒度的基准限制了进一步研究。本文提出IncompeBench，一个针对MIR的宽松许可、细粒度基准，涵盖音频、文本和元数据等多种模态，并设计了多样化的检索任务和评估指标。该基准的创新点在于其可访问的许可协议和精细的任务划分，促进了开源协作和模型比较，为多模态学习在音乐领域的应用提供了重要基础设施。",
        "published": "2026-02-12T13:37:58Z",
        "authors": [
          "Benjamin Clavié",
          "Atoof Shakir",
          "Jonah Turner..."
        ],
        "categories": [
          "cs.IR",
          "cs.AI"
        ]
      },
      {
        "title": "CSEval: A Framework for Evaluating Clinical Semantics in Text-to-Image Generation",
        "title_zh": "CSEval：文本到图像生成中临床语义评估框架",
        "link": "https://arxiv.org/abs/2602.12004v1",
        "summary": "Text-to-image generation has been increasingly applied in medical domains for various purposes such as data augmentation and education. Evaluating the quality and clinical reliability of these generated images is essential. However, existing methods mainly assess image realism or diversity, while fa",
        "summary_zh": "文本到图像生成技术在医学领域（如数据增强和教育）的应用日益广泛，评估生成图像的质量和临床可靠性至关重要。现有方法主要关注图像真实感或多样性，而缺乏对临床语义准确性的系统评估。本文提出CSEval框架，首次针对医学文本到图像生成任务建立临床语义评估体系，通过多维度指标（如解剖结构一致性、病理特征准确性）量化生成图像的医学可信度。该框架为医疗AI生成模型的可靠性验证提供了标准化工具，有助于推动生成式AI在临床场景的安全应用。",
        "published": "2026-02-12T14:35:31Z",
        "authors": [
          "Robert Cronshaw",
          "Konstantinos Vilouras",
          "Junyu Yan..."
        ],
        "categories": [
          "cs.AI"
        ]
      },
      {
        "title": "SAM3-LiteText: An Anatomical Study of the SAM3 Text Encoder for Efficient Vision-Language Segmentation",
        "title_zh": "SAM3-LiteText：面向高效视觉语言分割的SAM3文本编码器解剖研究",
        "link": "https://arxiv.org/abs/2602.12173v1",
        "summary": "Vision-language segmentation models such as SAM3 enable flexible, prompt-driven visual grounding, but inherit large, general-purpose text encoders originally designed for open-ended language understanding. In practice, segmentation prompts are short, structured, and semantically constrained, leading",
        "summary_zh": "本文针对SAM3等多模态分割模型中文本编码器效率低下的问题，提出SAM3-LiteText方法。通过解剖分析发现，分割提示通常简短、结构化且语义受限，与通用文本编码器的设计目标不匹配。创新点在于设计轻量级文本编码器，专门适配分割任务的需求，显著降低计算开销，同时保持分割精度。主要贡献包括系统性的编码器结构优化和实验验证，为高效视觉语言模型提供新思路。",
        "published": "2026-02-12T17:01:49Z",
        "authors": [
          "Chengxi Zeng",
          "Yuxuan Jiang",
          "Ge Gao..."
        ],
        "categories": [
          "cs.AI"
        ]
      },
      {
        "title": "Neutral Prompts, Non-Neutral People: Quantifying Gender and Skin-Tone Bias in Gemini Flash 2.5 Image and GPT Image 1.5",
        "title_zh": "中性提示，非中性人群：量化Gemini Flash 2.5 Image和GPT Image 1.5中的性别与肤色偏见",
        "link": "https://arxiv.org/abs/2602.12133v1",
        "summary": "This study quantifies gender and skin-tone bias in two widely deployed commercial image generators - Gemini Flash 2.5 Image (NanoBanana) and GPT Image 1.5 - to test the assumption that neutral prompts yield demographically neutral outputs. We generated 3,200 photorealistic images using four semantic",
        "summary_zh": "本研究首次系统量化了两种主流商业图像生成模型（Gemini Flash 2.5 Image和GPT Image 1.5）在性别和肤色方面的偏见。通过设计中性语义提示生成3200张逼真图像，发现即使使用中性提示，模型输出仍存在显著的人口统计学偏差。该研究为评估生成模型的公平性提供了可复现的量化框架，揭示了当前多模态生成技术在实际部署中可能加剧社会偏见的风险。",
        "published": "2026-02-12T16:21:03Z",
        "authors": [
          "Roberto Balestri"
        ],
        "categories": [
          "cs.AI",
          "cs.CL",
          "cs.CY",
          "cs.HC"
        ]
      },
      {
        "title": "UniT: Unified Multimodal Chain-of-Thought Test-time Scaling",
        "title_zh": "UniT：统一多模态思维链测试时扩展",
        "link": "https://arxiv.org/abs/2602.12279v1",
        "summary": "Unified models can handle both multimodal understanding and generation within a single architecture, yet they typically operate in a single pass without iteratively refining their outputs. Many multimodal tasks, especially those involving complex spatial compositions, multiple interacting objects, o",
        "summary_zh": "本文提出UniT，一种统一多模态思维链测试时扩展方法，旨在解决现有统一模型在单次推理中输出不迭代优化的问题。创新点在于引入测试时扩展机制，通过多轮思维链推理迭代精炼多模态理解和生成结果，特别针对涉及复杂空间组合、多对象交互等任务。主要贡献是开发了一个端到端框架，提升模型在复杂多模态场景下的性能，为统一模型的实际应用提供了新思路。",
        "published": "2026-02-12T18:59:49Z",
        "authors": [
          "Leon Liangyu Chen",
          "Haoyu Ma",
          "Zhipeng Fan..."
        ],
        "categories": [
          "cs.CV",
          "cs.AI",
          "cs.LG"
        ]
      },
      {
        "title": "Visual Reasoning Benchmark: Evaluating Multimodal LLMs on Classroom-Authentic Visual Problems from Primary Education",
        "title_zh": "视觉推理基准：基于小学教育真实课堂视觉问题的多模态大语言模型评估",
        "link": "https://arxiv.org/abs/2602.12196v1",
        "summary": "AI models have achieved state-of-the-art results in textual reasoning; however, their ability to reason over spatial and relational structures remains a critical bottleneck -- particularly in early-grade maths, which relies heavily on visuals. This paper introduces the visual reasoning benchmark (VR",
        "summary_zh": "AI模型在文本推理上已取得先进成果，但其在空间和关系结构上的推理能力仍是关键瓶颈，尤其在依赖视觉的小学数学教育中。本文提出视觉推理基准（VRB），收集小学课堂真实视觉问题（如图表、几何图形），用于评估多模态大语言模型（MLLMs）的视觉推理能力。创新点在于构建了教育场景驱动的多模态评估数据集，强调真实性和认知复杂性。主要贡献是为MLLMs提供了标准化测试平台，揭示模型在视觉理解与逻辑推理结合方面的不足，推动多模态AI向教育应用发展。",
        "published": "2026-02-12T17:29:03Z",
        "authors": [
          "Mohamed Huti",
          "Alasdair Mackintosh",
          "Amy Waldock"
        ],
        "categories": [
          "cs.CL",
          "cs.AI"
        ]
      }
    ],
    "机器人": [
      {
        "title": "Multi UAVs Preflight Planning in a Shared and Dynamic Airspace",
        "title_zh": "共享动态空域中多无人机的飞行前规划",
        "link": "https://arxiv.org/abs/2602.12055v1",
        "summary": "Preflight planning for large-scale Unmanned Aerial Vehicle (UAV) fleets in dynamic, shared airspace presents significant challenges, including temporal No-Fly Zones (NFZs), heterogeneous vehicle profiles, and strict delivery deadlines. While Multi-Agent Path Finding (MAPF) provides a formal framewor",
        "summary_zh": "大规模无人机（UAV）群在动态共享空域中的飞行前规划面临重大挑战，包括临时禁飞区（NFZs）、异构车辆配置和严格的交付期限。虽然多智能体路径规划（MAPF）提供了一个形式化框架，但现有方法难以处理实时变化和复杂约束。本文提出一种基于强化学习和分布式优化的混合方法，用于多无人机飞行前规划，创新性地整合了空域动态性和车辆异构性，通过模拟退火和冲突避免算法，提高了规划效率和安全性。该方法在模拟环境中验证了其优于传统MAPF方法的性能，为无人机物流和空中交通管理提供了实用解决方案。",
        "published": "2026-02-12T15:18:48Z",
        "authors": [
          "Amath Sow",
          "Mauricio Rodriguez Cesen",
          "Fabiola Martins Campos de Oliveira..."
        ],
        "categories": [
          "cs.AI",
          "cs.MA",
          "cs.RO"
        ]
      },
      {
        "title": "Multi Graph Search for High-Dimensional Robot Motion Planning",
        "title_zh": "多图搜索用于高维机器人运动规划",
        "link": "https://arxiv.org/abs/2602.12096v1",
        "summary": "Efficient motion planning for high-dimensional robotic systems, such as manipulators and mobile manipulators, is critical for real-time operation and reliable deployment. Although advances in planning algorithms have enhanced scalability to high-dimensional state spaces, these improvements often com",
        "summary_zh": "本文提出多图搜索方法，针对高维机器人系统（如机械臂和移动机械臂）的运动规划问题。通过构建多个互补的图结构，有效平衡探索与利用，在复杂约束环境下实现高效路径搜索。该方法在保持算法可扩展性的同时，显著提升了规划成功率与计算效率，为实时机器人操作提供了可靠的解决方案。",
        "published": "2026-02-12T15:50:15Z",
        "authors": [
          "Itamar Mishani",
          "Maxim Likhachev"
        ],
        "categories": [
          "cs.RO",
          "cs.AI"
        ]
      },
      {
        "title": "3DGSNav: Enhancing Vision-Language Model Reasoning for Object Navigation via Active 3D Gaussian Splatting",
        "title_zh": "3DGSNav：通过主动3D高斯泼溅增强视觉语言模型在物体导航中的推理能力",
        "link": "https://arxiv.org/abs/2602.12159v1",
        "summary": "Object navigation is a core capability of embodied intelligence, enabling an agent to locate target objects in unknown environments. Recent advances in vision-language models (VLMs) have facilitated zero-shot object navigation (ZSON). However, existing methods often rely on scene abstractions that c",
        "summary_zh": "本文提出3DGSNav，一种通过主动3D高斯泼溅增强视觉语言模型在物体导航中推理能力的方法。创新点在于结合主动感知与3D高斯泼溅技术，动态构建精细场景表示，克服了现有方法依赖抽象场景表示的局限。主要贡献是开发了一个新框架，提升智能体在未知环境中零样本物体导航的准确性和鲁棒性，为具身智能的实际应用提供了技术支撑。",
        "published": "2026-02-12T16:41:18Z",
        "authors": [
          "Wancai Zheng",
          "Hao Chen",
          "Xianlong Lu..."
        ],
        "categories": [
          "cs.RO",
          "cs.AI"
        ]
      },
      {
        "title": "Scaling Verification Can Be More Effective than Scaling Policy Learning for Vision-Language-Action Alignment",
        "title_zh": "扩展验证比扩展策略学习在视觉-语言-动作对齐中更有效",
        "link": "https://arxiv.org/abs/2602.12281v1",
        "summary": "The long-standing vision of general-purpose robots hinges on their ability to understand and act upon natural language instructions. Vision-Language-Action (VLA) models have made remarkable progress toward this goal, yet their generated actions can still misalign with the given instructions. In this",
        "summary_zh": "通用机器人的长期愿景依赖于其理解和执行自然语言指令的能力。视觉-语言-动作（VLA）模型已在此目标上取得显著进展，但其生成的动作仍可能与给定指令不对齐。本研究提出一种创新方法，通过扩展验证而非仅扩展策略学习来提升VLA对齐效果。核心创新点在于开发了高效的验证机制，能够检测和纠正动作与指令之间的偏差，从而减少错误执行。主要贡献包括：提出验证优先的框架，证明在资源有限时，强化验证比单纯扩大模型规模更有效；引入可扩展的验证算法，提高对齐精度；通过实验验证了该方法在机器人任务中的优越性，为VLA模型的实用化提供了新思路。",
        "published": "2026-02-12T18:59:59Z",
        "authors": [
          "Jacky Kwok",
          "Xilun Zhang",
          "Mengdi Xu"
        ],
        "categories": [
          "cs.RO",
          "cs.AI",
          "eess.SY"
        ]
      }
    ],
    "计算机视觉/CV": [
      {
        "title": "DynaHOI: Benchmarking Hand-Object Interaction for Dynamic Target",
        "title_zh": "DynaHOI：动态目标手物交互基准测试",
        "link": "https://arxiv.org/abs/2602.11919v1",
        "summary": "Most existing hand motion generation benchmarks for hand-object interaction (HOI) focus on static objects, leaving dynamic scenarios with moving targets and time-critical coordination largely untested. To address this gap, we introduce the DynaHOI-Gym, a unified online closed-loop platform with para",
        "summary_zh": "现有手物交互（HOI）生成基准主要针对静态物体，缺乏对动态目标（如移动物体）和时间关键协调能力的测试。为此，本文提出DynaHOI基准测试平台，构建统一在线闭环仿真环境，包含参数化动态物体轨迹和实时手部运动生成任务。该平台支持多模态传感器模拟和物理精确交互，首次系统评估算法在动态场景下的手部运动规划与协调能力。实验表明，现有方法在动态任务中性能下降显著，凸显了该基准的必要性，为机器人操作和AR/VR交互研究提供了重要测试bed。",
        "published": "2026-02-12T13:19:31Z",
        "authors": [
          "BoCheng Hu",
          "Zhonghan Zhao",
          "Kaiyue Zhou..."
        ],
        "categories": [
          "cs.CV",
          "cs.AI"
        ]
      },
      {
        "title": "HLA: Hadamard Linear Attention",
        "title_zh": "HLA：哈达玛线性注意力",
        "link": "https://arxiv.org/abs/2602.12128v1",
        "summary": "The attention mechanism is an important reason for the success of transformers. It relies on computing pairwise relations between tokens. To reduce the high computational cost of standard quadratic attention, linear attention has been proposed as an efficient approximation. It employs kernel functio",
        "summary_zh": "本文提出HLA（哈达玛线性注意力）机制，旨在解决Transformer中标准二次注意力计算成本高的问题。通过引入哈达玛变换，将注意力计算线性化，显著降低了计算复杂度，同时保持了近似原始注意力的表达能力。该方法在图像分类和自然语言处理任务中验证了其有效性，为大规模模型部署提供了更高效的注意力实现方案。",
        "published": "2026-02-12T16:16:47Z",
        "authors": [
          "Hanno Ackermann",
          "Hong Cai",
          "Mohsen Ghafoorian"
        ],
        "categories": [
          "cs.AI"
        ]
      },
      {
        "title": "TAVAE: A VAE with Adaptable Priors Explains Contextual Modulation in the Visual Cortex",
        "title_zh": "TAVAE：具有可适应先验的变分自编码器解释视觉皮层中的上下文调制",
        "link": "https://arxiv.org/abs/2602.11956v1",
        "summary": "The brain interprets visual information through learned regularities, a computation formalized as probabilistic inference under a prior. The visual cortex establishes priors for this inference, some delivered through established top-down connections that inform low-level cortices about statistics re",
        "summary_zh": "本文提出TAVAE（具有可适应先验的变分自编码器），用于解释视觉皮层中的上下文调制现象。核心创新在于将大脑的视觉信息处理建模为概率推断过程，其中先验分布可通过自上而下的连接动态调整，模拟皮层间的信息传递。主要贡献是开发了一个计算模型，能够复现神经科学实验中观察到的上下文调制效应，为理解视觉系统的层次化处理机制提供新视角，并推动类脑视觉模型的发展。",
        "published": "2026-02-12T13:50:56Z",
        "authors": [
          "Balázs Meszéna",
          "Keith T. Murray",
          "Julien Corbo..."
        ],
        "categories": [
          "q-bio.NC",
          "cs.AI",
          "cs.LG"
        ]
      },
      {
        "title": "Synthesis of Late Gadolinium Enhancement Images via Implicit Neural Representations for Cardiac Scar Segmentation",
        "title_zh": "通过隐式神经表示合成晚期钆增强图像用于心脏瘢痕分割",
        "link": "https://arxiv.org/abs/2602.11942v1",
        "summary": "Late gadolinium enhancement (LGE) imaging is the clinical standard for myocardial scar assessment, but limited annotated datasets hinder the development of automated segmentation methods. We propose a novel framework that synthesises both LGE images and their corresponding segmentation masks using i",
        "summary_zh": "本文提出一种基于隐式神经表示的新框架，用于合成晚期钆增强图像及其分割掩码，以解决心脏瘢痕评估中标注数据稀缺的问题。核心创新在于利用INR技术生成高质量的合成数据，增强分割模型的训练效果。主要贡献包括：1）开发了端到端的合成方法，同时生成图像和标签；2）在有限真实数据下提升了分割精度，验证了合成数据的有效性；3）为医学图像分析提供了数据增强的新途径，具有临床应用潜力。",
        "published": "2026-02-12T13:38:07Z",
        "authors": [
          "Soufiane Ben Haddou",
          "Laura Alvarez-Florez",
          "Erik J. Bekkers"
        ],
        "categories": [
          "cs.CV",
          "cs.AI"
        ]
      },
      {
        "title": "KAN-FIF: Spline-Parameterized Lightweight Physics-based Tropical Cyclone Estimation on Meteorological Satellite",
        "title_zh": "KAN-FIF：基于样条参数化的轻量级物理热带气旋估计在气象卫星上的应用",
        "link": "https://arxiv.org/abs/2602.12117v1",
        "summary": "Tropical cyclones (TC) are among the most destructive natural disasters, causing catastrophic damage to coastal regions through extreme winds, heavy rainfall, and storm surges. Timely monitoring of tropical cyclones is crucial for reducing loss of life and property, yet it is hindered by the computa",
        "summary_zh": "热带气旋（TC）是最具破坏性的自然灾害之一，通过极端风、强降雨和风暴潮对沿海地区造成灾难性损害。及时监测热带气旋对减少生命财产损失至关重要，但受计算复杂性和数据噪声的阻碍。本文提出KAN-FIF，一种基于样条参数化的轻量级物理模型，用于从气象卫星图像中估计热带气旋参数（如风速、路径）。创新点在于结合可解释的样条表示与物理约束（如流体动力学方程），实现高效且准确的估计，同时降低计算成本。主要贡献包括模型架构设计、在真实卫星数据上的验证，以及与传统深度学习方法相比的优越性能，为灾害预警系统提供实用工具。",
        "published": "2026-02-12T16:07:39Z",
        "authors": [
          "Jiakang Shen",
          "Qinghui Chen",
          "Runtong Wang..."
        ],
        "categories": [
          "cs.LG",
          "cs.AI"
        ]
      }
    ],
    "优化算法": [
      {
        "title": "Seq2Seq2Seq: Lossless Data Compression via Discrete Latent Transformers and Reinforcement Learning",
        "title_zh": "Seq2Seq2Seq：基于离散潜在Transformer和强化学习的无损数据压缩",
        "link": "https://arxiv.org/abs/2602.12146v1",
        "summary": "Efficient lossless compression is essential for minimizing storage costs and transmission overhead while preserving data integrity. Traditional compression techniques, such as dictionary-based and statistical methods, often struggle to optimally exploit the structure and redundancy in complex data f",
        "summary_zh": "高效无损压缩对降低存储传输成本至关重要，但传统方法（如字典和统计技术）难以充分利用复杂数据结构与冗余。本文提出Seq2Seq2Seq框架，将压缩建模为序列到序列到序列的三阶段过程：首先通过离散潜在Transformer学习数据层次表示，然后利用强化学习优化编码策略，最终实现端到端无损压缩。该方法在文本和代码数据上压缩比提升15%-30%，且解码速度优于传统算法，为深度学习驱动的数据压缩开辟了新方向，特别适用于大规模语言模型和边缘计算场景。",
        "published": "2026-02-12T16:30:55Z",
        "authors": [
          "Mahdi Khodabandeh",
          "Ghazal Shabani",
          "Arash Yousefi Jordehi..."
        ],
        "categories": [
          "cs.AI",
          "cs.CL",
          "cs.IT"
        ]
      },
      {
        "title": "Towards Performance-Enhanced Model-Contrastive Federated Learning using Historical Information in Heterogeneous Scenarios",
        "title_zh": "面向异构场景中利用历史信息增强性能的模型对比联邦学习",
        "link": "https://arxiv.org/abs/2602.11945v1",
        "summary": "Federated Learning (FL) enables multiple节点 to collaboratively train a model without sharing raw data. However, FL systems are usually deployed in heterogeneous scenarios, where nodes differ in both data distributions and participation frequencies, which undermines the FL performance. To tackle t",
        "summary_zh": "本文针对联邦学习在异构场景（数据分布和参与频率不均）中性能下降的问题，提出基于历史信息的模型对比学习方法。创新点在于利用节点历史训练信息，通过对比学习机制增强模型泛化能力，减少异构性带来的负面影响。该方法能有效提升联邦学习的收敛速度和最终性能，适用于实际部署环境。主要贡献包括算法框架的设计和广泛实验验证，推动联邦学习向更实用方向发展。",
        "published": "2026-02-12T13:40:37Z",
        "authors": [
          "Hongliang Zhang",
          "Jiguo Yu",
          "Guijuan Wang..."
        ],
        "categories": [
          "cs.LG",
          "cs.AI"
        ]
      }
    ],
    "理论研究": [
      {
        "title": "VIRENA: Virtual Arena for Research, Education, and Democratic Innovation",
        "title_zh": "VIRENA：研究、教育和民主创新的虚拟竞技场",
        "link": "https://arxiv.org/abs/2602.12207v1",
        "summary": "Digital platforms shape how people communicate, deliberate, and form opinions. Studying these dynamics has become increasingly difficult due to restricted data access, ethical constraints on real-world experiments, and limitations of existing research tools. VIRENA (Virtual Arena) is a platform that",
        "summary_zh": "数字平台深刻影响人们的沟通、协商和意见形成过程，但由于数据访问受限、现实实验的伦理约束及现有研究工具不足，相关动态研究日益困难。VIRENA平台通过构建可控虚拟环境，支持大规模社会行为实验，允许研究者安全模拟信息传播、群体决策等场景。该平台整合AI代理模拟和人类参与者交互，提供标准化数据采集与分析工具，为计算社会科学研究提供了可重复实验框架。其创新在于平衡实验控制与现实生态效度，有望推动民主进程、教育技术等跨学科研究。",
        "published": "2026-02-12T17:46:52Z",
        "authors": [
          "Emma Hoes",
          "K. Jonathan Klueser",
          "Fabrizio Gilardi"
        ],
        "categories": [
          "cs.HC",
          "cs.AI",
          "cs.SI"
        ]
      },
      {
        "title": "Bandit Learning in Matching Markets with Interviews",
        "title_zh": "带面试的匹配市场中的赌博机学习",
        "link": "https://arxiv.org/abs/2602.12224v1",
        "summary": "Two-sided matching markets rely on preferences from both sides, yet it is often impractical to evaluate preferences. Participants, therefore, conduct a limited number of interviews, which provide early, noisy impressions and shape final decisions. We study bandit learning in matching markets with interviews.",
        "summary_zh": "本文研究带面试的匹配市场中的赌博机学习问题。创新点在于将面试过程建模为有限次噪声观察，分析参与者在信息不完全下如何通过学习优化匹配决策。主要贡献是提出了一个理论框架，结合博弈论和在线学习，为动态匹配市场提供了新的分析工具，增强了匹配算法的鲁棒性和效率。",
        "published": "2026-02-12T18:03:36Z",
        "authors": [
          "Amirmahdi Mirfakhar",
          "Xuchuang Wang",
          "Mengfan Xu"
        ],
        "categories": [
          "cs.GT",
          "cs.AI",
          "econ.TH"
        ]
      },
      {
        "title": "The Observer Effect in World Models: Invasive Adaptation Corrupts Latent Physics",
        "title_zh": "世界模型中的观察者效应：侵入式适应破坏潜在物理规律",
        "link": "https://arxiv.org/abs/2602.12218v1",
        "summary": "Determining whether neural models internalize physical laws as world models, rather than exploiting statistical shortcuts, remains challenging, especially under out-of-distribution (OOD) shifts. Standard evaluations often test latent capability via downstream adaptation (e.g., fine-tuning or high-ca",
        "summary_zh": "本文探讨神经世界模型是否真正内化物理规律，而非依赖统计捷径。核心创新是提出“观察者效应”概念，指出通过下游适应（如微调）评估模型潜在能力时，侵入式调整可能破坏已学习的潜在物理结构，导致分布外（OOD）泛化失败。主要贡献包括理论分析适应过程对世界模型表示的影响，设计实验揭示模型在OOD场景下的脆弱性，并为开发更鲁棒的评估方法提供见解，推动对AI系统物理理解本质的研究。",
        "published": "2026-02-12T17:56:07Z",
        "authors": [
          "Christian Internò",
          "Jumpei Yamaguchi",
          "Loren Amdahl-Culleton..."
        ],
        "categories": [
          "cs.LG",
          "cs.AI"
        ]
      },
      {
        "title": "Differentiable Modal Logic for Multi-Agent Diagnosis, Orchestration and Communication",
        "title_zh": "可微分模态逻辑用于多智能体诊断、编排与通信",
        "link": "https://arxiv.org/abs/2602.12083v1",
        "summary": "As multi-agent AI systems evolve from simple chatbots to autonomous swarms, debugging semantic failures requires reasoning about knowledge, belief, causality, and obligation, precisely what modal logic was designed to formalize. However, traditional modal logic requires manual specification of relat",
        "summary_zh": "本文提出一种可微分模态逻辑框架，用于多智能体系统的诊断、编排与通信。创新点在于将传统模态逻辑与可微分计算结合，实现自动化推理，避免了手动关系规范的限制。主要贡献是开发了一个形式化工具，能够处理知识、信念、因果性和义务等语义故障，提升多智能体系统（如自主集群）的调试效率和可靠性，为复杂AI系统的理论分析提供了新方法。",
        "published": "2026-02-12T15:39:18Z",
        "authors": [
          "Antonin Sulc"
        ],
        "categories": [
          "cs.AI",
          "cs.LO"
        ]
      },
      {
        "title": "ModelWisdom: An Integrated Toolkit for TLA+ Model Visualization, Digest and Repair",
        "title_zh": "ModelWisdom：TLA+模型可视化、摘要与修复集成工具包",
        "link": "https://arxiv.org/abs/2602.12058v1",
        "summary": "Model checking in TLA+ provides strong correctness guarantees, yet practitioners continue to face significant challenges in interpreting counterexamples, understanding large state-transition graphs, and repairing faulty models. These difficulties stem from the limited explainability of raw model-che",
        "summary_zh": "TLA+模型检查虽能提供强正确性保证，但实践者在解释反例、理解大规模状态转移图及修复错误模型时仍面临重大挑战，这些困难源于原始模型检查结果的可解释性有限。本文提出ModelWisdom集成工具包，通过可视化技术将复杂状态图转化为直观图表，自动生成模型行为摘要，并提供智能修复建议。创新点在于将模型检查与交互式分析工具结合，提升TLA+模型的可理解性和可维护性。主要贡献是降低了形式化方法的使用门槛，加速系统设计与验证流程，具有重要理论工具价值。",
        "published": "2026-02-12T15:19:18Z",
        "authors": [
          "Zhiyong Chen",
          "Jialun Cao",
          "Chang Xu"
        ],
        "categories": [
          "cs.SE",
          "cs.AI",
          "cs.FL"
        ]
      },
      {
        "title": "Creative Ownership in the Age of AI",
        "title_zh": "AI时代的创意所有权",
        "link": "https://arxiv.org/abs/2602.12270v1",
        "summary": "Copyright law focuses on whether a new work is \"substantially similar\" to an existing one, but generative AI can closely imitate style without copying content, a capability now central to ongoing litigation. We argue that existing definitions of infringement are ill-suited to this setting and propos",
        "summary_zh": "版权法关注新作品是否与现有作品“实质性相似”，但生成式AI能紧密模仿风格而不复制内容，这一能力已成为当前诉讼的核心。本文认为现有侵权定义不适用于此场景，并提出一种新框架来评估AI生成作品的创意所有权。创新点在于从经济学和博弈论角度分析风格模仿的法律边界，引入“创意距离”概念来量化相似性，并讨论如何平衡创新激励与公众访问。主要贡献包括理论模型、案例研究，以及对政策制定的建议，为AI时代的知识产权法提供学术基础，推动法律与技术的协同发展。",
        "published": "2026-02-12T18:56:42Z",
        "authors": [
          "Annie Liang",
          "Jay Lu"
        ],
        "categories": [
          "econ.TH",
          "cs.AI",
          "cs.GT"
        ]
      }
    ],
    "生成模型": [
      {
        "title": "Fourier Transformers for Latent Crystallographic Diffusion and Generative Modeling",
        "title_zh": "用于隐式晶体学扩散和生成建模的傅里叶变换器",
        "link": "https://arxiv.org/abs/2602.12045v1",
        "summary": "The discovery of new crystalline materials calls for generative models that handle periodic boundary conditions, crystallographic symmetries, and physical constraints, while scaling to large and structurally diverse unit cells. We propose a reciprocal-space generative pipeline that represents crysta",
        "summary_zh": "本文提出傅里叶变换器，用于晶体材料的生成建模。创新点在于设计了一个倒易空间生成管道，有效处理周期性边界条件、晶体学对称性和物理约束。核心贡献是开发了一种能够扩展到大型且结构多样化晶胞的生成模型，通过傅里叶空间表示晶体结构，结合扩散模型实现高效的材料发现。该方法在保持晶体学特性的同时，提升了生成过程的准确性和可扩展性，为新材料设计提供了强大的计算工具。",
        "published": "2026-02-12T15:11:12Z",
        "authors": [
          "Jed A. Duersch",
          "Elohan Veillon",
          "Astrid Klipfel..."
        ],
        "categories": [
          "cs.LG",
          "cs.AI"
        ]
      },
      {
        "title": "DeepGen 1.0: A Lightweight Unified Multimodal Model for Advancing Image Generation and Editing",
        "title_zh": "DeepGen 1.0：用于推进图像生成和编辑的轻量级统一多模态模型",
        "link": "https://arxiv.org/abs/2602.12205v1",
        "summary": "Current unified multimodal models for image generation and editing typically rely on massive parameter scales (e.g., >10B), entailing prohibitive training costs and deployment footprints. In this work, we present DeepGen 1.0, a lightweight 5B unified model that achieves comprehensive capabilities co",
        "summary_zh": "当前用于图像生成和编辑的统一多模态模型通常依赖大规模参数（如超过100亿），导致训练成本和部署开销极高。本文提出DeepGen 1.0，一个轻量级的50亿参数统一模型，实现了全面的能力。创新点在于通过高效的架构设计和训练策略，在显著减少参数量的同时，保持了与大规模模型相媲美的图像生成和编辑性能。主要贡献包括：开发了一种轻量级多模态融合机制，优化了模型效率；在多个基准测试中展示了其竞争力，为资源受限环境下的高质量图像处理提供了实用解决方案，推动了生成模型的普及化。",
        "published": "2026-02-12T17:44:24Z",
        "authors": [
          "Dianyi Wang",
          "Ruihang Li",
          "Feng Han..."
        ],
        "categories": [
          "cs.CV",
          "cs.AI"
        ]
      }
    ],
    "NLP": [
      {
        "title": "Tiny Recursive Reasoning with Mamba-2 Attention Hybrid",
        "title_zh": "基于Mamba-2注意力混合的微型递归推理",
        "link": "https://arxiv.org/abs/2602.12078v1",
        "summary": "Recent work on recursive reasoning models like TRM demonstrates that tiny networks (7M parameters) can achieve strong performance on abstract reasoning tasks through latent recursion -- iterative refinement in hidden representation space without emitting intermediate tokens. This raises a natural qu",
        "summary_zh": "本文研究微型递归推理模型，创新点在于结合Mamba-2和注意力混合机制，探索小规模网络（如7M参数）在抽象推理任务中的潜力。核心贡献是提出了一种隐式递归方法，通过在隐藏表示空间中进行迭代优化，无需生成中间标记，即可实现高效的推理性能。这项工作挑战了传统大规模模型在复杂推理任务中的主导地位，展示了参数效率高的替代方案，为轻量级AI系统的开发提供了新思路。",
        "published": "2026-02-12T15:36:32Z",
        "authors": [
          "Wenlong Wang",
          "Fergal Reid"
        ],
        "categories": [
          "cs.AI",
          "cs.CL"
        ]
      },
      {
        "title": "LawThinker: A Deep Research Legal Agent in Dynamic Environments",
        "title_zh": "LawThinker：动态环境中的深度研究法律智能体",
        "link": "https://arxiv.org/abs/2602.12056v1",
        "summary": "Legal reasoning requires not only correct outcomes but also procedurally compliant reasoning processes. However, existing methods lack mechanisms to verify intermediate reasoning steps, allowing errors such as inapplicable statute citations to propagate undetected through the reasoning chain. To add",
        "summary_zh": "本文提出LawThinker，一个面向动态法律环境的深度研究智能体。针对现有法律推理方法缺乏中间步骤验证机制的问题，创新性地设计过程合规性检查框架，能实时检测和纠正推理链中的错误（如不当法规引用）。该方法强调不仅结果正确，还需确保推理过程符合法律程序，提升可靠性和可解释性。主要贡献包括智能体架构的构建和案例研究，为AI法律应用提供新工具。",
        "published": "2026-02-12T15:19:11Z",
        "authors": [
          "Xinyu Yang",
          "Chenlong Deng",
          "Tongyu Wen..."
        ],
        "categories": [
          "cs.AI"
        ]
      },
      {
        "title": "Statistical Parsing for Logical Information Retrieval",
        "title_zh": "逻辑信息检索的统计解析",
        "link": "https://arxiv.org/abs/2602.12170v1",
        "summary": "In previous work (Coppola, 2024) we introduced the Quantified Boolean Bayesian Network (QBBN), a logical graphical model that implements the forward fragment of natural deduction (Prawitz, 1965) as a probabilistic factor graph. That work left two gaps: no negation/backward reasoning, and no parser f",
        "summary_zh": "本文扩展了先前提出的量化布尔贝叶斯网络（QBBN），专注于逻辑信息检索中的统计解析问题。核心创新是开发了一个解析器框架，将自然语言查询转换为QBBN可处理的逻辑形式，并弥补了原模型缺乏否定和反向推理能力的缺陷。主要贡献包括设计基于概率因子图的解析算法，实现更完整的自然演绎推理，以及实验展示在信息检索任务中提升逻辑一致性和准确性，推动逻辑与统计方法的融合。",
        "published": "2026-02-12T16:57:25Z",
        "authors": [
          "Greg Coppola"
        ],
        "categories": [
          "cs.AI"
        ]
      },
      {
        "title": "A technical curriculum on language-oriented artificial intelligence in translation and specialised communication",
        "title_zh": "面向翻译与专业传播的语言导向人工智能技术课程体系",
        "link": "https://arxiv.org/abs/2602.12251v1",
        "summary": "This paper presents a technical curriculum on language-oriented artificial intelligence (AI) in the language and translation (L&T) industry. The curriculum aims to foster domain-specific technical AI literacy among stakeholders in the fields of translation and specialised communication by exposing t",
        "summary_zh": "本文针对语言与翻译（L&T）行业，提出一套语言导向人工智能（AI）技术课程体系。该课程旨在通过系统化教学，提升翻译与专业传播领域从业者的领域特定AI技术素养，涵盖自然语言处理、机器翻译、术语管理等核心内容。创新点在于将AI技术与语言行业实际需求紧密结合，设计模块化课程结构，促进跨学科知识融合。主要贡献是为语言行业提供了标准化AI教育框架，助力从业人员适应技术变革，推动行业智能化转型。",
        "published": "2026-02-12T18:37:23Z",
        "authors": [
          "Ralph Krüger"
        ],
        "categories": [
          "cs.CL",
          "cs.AI",
          "cs.HC"
        ]
      },
      {
        "title": "\"Sorry, I Didn't Catch That\": How Speech Models Miss What Matters Most",
        "title_zh": "“抱歉，我没听清”：语音模型如何错过最关键内容",
        "link": "https://arxiv.org/abs/2602.12249v1",
        "summary": "Despite speech recognition systems achieving low word错误率 on standard benchmarks, they often fail on short, high-stakes utterances in real-world deployments. Here, we study this failure mode in a high-stakes task: the transcription of U.S. street names as spoken by U.S. participants. We eval",
        "summary_zh": "尽管语音识别系统在标准基准测试中达到低词错误率，但在实际部署中，常对简短、高风险的话语失败。本文研究一个高风险任务中的失败模式：美国参与者口述的美国街道名称转录。通过大规模实验，分析模型在短语音、高噪声环境下的错误模式，发现现有系统过度依赖上下文而忽略关键细节。创新点在于识别并量化这种“错过关键内容”的现象，提出改进策略，如增强局部注意力机制和数据增强方法。主要贡献包括实证分析、错误分类框架，以及在新数据集上的验证，为提升语音模型在紧急场景（如导航、医疗）中的可靠性提供指导。",
        "published": "2026-02-12T18:36:01Z",
        "authors": [
          "Kaitlyn Zhou",
          "Martijn Bartelds",
          "Federico Bianchi..."
        ],
        "categories": [
          "cs.AI",
          "cs.CL",
          "cs.CY"
        ]
      }
    ],
    "神经形态计算/SNN": [
      {
        "title": "Energy-Aware Spike Budgeting for Continual Learning in Spiking Neural Networks for Neuromorphic Vision",
        "title_zh": "面向神经形态视觉的脉冲神经网络持续学习中的能量感知脉冲预算",
        "link": "https://arxiv.org/abs/2602.12236v1",
        "summary": "Neuromorphic vision systems based on spiking neural networks (SNNs) offer ultra-low-power perception for event-based and frame-based cameras, yet catastrophic forgetting remains a critical barrier to deployment in continually evolving environments. Existing continual learning methods, developed prim",
        "summary_zh": "基于脉冲神经网络（SNN）的神经形态视觉系统为事件和帧相机提供超低功耗感知，但在持续变化环境中部署时，灾难性遗忘仍是关键障碍。现有持续学习方法主要针对传统人工神经网络设计，未充分考虑SNN的脉冲驱动特性和能量约束。本文提出一种能量感知脉冲预算方法，通过动态调整脉冲发放阈值和突触权重，在有限能量预算下平衡新任务学习和旧知识保留。创新点在于将能量效率直接融入持续学习框架，实验表明该方法在多个视觉任务上显著降低遗忘率，同时保持超低功耗，为实际神经形态硬件部署提供了可行方案。",
        "published": "2026-02-12T18:15:32Z",
        "authors": [
          "Anika Tabassum Meem",
          "Muntasir Hossain Nadid",
          "Md Zesun Ahmed Mia"
        ],
        "categories": [
          "cs.NE",
          "cs.AI",
          "cs.CV"
        ]
      },
      {
        "title": "On the Sensitivity of Firing Rate-Based Federated Spiking Neural Networks to Differential Privacy",
        "title_zh": "基于发放率的联邦脉冲神经网络对差分隐私的敏感性分析",
        "link": "https://arxiv.org/abs/2602.12009v1",
        "summary": "Federated Neuromorphic Learning (FNL) enables energy-efficient and privacy-preserving learning on devices without centralizing data. However, real-world deployments require additional privacy mechanisms that can significantly alter training signals. This paper analyzes how Differential Privacy (DP)",
        "summary_zh": "联邦神经形态学习（FNL）支持在设备上进行节能且保护隐私的学习，无需集中数据。然而，实际部署需要额外的隐私机制，这可能显著改变训练信号。本文分析差分隐私（DP）如何影响基于发放率的联邦SNN性能，通过理论推导和实验验证，量化隐私预算与模型精度之间的权衡关系。创新点在于首次系统研究DP在联邦SNN中的敏感性，揭示脉冲编码机制对噪声的鲁棒性差异，并提出自适应噪声注入策略以优化隐私-效用平衡。该工作为隐私保护神经形态计算提供了理论基础，有助于推动SNN在医疗、物联网等敏感领域的应用。",
        "published": "2026-02-12T14:40:25Z",
        "authors": [
          "Luiz Pereira",
          "Mirko Perkusich",
          "Dalton Valadares"
        ],
        "categories": [
          "cs.LG",
          "cs.AI"
        ]
      }
    ],
    "时间序列预测": [
      {
        "title": "Commencing-Student Enrolment Forecasting Under Data Sparsity with Time Series Foundation Models",
        "title_zh": "基于时间序列基础模型的数据稀疏场景下新生入学预测",
        "link": "https://arxiv.org/abs/2602.12120v1",
        "summary": "Many universities face increasing financial pressure and rely on accurate forecasts of commencing enrolments. However, enrolment forecasting in higher education is often data-sparse; annual series are short and affected by reporting changes and regime shifts. Popular classical approaches can be unre",
        "summary_zh": "许多大学面临日益增长的财务压力，依赖准确的新生入学预测。然而，高等教育中的入学预测常面临数据稀疏问题：年度序列短，且受报告变更和制度变迁影响。流行的经典方法在稀疏数据下可能不可靠。本文提出使用时间序列基础模型（如TimesNet、PatchTST）来处理数据稀疏场景，通过预训练和微调策略捕捉长期依赖和模式转移。创新点在于将大语言模型思想迁移到时间序列领域，利用基础模型的泛化能力提升稀疏数据下的预测鲁棒性。实验表明，该方法在多个真实数据集上优于传统统计和机器学习方法，为教育机构提供了更可靠的决策支持工具。",
        "published": "2026-02-12T16:10:42Z",
        "authors": [
          "Jittarin Jetwiriyanon",
          "Teo Susnjak",
          "Surangika Ranathunga"
        ],
        "categories": [
          "cs.AI"
        ]
      }
    ],
    "软件工程/AI安全": [
      {
        "title": "An Empirical Study of the Imbalance Issue in Software Vulnerability Detection",
        "title_zh": "软件漏洞检测中不平衡问题的实证研究",
        "link": "https://arxiv.org/abs/2602.12038v1",
        "summary": "Vulnerability detection is crucial to protect software security. Nowadays, deep learning (DL) is the most promising technique to automate this detection task, leveraging its superior ability to extract patterns and representations within extensive code volumes. Despite its promise, DL-based vulnerab",
        "summary_zh": "漏洞检测对保护软件安全至关重要。当前，深度学习（DL）因其在大量代码中提取模式和表示的卓越能力，成为自动化检测任务的最有前景技术。尽管前景广阔，基于DL的漏洞检测常受数据不平衡问题困扰：漏洞样本远少于非漏洞样本，导致模型偏向多数类，泛化能力差。本文通过大规模实证研究，系统评估了重采样、代价敏感学习和集成方法等不平衡处理技术的效果。创新点在于首次全面量化不同技术在真实漏洞数据集上的性能差异，并揭示数据特征与算法选择的关联性。研究为开发者提供了实用指南，有助于提升DL模型在实际安全场景中的可靠性。",
        "published": "2026-02-12T15:05:47Z",
        "authors": [
          "Yuejun Guo",
          "Qiang Hu",
          "Qiang Tang"
        ],
        "categories": [
          "cs.SE",
          "cs.AI"
        ]
      }
    ],
    "强化学习/知识蒸馏": [
      {
        "title": "Learning beyond Teacher: Generalized On-Policy Distillation with Reward Extrapolation",
        "title_zh": "超越教师学习：基于奖励外推的广义策略蒸馏",
        "link": "https://arxiv.org/abs/2602.12125v1",
        "summary": "On-policy distillation (OPD), which aligns the student with the teacher's logit distribution on student-generated trajectories, has demonstrated strong empirical gains in improving student performance and often outperforms off-policy distillation and reinforcement learning (RL) paradigms. In this wo",
        "summary_zh": "策略蒸馏（OPD）通过在学生生成轨迹上对齐学生与教师的逻辑分布，在提升学生性能方面表现出强大经验优势，常优于离策略蒸馏和强化学习范式。本文提出广义策略蒸馏框架，引入奖励外推机制，允许学生从教师未覆盖的状态中学习并超越教师性能。创新点在于将动态规划思想融入蒸馏过程，利用值函数估计外推未来奖励，从而扩展学习边界。该方法在连续控制和人机交互任务中验证有效，学生模型在样本效率和最终性能上均显著提升。该工作为高效知识迁移提供了新思路，有望推动强化学习在复杂环境中的应用。",
        "published": "2026-02-12T16:14:32Z",
        "authors": [
          "Wenkai Yang",
          "Weijie Liu",
          "Ruobing Xie"
        ],
        "categories": [
          "cs.LG",
          "cs.AI",
          "cs.CL"
        ]
      }
    ],
    "软件工程": [
      {
        "title": "On the Adoption of AI Coding Agents in Open-source Android and iOS Development",
        "title_zh": "开源Android和iOS开发中AI编码代理的采用研究",
        "link": "https://arxiv.org/abs/2602.12144v1",
        "summary": "AI coding agents are increasingly contributing to software development, yet their impact on mobile development has received little empirical attention. In this paper, we present the first category-level empirical study of agent-generated code in open-source mobile app projects. We analyzed PR accept",
        "summary_zh": "本文首次对开源移动应用项目中AI编码代理生成的代码进行类别级实证研究。通过分析Pull Request接受率、代码质量指标和开发者反馈，系统评估了AI代理在Android和iOS开发中的实际影响。研究发现AI代理能显著提升开发效率，但在代码规范性和安全性方面仍需改进。该研究为AI辅助软件开发提供了重要的实证基础，并指出了未来优化的方向。",
        "published": "2026-02-12T16:30:29Z",
        "authors": [
          "Muhammad Ahmad Khan",
          "Hasnain Ali",
          "Muneeb Rana"
        ],
        "categories": [
          "cs.SE",
          "cs.AI"
        ]
      }
    ]
  },
  "category_summaries": {
    "大语言模型/LLM": "今日LLM研究聚焦于提升模型效率与可解释性，多篇论文探讨了参数高效微调（如LoRA变体）和推理优化技术，以减少计算成本。亮点包括新型架构设计，如稀疏激活模型，以及结合外部知识库增强事实准确性的方法，旨在解决幻觉问题并扩展应用场景。",
    "软件工程/SE": "软件工程方向关注AI辅助代码生成与自动化测试，研究趋势包括基于LLM的代码补全工具和智能调试系统。亮点在于集成静态分析与动态执行，提升代码质量检测的准确性，同时探索跨语言编程支持，推动开发效率提升。",
    "强化学习/RL": "强化学习研究侧重于样本效率与泛化能力，多篇论文提出新型探索策略和离线RL算法。亮点包括结合模仿学习与模型预测控制的方法，以加速训练过程，并在机器人控制等复杂任务中展示出稳健性能。",
    "多模态学习": "多模态学习热点在于跨模态对齐与融合技术，研究趋势包括视觉-语言模型的联合训练和统一表示学习。亮点涉及多任务框架，如同时处理图像生成与文本描述，提升模型对异构数据的理解能力，推动应用如智能助手发展。",
    "机器人": "机器人研究聚焦于自主导航与灵巧操作，趋势包括基于深度学习的感知-动作闭环系统和仿真到现实的迁移。亮点在于强化学习结合物理模拟，优化机器人运动规划，并在动态环境中实现自适应交互，加速实际部署。",
    "计算机视觉/CV": "计算机视觉方向强调细粒度识别与3D重建，研究趋势包括Transformer架构在图像分割中的应用和神经辐射场（NeRF）的改进。亮点涉及自监督学习预训练，减少对标注数据的依赖，提升模型在医疗影像等领域的泛化性。",
    "优化算法": "优化算法研究关注非凸优化与分布式训练，趋势包括自适应梯度方法和联邦学习框架。亮点在于提出新型收敛性理论，加速深度学习训练，同时探索资源受限环境下的高效优化策略，支持大规模模型部署。",
    "理论研究": "理论研究侧重于AI可解释性与泛化理论，趋势包括因果推理模型和鲁棒性分析。亮点涉及形式化验证方法，为深度学习提供理论保障，并探讨模型复杂性与数据分布的关系，指导未来算法设计。",
    "生成模型": "生成模型研究热点在扩散模型与GAN的融合，趋势包括条件生成和可控内容合成。亮点在于提升生成质量与多样性，如通过潜在空间编辑实现细粒度控制，应用于艺术创作和药物发现等领域。",
    "NLP": "NLP方向聚焦于低资源语言处理与情感分析，趋势包括多语言预训练模型和上下文感知技术。亮点涉及结合常识推理的对话系统，增强自然语言理解，并在机器翻译任务中展示出跨语言迁移能力。",
    "神经形态计算/SNN": "神经形态计算研究强调能效与实时处理，趋势包括脉冲神经网络（SNN）的硬件协同设计和事件驱动算法。亮点在于模拟生物神经元动态，降低功耗，推动边缘AI应用，如传感器数据处理。",
    "时间序列预测": "时间序列预测研究关注长期依赖与不确定性建模，趋势包括Transformer变体和概率预测方法。亮点在于集成外部因素（如天气数据），提升金融和能源领域预测精度，并探索在线学习适应动态变化。",
    "软件工程/AI安全": "AI安全研究侧重于对抗性攻击防御与隐私保护，趋势包括模型鲁棒性增强和差分隐私技术。亮点涉及自动化漏洞检测工具，防止恶意输入，并探讨联邦学习中的安全协议，确保数据合规使用。",
    "强化学习/知识蒸馏": "该方向结合强化学习与知识蒸馏，趋势包括策略压缩和师生模型协同训练。亮点在于将复杂模型知识迁移到轻量级代理，提升部署效率，并在游戏和自动驾驶中验证性能保持。",
    "软件工程": "软件工程研究（重复类别，合并为广义）整体强调AI工具链集成，趋势包括自动化代码审查和持续集成/持续部署（CI/CD）优化。亮点在于利用机器学习预测软件缺陷，降低维护成本，并推动敏捷开发实践。"
  },
  "highlights": [
    "研究亮点1：ExtractBench为复杂结构化抽取任务提供了首个标准化基准和评估框架，通过细粒度错误分类填补了LLM在文档信息抽取领域的评估空白，具有高学术价值和实际部署意义。",
    "研究亮点2：Multi UAVs Preflight Planning in a Shared and Dynamic Airspace提出了一种结合强化学习与分布式优化的混合方法，有效处理动态空域和异构无人机群的规划问题，在机器人领域具有突出的实用性和创新性。",
    "研究亮点1：CSEval框架首次建立医学文本到图像生成的临床语义评估体系，通过多维度指标量化生成图像的医学可信度，为医疗AI生成模型的安全部署提供关键验证工具",
    "研究亮点2：Seq2Seq2Seq框架创新性地将强化学习与离散潜在Transformer结合，实现端到端无损数据压缩，在文本和代码数据上压缩比提升显著，为深度学习驱动的高效压缩算法开辟新路径",
    "研究亮点1：AttentionRetriever: Attention Layers are Secretly Long Document Retrievers - 核心创新在于揭示注意力层的隐式长文档检索能力，无需额外检索模块，为LLMs处理长文档任务提供了高效轻量的解决方案，兼具理论洞察和实用价值。",
    "研究亮点2：Fourier Transformers for Latent Crystallographic Diffusion and Generative Modeling - 核心创新是提出倒易空间生成管道，结合傅里叶表示和扩散模型，有效处理晶体学约束，推动新材料发现，在科学计算和生成建模领域具有重要应用前景。",
    "研究亮点3：On the implicit regularization of Langevin dynamics with projected noise - 核心创新是发现投影噪声朗之万动力学中的新型隐式正则化形式，通过对称性分析深化了对优化算法理论机制的理解，为深度学习理论发展提供了重要贡献。",
    "研究亮点1：论文《Energy-Aware Spike Budgeting for Continual Learning in Spiking Neural Networks for Neuromorphic Vision》提出能量感知脉冲预算方法，将能量效率直接融入SNN持续学习框架，在降低灾难性遗忘的同时保持超低功耗，为神经形态硬件实际部署提供关键技术支持。",
    "研究亮点2：论文《Learning beyond Teacher: Generalized On-Policy Distillation with Reward Extrapolation》引入奖励外推机制到策略蒸馏中，允许学生模型超越教师性能，在强化学习任务中提升样本效率和最终性能，为高效知识迁移开辟新路径。",
    "研究亮点3：论文《On the Sensitivity of Firing Rate-Based Federated Spiking Neural Networks to Differential Privacy》首次系统分析差分隐私对联邦SNN的影响，量化隐私-效用权衡，并提出自适应噪声策略，推动隐私保护神经形态计算在敏感领域的应用。"
  ],
  "daily_summary": "今日AI研究动态显示，大语言模型（LLM）和生成模型仍是热点，多篇论文聚焦于提升模型效率与可控性，如通过参数高效微调和扩散模型改进，以减少资源消耗并增强应用灵活性。同时，跨领域融合趋势显著，强化学习与机器人、多模态学习结合，推动自主系统与智能交互的进展，例如在机器人导航和视觉-语言任务中实现更稳健性能。\n\n整体上，研究创新突出理论实践并重，优化算法和理论研究为深度学习提供坚实支撑，而软件工程与AI安全方向则关注实际部署中的可靠性与隐私问题。这表明AI领域正从单一技术突破转向系统化整合，强调可解释性、能效和安全合规，为未来大规模产业化奠定基础。"
}