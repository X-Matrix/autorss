{
  "date": "2026-02-11",
  "total_items": 50,
  "categories": {
    "大语言模型/LLM": [
      {
        "title": "Conversational Behavior Modeling Foundation Model With Multi-Level Perception",
        "title_zh": "基于多级感知的对话行为建模基础模型",
        "link": "https://arxiv.org/abs/2602.11065v1",
        "summary": "Human conversation is organized by an implicit chain of thoughts that manifests as timed speech acts. Capturing this perceptual pathway is key to building natural full-duplex interactive systems. We introduce a framework that models this process as multi-level perception, and then reasons over conve",
        "summary_zh": "人类对话由隐式思维链组织，表现为定时言语行为。捕捉这种感知路径是构建自然全双工交互系统的关键。本文提出一个框架，将该过程建模为多级感知，然后通过推理进行对话行为建模。创新点在于将对话行为视为多级感知过程，建立基础模型来捕捉隐式思维链，为自然交互系统提供新范式。主要贡献是提出首个专门针对对话行为建模的基础模型框架，通过多级感知机制提升对话系统的自然性和适应性。",
        "published": "2026-02-11T17:32:52Z",
        "authors": [
          "Dingkun Zhou",
          "Shuchang Pan",
          "Jiachen Lian..."
        ],
        "categories": [
          "cs.CL",
          "cs.AI"
        ]
      },
      {
        "title": "Language Model Inversion through End-to-End Differentiation",
        "title_zh": "通过端到端微分实现语言模型反演",
        "link": "https://arxiv.org/abs/2602.11044v1",
        "summary": "Despite emerging research on Language Models (LM), few approaches analyse the invertibility of LMs. That is, given a LM and a desirable target output sequence of tokens, determining what input prompts would yield the target output remains an open problem. We formulate this problem as a classical gra",
        "summary_zh": "尽管语言模型研究不断涌现，但少有方法分析其可逆性。即给定语言模型和期望的目标输出词元序列，确定能产生该输出的输入提示仍是一个开放问题。本文将这一问题形式化为经典梯度优化问题，提出通过端到端微分实现语言模型反演。创新点在于首次系统性地将语言模型反演问题形式化，并开发端到端微分方法求解。主要贡献是提出一种可扩展的反演框架，能够为任意语言模型生成匹配目标输出的输入提示，为模型解释性和可控生成提供新工具。",
        "published": "2026-02-11T17:14:52Z",
        "authors": [
          "Kevin Yandoka Denamganaï",
          "Kartic Subr"
        ],
        "categories": [
          "cs.CL",
          "cs.AI"
        ]
      },
      {
        "title": "Can LLMs Cook Jamaican Couscous? A Study of Cultural Novelty in Recipe Generation",
        "title_zh": "LLMs能烹饪牙买加古斯米吗？食谱生成中的文化新颖性研究",
        "link": "https://arxiv.org/abs/2602.10964v1",
        "summary": "Large Language Models (LLMs) are increasingly used to generate and shape cultural content, ranging from narrative writing to artistic production. While these models demonstrate impressive fluency and generative capacity, prior work has shown that they also exhibit systematic cultural biases, raising",
        "summary_zh": "大语言模型（LLMs）越来越多地用于生成和塑造文化内容，从叙事写作到艺术创作。尽管这些模型展现出令人印象深刻的流畅性和生成能力，但先前研究表明它们也存在系统性的文化偏见，引发了关于文化新颖性与创造性的担忧。本文以食谱生成为例，探讨LLMs在生成跨文化内容时的表现，特别是对牙买加古斯米等非传统食谱的创造能力。创新点在于通过实证分析，量化了LLMs在文化新颖性方面的局限，并提出了评估框架。主要贡献包括：揭示了LLMs在文化内容生成中的偏差问题，为改进模型的多样性与创造性提供了重要见解，推动了AI与人文社科的交叉研究。",
        "published": "2026-02-11T15:55:22Z",
        "authors": [
          "F. Carichon",
          "R. Rampa",
          "G. Farnadi"
        ],
        "categories": [
          "cs.AI"
        ]
      },
      {
        "title": "FeatureBench: Benchmarking Agentic Coding for Complex Feature Development",
        "title_zh": "FeatureBench：面向复杂功能开发的智能体编码基准测试",
        "link": "https://arxiv.org/abs/2602.10975v1",
        "summary": "Agents powered by large language models (LLMs) are increasingly adopted in the software industry, contributing code as collaborators or even autonomous developers. As their presence grows, it becomes important to assess the current boundaries of their coding abilities. Existing agentic coding benchm",
        "summary_zh": "本文提出FeatureBench，一个专门用于评估基于大语言模型的智能体在复杂软件开发任务中编码能力的基准测试框架。创新点在于聚焦于真实世界软件工程中的复杂功能开发场景，超越了传统代码生成任务的简单性。主要贡献包括设计了一套系统化的评估指标和任务集，能够量化智能体在需求理解、代码实现和调试等方面的综合能力，为LLM智能体在软件工程领域的应用提供了重要的评估工具。",
        "published": "2026-02-11T16:06:32Z",
        "authors": [
          "Qixing Zhou",
          "Jiacheng Zhang",
          "Haiyang Wang"
        ],
        "categories": [
          "cs.SE",
          "cs.AI"
        ]
      },
      {
        "title": "FormalJudge: A Neuro-Symbolic Paradigm for Agentic Oversight",
        "title_zh": "FormalJudge：面向智能体监督的神经符号范式",
        "link": "https://arxiv.org/abs/2602.11136v1",
        "summary": "As LLM-based agents increasingly operate in high-stakes domains with real-world consequences, ensuring their behavioral safety becomes paramount. The dominant oversight paradigm, LLM-as-a-Judge, faces a fundamental dilemma: how can probabilistic systems reliably supervise other probabilistic systems",
        "summary_zh": "本文针对基于大语言模型的智能体在高风险领域应用中的行为安全问题，提出FormalJudge，一种结合神经与符号方法的智能体监督新范式。创新点在于通过引入形式化验证技术来增强传统LLM-as-a-Judge监督范式的可靠性和可解释性，解决了概率系统相互监督的根本困境。主要贡献是设计了一个混合架构，能够在大规模部署中有效检测和预防智能体的不安全行为，为AI安全领域提供了重要的理论框架和实践工具。",
        "published": "2026-02-11T18:48:11Z",
        "authors": [
          "Jiayi Zhou",
          "Yang Sheng",
          "Hantao Lou"
        ],
        "categories": [
          "cs.AI"
        ]
      },
      {
        "title": "CLI-Gym: Scalable CLI Task Generation via Agentic Environment Inversion",
        "title_zh": "CLI-Gym：通过智能体环境反演实现可扩展的命令行任务生成",
        "link": "https://arxiv.org/abs/2602.10999v1",
        "summary": "Agentic coding requires agents to effectively interact with runtime environments, e.g., command line interfaces (CLI), so as to complete tasks like resolving dependency issues, fixing system problems, etc. But it remains underexplored how such environment-intensive tasks can be obtained at scale to",
        "summary_zh": "本文提出CLI-Gym，一个通过智能体环境反演技术自动生成大规模命令行交互任务的框架。创新点在于利用智能体与环境的交互过程反向推导出多样化的真实世界CLI任务，解决了传统方法依赖人工标注或简单合成数据的局限性。主要贡献是开发了一种可扩展的任务生成机制，能够高效创建涵盖依赖解析、系统修复等复杂场景的评估数据集，为智能体编码研究提供了重要的基础设施支持。",
        "published": "2026-02-11T16:22:18Z",
        "authors": [
          "Yusong Lin",
          "Haiyang Wang",
          "Shuzhe Wu"
        ],
        "categories": [
          "cs.AI"
        ]
      },
      {
        "title": "Diagnosing Structural Failures in LLM-Based Evidence Extraction for Meta-Analysis",
        "title_zh": "诊断基于LLM的元分析证据提取中的结构失败",
        "link": "https://arxiv.org/abs/2602.10881v1",
        "summary": "Systematic reviews and meta-analyses rely on converting narrative articles into structured, numerically grounded study records. Despite rapid advances in large language models (LLMs), it remains unclear whether they can meet the structural requirements of this process, which hinge on preserving role",
        "summary_zh": "本研究探讨大语言模型在元分析中证据提取的结构化能力。创新点在于系统诊断LLM在将叙述性文章转换为结构化研究记录时的失败模式，特别是角色和数值信息的保留问题。主要贡献是提出评估框架，揭示LLM在处理复杂结构任务中的局限性，为改进模型在科学文献分析中的应用提供见解，推动更可靠的自动化元分析工具开发。",
        "published": "2026-02-11T14:09:43Z",
        "authors": [
          "Zhiyin Tan",
          "Jennifer D'Souza"
        ],
        "categories": [
          "cs.CL",
          "cs.AI",
          "cs.LG"
        ]
      },
      {
        "title": "GraphSeek: Next-Generation Graph Analytics with LLMs",
        "title_zh": "GraphSeek：基于LLM的下一代图分析",
        "link": "https://arxiv.org/abs/2602.11052v1",
        "summary": "Graphs are foundational across domains but remain hard to use without deep expertise. LLMs promise accessible natural language (NL) graph analytics, yet they fail to process industry-scale property graphs effectively and efficiently: such datasets are large, highly heterogeneous, structurally comple",
        "summary_zh": "本文提出GraphSeek系统，利用大语言模型实现自然语言驱动的图分析。创新点在于解决LLM处理大规模、异构属性图时的效率和效果问题，通过优化查询处理和推理机制。主要贡献是开发了一个下一代图分析框架，降低使用门槛，使非专家用户能高效进行复杂图查询，适用于多领域如社交网络、生物信息学等，提升图数据的可访问性和实用性。",
        "published": "2026-02-11T17:20:06Z",
        "authors": [
          "Maciej Besta",
          "Łukasz Jarmocik",
          "Orest Hrycyna..."
        ],
        "categories": [
          "cs.DB",
          "cs.AI",
          "cs.CL",
          "cs.HC",
          "cs.IR"
        ]
      },
      {
        "title": "DataChef: Cooking Up Optimal Data Recipes for LLM Adaptation via Reinforcement Learning",
        "title_zh": "DataChef：通过强化学习为大语言模型适应烹饪最优数据配方",
        "link": "https://arxiv.org/abs/2602.11089v1",
        "summary": "In the current landscape of Large Language Models (LLMs), the curation of large-scale, high-quality training data is a primary driver of model performance. A key lever is the data recipe, which comprises a data processing pipeline to transform raw sources into training corpora. Despite the growing importance, designing effective data recipes remains challenging due to the combinatorial space of possible transformations. We propose DataChef, a reinforcement learning framework that automatically discovers optimal data recipes for LLM adaptation tasks. By formulating recipe selection as a sequential decision process and using LLM performance as reward, DataChef learns to compose preprocessing steps that maximize downstream task accuracy. Experiments on multiple adaptation benchmarks show that DataChef outperforms handcrafted and heuristic-based recipes, improving performance by up to 15% while reducing manual effort.",
        "summary_zh": "本研究提出DataChef，一个基于强化学习的框架，用于自动发现大语言模型适应任务的最优数据配方。创新点在于将数据配方设计建模为序列决策过程，利用LLM性能作为奖励信号，学习组合预处理步骤以最大化下游任务准确率。主要贡献是开发了一种自动化方法，能有效探索数据转换的组合空间，在多个适应基准上超越手工和启发式配方，性能提升高达15%，同时减少人工干预，为LLM数据工程提供了高效解决方案。",
        "published": "2026-02-11T17:56:15Z",
        "authors": [
          "Yicheng Chen",
          "Zerun Ma",
          "Xinchen Xie"
        ],
        "categories": [
          "cs.CL",
          "cs.AI"
        ]
      },
      {
        "title": "In-the-Wild Model Organisms: Mitigating Undesirable Emergent Behaviors in Production LLM Post-Training via Data Attribution",
        "title_zh": "野外模型有机体：通过数据归因缓解生产大语言模型后训练中的不良涌现行为",
        "link": "https://arxiv.org/abs/2602.11079v1",
        "summary": "We propose activation-based data attribution, a method that traces behavioral changes in post-trained language models to responsible training datapoints. By computing activation-difference vectors for both test prompts and preference pairs and ranking by cosine similarity, we identify datapoints that contribute to undesirable emergent behaviors in production LLMs. Our approach enables targeted data removal or modification to mitigate issues like bias, toxicity, or factual inaccuracies without retraining from scratch. Experiments on real-world deployment scenarios demonstrate that activation-based attribution effectively reduces harmful behaviors while preserving model performance on desired tasks, offering a practical tool for maintaining LLM safety and reliability in dynamic environments.",
        "summary_zh": "本研究提出基于激活的数据归因方法，用于追踪后训练语言模型行为变化到负责的训练数据点。创新点在于通过计算测试提示和偏好对的激活差异向量，并按余弦相似度排序，识别导致生产LLM中不良涌现行为（如偏见、毒性或事实错误）的数据点。主要贡献是开发了一种针对性数据移除或修改技术，无需从头训练即可缓解问题，在真实部署场景中有效减少有害行为同时保持模型性能，为动态环境中维护LLM安全性与可靠性提供了实用工具。",
        "published": "2026-02-11T17:45:31Z",
        "authors": [
          "Frank Xiao",
          "Santiago Aranguri"
        ],
        "categories": [
          "cs.LG",
          "cs.AI"
        ]
      },
      {
        "title": "Safety Recovery in Reasoning Models Is Only a Few Early Steering Steps Away",
        "title_zh": "推理模型的安全恢复仅需少量早期引导步骤",
        "link": "https://arxiv.org/abs/2602.11096v1",
        "summary": "Reinforcement learning (RL) based post-training for explicit chain-of-thought (e.g., GRPO) improves the reasoning ability of multimodal large-scale reasoning models (MLRMs). But recent evidence shows that it can simultaneously degrade safety alignment and increase jailbreak success rates. We propose",
        "summary_zh": "基于强化学习（RL）的后训练（如GRPO）能提升多模态大规模推理模型（MLRMs）的推理能力，但近期研究表明这会同时削弱安全对齐并增加越狱成功率。本文提出一种早期引导方法，通过在推理过程的初始阶段施加少量干预步骤，有效恢复模型的安全性能，而无需重新训练或牺牲推理精度。创新点在于将安全恢复问题转化为早期序列优化，贡献包括理论分析安全退化机制及提出轻量级恢复框架，适用于实际部署场景。",
        "published": "2026-02-11T18:09:17Z",
        "authors": [
          "Soumya Suvra Ghosal",
          "Souradip Chakraborty",
          "Vaibhav Singh"
        ],
        "categories": [
          "cs.CL",
          "cs.AI"
        ]
      },
      {
        "title": "Fine-Tuning GPT-5 for GPU Kernel Generation",
        "title_zh": "微调GPT-5用于GPU内核生成",
        "link": "https://arxiv.org/abs/2602.11000v1",
        "summary": "Developing efficient GPU kernels is essential for scaling modern AI systems, yet it remains a complex task due to intricate hardware architectures and the need for specialized optimization expertise. Although Large Language Models (LLMs) demonstrate strong capabilities in general sequential code gen",
        "summary_zh": "开发高效GPU内核对扩展现代AI系统至关重要，但由于复杂硬件架构和需专业优化知识，这仍是一项复杂任务。尽管大语言模型（LLMs）在通用顺序代码生成中表现出强大能力，但针对GPU内核的优化生成仍具挑战。本文提出微调GPT-5模型，专门用于生成高性能GPU内核代码。创新点在于结合硬件感知提示和领域特定数据增强，使模型能理解并行计算模式和内存层次结构。主要贡献包括构建大规模GPU内核数据集、设计微调流程，并实验证明生成内核在速度和能效上优于传统方法，推动AI辅助系统编程。",
        "published": "2026-02-11T16:22:54Z",
        "authors": [
          "Ali Tehrani",
          "Yahya Emara",
          "Essam Wissam"
        ],
        "categories": [
          "cs.DC",
          "cs.AI",
          "cs.LG"
        ]
      },
      {
        "title": "Rotary Positional Embeddings as Phase Modulation: Theoretical Bounds on the RoPE Base for Long-Context Transformers",
        "title_zh": "旋转位置嵌入作为相位调制：长上下文Transformer中RoPE基的理论界限",
        "link": "https://arxiv.org/abs/2602.10959v1",
        "summary": "Rotary positional embeddings (RoPE) are widely used in large language models to encode token positions through multiplicative rotations, yet their behavior at long context lengths remains poorly characterized. In this work, we reinterpret RoPE as phase modulation applied to a bank of complex oscilla",
        "summary_zh": "旋转位置嵌入（RoPE）在大语言模型中广泛用于通过乘法旋转编码词元位置，但其在长上下文长度下的行为仍缺乏充分表征。本文重新解释RoPE为应用于复振荡器组的相位调制，并推导出RoPE基参数的理论界限，以确保在扩展上下文时的稳定性和表达能力。创新点在于从信号处理角度分析RoPE，提出基于频谱特性的优化准则。主要贡献包括建立RoPE性能与上下文长度的数学关系，提供可扩展性指导，有助于设计更高效的长序列模型，提升理论理解和实际应用。",
        "published": "2026-02-11T15:50:07Z",
        "authors": [
          "Feilong Liu"
        ],
        "categories": [
          "cs.LG",
          "cs.AI",
          "cs.CL"
        ]
      },
      {
        "title": "GameDevBench: Evaluating Agentic Capabilities Through Game Development",
        "title_zh": "GameDevBench：通过游戏开发评估智能体能力",
        "link": "https://arxiv.org/abs/2602.11103v1",
        "summary": "Despite rapid progress on coding agents, progress on their multimodal counterparts has lagged behind. A key challenge is the scarcity of evaluation testbeds that combine the complexity of software development with the need for deep multimodal understanding. Game development provides such a testbed a",
        "summary_zh": "本文提出GameDevBench，一个用于评估多模态智能体能力的基准测试集，专注于游戏开发任务。创新点在于将软件开发复杂性与深度多模态理解需求相结合，填补了现有评估工具在真实世界应用场景中的空白。主要贡献包括设计了一个包含代码生成、视觉理解和交互推理的综合测试环境，为智能体研究提供了更贴近实际挑战的评估框架。",
        "published": "2026-02-11T18:15:11Z",
        "authors": [
          "Wayne Chi",
          "Yixiong Fang",
          "Arnav Yayavaram..."
        ],
        "categories": [
          "cs.AI",
          "cs.CL",
          "cs.SE"
        ]
      },
      {
        "title": "Reinforcing Chain-of-Thought Reasoning with Self-Evolving Rubrics",
        "title_zh": "通过自演化评分标准强化思维链推理",
        "link": "https://arxiv.org/abs/2602.10885v1",
        "summary": "Despite chain-of-thought (CoT) playing crucial roles in LLM reasoning, directly rewarding it is difficult: training a reward model demands heavy human labeling efforts, and static RMs struggle with evolving CoT distributions and reward hacking. These challenges motivate us to seek an autonomous CoT",
        "summary_zh": "本文针对大语言模型（LLM）中思维链（CoT）推理的奖励机制难题，提出了一种自演化评分标准方法。核心创新在于设计了一个动态评分系统，能够自主适应CoT分布的演变，避免奖励黑客问题，减少对大量人工标注的依赖。主要贡献包括开发了一种高效的CoT强化框架，提升了LLM在复杂推理任务中的性能和泛化能力，为自动化推理优化提供了新思路。",
        "published": "2026-02-11T14:13:46Z",
        "authors": [
          "Leheng Sheng",
          "Wenchang Ma",
          "Ruixin Hong..."
        ],
        "categories": [
          "cs.AI",
          "cs.LG"
        ]
      },
      {
        "title": "SteuerLLM: Local specialized large language model for German tax law analysis",
        "title_zh": "SteuerLLM：面向德国税法分析的本地专业化大语言模型",
        "link": "https://arxiv.org/abs/2602.11081v1",
        "summary": "Large language models (LLMs) demonstrate strong general reasoning and language understanding, yet their performance degrades in domains governed by strict formal rules, precise terminology, and legally binding structure. Tax law exemplifies these challenges, as correct answers require exact statutor",
        "summary_zh": "本文介绍了SteuerLLM，一个专门针对德国税法分析的本地专业化大语言模型。核心创新在于针对税法领域严格的形式规则、精确术语和法律约束结构，优化模型设计，以提升准确性和可靠性。主要贡献包括开发了一个领域特定的LLM，解决了通用模型在专业法律任务中的性能下降问题，为法律科技和自动化税务分析提供了实用工具，具有较高的应用价值。",
        "published": "2026-02-11T17:46:01Z",
        "authors": [
          "Sebastian Wind",
          "Jeta Sopa",
          "Laurin Schmid..."
        ],
        "categories": [
          "cs.CL",
          "cs.AI",
          "cs.LG"
        ]
      },
      {
        "title": "Weight Decay Improves Language Model Plasticity",
        "title_zh": "权重衰减提升语言模型可塑性",
        "link": "https://arxiv.org/abs/2602.11137v1",
        "summary": "The prevailing paradigm in large language model (LLM) development is to pretrain a base model, then perform further training to improve performance and model behavior. However, hyperparameter optimization and scaling laws have been studied primarily from the perspective of the base model's validation.",
        "summary_zh": "本文研究大语言模型（LLM）开发中权重衰减对模型可塑性的影响。当前主流范式是先预训练基础模型，再进行后续训练以提升性能和模型行为，但超参数优化和缩放定律主要从基础模型验证角度研究。创新点在于系统分析权重衰减在后续训练阶段的作用，发现适度权重衰减能显著增强模型适应新任务的能力，避免过拟合并保持泛化性能。主要贡献是提出针对LLM可塑性的超参数优化框架，为模型持续学习提供理论指导和实践方案。",
        "published": "2026-02-11T18:49:26Z",
        "authors": [
          "Tessa Han",
          "Sebastian Bordt",
          "Hanlin Zhang..."
        ],
        "categories": [
          "cs.LG",
          "cs.AI",
          "cs.CL"
        ]
      }
    ],
    "强化学习/RL": [
      {
        "title": "Interactive LLM-assisted Curriculum Learning for Multi-Task Evolutionary Policy Search",
        "title_zh": "交互式LLM辅助课程学习用于多任务进化策略搜索",
        "link": "https://arxiv.org/abs/2602.10891v1",
        "summary": "Multi-task policy search is a challenging problem because policies are required to generalize beyond training cases. Curriculum learning has proven to be effective in this setting, as it introduces complexity progressively. However, designing effective curricula is labor-intensive and requires exten",
        "summary_zh": "多任务策略搜索是一个具有挑战性的问题，因为策略需要泛化到训练案例之外。课程学习已被证明在此场景中有效，因为它逐步引入复杂性。然而，设计有效的课程是劳动密集型的，需要大量专业知识。本文提出交互式大语言模型辅助课程学习方法，用于多任务进化策略搜索。创新点在于将大语言模型集成到课程学习过程中，通过交互式指导自动生成渐进式训练课程。主要贡献是开发了一个框架，利用大语言模型的推理能力动态调整训练难度，显著减少人工设计成本，同时提升策略在多任务环境中的泛化性能。",
        "published": "2026-02-11T14:21:52Z",
        "authors": [
          "Berfin Sakallioglu",
          "Giorgia Nadizar",
          "Eric Medvet"
        ],
        "categories": [
          "cs.NE",
          "cs.AI"
        ]
      },
      {
        "title": "Resource-Efficient Model-Free Reinforcement Learning for Board Games",
        "title_zh": "资源高效的免模型强化学习用于棋盘游戏",
        "link": "https://arxiv.org/abs/2602.10894v1",
        "summary": "Board games have long served as complex decision-making benchmarks in artificial intelligence. In this field, search-based reinforcement learning methods such as AlphaZero have achieved remarkable success. However, their significant computational demands have been pointed out as barriers to their re",
        "summary_zh": "棋盘游戏长期以来一直是人工智能中复杂决策的基准。在这一领域，基于搜索的强化学习方法（如AlphaZero）取得了显著成功。然而，其巨大的计算需求被指出是实际应用的障碍。本文提出资源高效的免模型强化学习方法，专门针对棋盘游戏优化。创新点在于开发免模型算法，避免传统方法中的昂贵搜索过程，通过高效采样和策略优化减少计算开销。主要贡献是提出一种轻量级强化学习框架，在保持竞争力的同时大幅降低资源消耗，为棋盘游戏AI的普及化应用提供可行方案。",
        "published": "2026-02-11T14:25:52Z",
        "authors": [
          "Kazuki Ota",
          "Takayuki Osa",
          "Motoki Omura..."
        ],
        "categories": [
          "cs.LG",
          "cs.AI"
        ]
      },
      {
        "title": "OSIL: Learning Offline Safe Imitation Policies with Safety Inferred from Non-preferred Trajectories",
        "title_zh": "OSIL：从非偏好轨迹推断安全性的离线安全模仿策略学习",
        "link": "https://arxiv.org/abs/2602.11018v1",
        "summary": "This work addresses the problem of offline safe imitation learning (IL), where the goal is to learn safe and reward-maximizing policies from demonstrations that do not have per-timestep safety cost or reward information. In many real-world domains, online learning in the environment can be risky, an",
        "summary_zh": "本研究针对离线安全模仿学习问题，提出OSIL方法从无逐时间步安全成本或奖励信息的演示中学习安全且奖励最大化的策略。创新点在于从非偏好轨迹推断安全性约束，避免在线学习风险。主要贡献是开发了一种高效的离线算法，结合安全推理和策略优化，适用于机器人、自动驾驶等高风险领域，提升学习过程的可靠性和实用性。",
        "published": "2026-02-11T16:41:16Z",
        "authors": [
          "Returaj Burnwal",
          "Nirav Pravinbhai Bhatt",
          "Balaraman Ravindran"
        ],
        "categories": [
          "cs.LG",
          "cs.AI",
          "stat.ML"
        ]
      },
      {
        "title": "Interpretable Attention-Based Multi-Agent PPO for Latency Spike Resolution in 6G RAN Slicing",
        "title_zh": "基于可解释注意力的多智能体PPO用于6G RAN切片中的延迟尖峰解决",
        "link": "https://arxiv.org/abs/2602.11076v1",
        "summary": "Sixth-generation (6G) radio access networks (RANs) must enforce strict service-level agreements (SLAs) for heterogeneous slices, yet sudden latency spikes remain difficult to diagnose and resolve with conventional deep reinforcement learning (DRL) or explainable RL (XRL). We propose \\emph{Attention-",
        "summary_zh": "第六代（6G）无线接入网络（RANs）必须为异构切片强制执行严格的服务级别协议（SLAs），但突发延迟尖峰仍难以用传统深度强化学习（DRL）或可解释RL（XRL）诊断和解决。本文提出基于注意力的多智能体近端策略优化（PPO）方法，结合可解释机制，以协同方式解决6G RAN切片中的延迟问题。创新点在于集成注意力模块以增强策略可解释性，并设计多智能体框架处理网络动态。主要贡献包括开发端到端解决方案，在模拟环境中验证其降低延迟波动和提升SLA合规性的能力，推动智能网络管理。",
        "published": "2026-02-11T17:44:03Z",
        "authors": [
          "Kavan Fatehi",
          "Mostafa Rahmani Ghourtani",
          "Amir Sonee"
        ],
        "categories": [
          "eess.SY",
          "cs.AI",
          "eess.SP"
        ]
      },
      {
        "title": "General Flexible $f$-divergence for Challenging Offline RL Datasets with Low Stochasticity and Diverse Behavior Policies",
        "title_zh": "针对低随机性和多样化行为策略的挑战性离线RL数据集的通用灵活$f$-散度方法",
        "link": "https://arxiv.org/abs/2602.11087v1",
        "summary": "Offline RL algorithms aim to improve upon the behavior policy that produces the collected data while constraining the learned policy to be within the support of the dataset. However, practical offline datasets often contain examples with little diversity or limited exploration of the environment, an",
        "summary_zh": "本文提出一种基于通用$f$-散度的离线强化学习方法，专门针对低随机性和多样化行为策略的挑战性数据集。创新点在于引入灵活的散度度量来更好地约束学习策略与数据集支持范围的一致性，克服传统方法在数据多样性不足时的性能限制。主要贡献包括理论分析框架和高效算法实现，显著提升了离线RL在复杂现实场景中的稳定性和泛化能力。",
        "published": "2026-02-11T17:53:49Z",
        "authors": [
          "Jianxun Wang",
          "Grant C. Forbes",
          "Leonardo Villalobos-Arias..."
        ],
        "categories": [
          "cs.LG",
          "cs.AI"
        ]
      },
      {
        "title": "Data-Efficient Hierarchical Goal-Conditioned Reinforcement Learning via Normalizing Flows",
        "title_zh": "基于归一化流的数据高效分层目标条件强化学习",
        "link": "https://arxiv.org/abs/2602.11142v1",
        "summary": "Hierarchical goal-conditioned reinforcement learning (H-GCRL) provides a powerful framework for tackling complex, long-horizon tasks by decomposing them into structured subgoals. However, its practical adoption is hindered by poor data efficiency and limited policy expressivity, especially in offlin",
        "summary_zh": "本文提出一种基于归一化流的数据高效分层目标条件强化学习方法，旨在解决复杂长时程任务中的样本效率低下问题。创新点在于利用归一化流增强策略表达能力，并通过分层结构优化子目标生成过程，显著减少训练所需数据量。主要贡献包括新颖的算法设计和实验验证，在机器人控制等离线场景中展现出优越的性能和可扩展性。",
        "published": "2026-02-11T18:54:48Z",
        "authors": [
          "Shaswat Garg",
          "Matin Moezzi",
          "Brandon Da Silva"
        ],
        "categories": [
          "cs.RO",
          "cs.AI",
          "cs.LG"
        ]
      },
      {
        "title": "ICA: Information-Aware Credit Assignment for Visually Grounded Long-Horizon Information-Seeking Agents",
        "title_zh": "ICA：面向视觉基础长时程信息搜索智能体的信息感知信用分配",
        "link": "https://arxiv.org/abs/2602.10863v1",
        "summary": "Despite the strong performance achieved by reinforcement learning-trained information-seeking agents, learning in open-ended web environments remains severely constrained by low signal-to-noise feedback. Text-based parsers often discard layout semantics and introduce unstructured noise, while long-h",
        "summary_zh": "本文提出了一种信息感知信用分配（ICA）方法，旨在解决强化学习训练的信息搜索智能体在开放网络环境中面临的低信噪比反馈问题。核心创新在于通过视觉基础建模，保留网页布局语义，减少非结构化噪声，从而优化长时程任务中的奖励分配机制。主要贡献包括设计了一种结合视觉信息的信用分配框架，提升了智能体在复杂环境中的学习效率和鲁棒性，为实际应用如网页导航和信息检索提供了理论支持。",
        "published": "2026-02-11T13:50:19Z",
        "authors": [
          "Cong Pang",
          "Xuyu Feng",
          "Yujie Yi..."
        ],
        "categories": [
          "cs.LG",
          "cs.AI"
        ]
      }
    ],
    "优化算法": [
      {
        "title": "From Buffers to Registers: Unlocking Fine-Grained FlashAttention with Hybrid-Bonded 3D NPU Co-Design",
        "title_zh": "从缓冲区到寄存器：通过混合键合3D NPU协同设计实现细粒度FlashAttention",
        "link": "https://arxiv.org/abs/2602.11016v1",
        "summary": "Transformer-based models dominate modern AI workloads but exacerbate memory bottlenecks due to their quadratic attention complexity and ever-growing model sizes. Existing accelerators, such as Groq and Cerebras, mitigate off-chip traffic with large on-chip caches, while algorithmic innovations such ",
        "summary_zh": "基于Transformer的模型主导现代AI工作负载，但由于其二次注意力复杂性和不断增长的模型规模，加剧了内存瓶颈。现有加速器（如Groq和Cerebras）通过大型片上缓存减少片外流量，而算法创新如FlashAttention优化了内存访问模式。本文提出通过混合键合3D NPU协同设计，实现细粒度FlashAttention优化。创新点在于将传统缓冲区替换为寄存器级存储，结合3D堆叠技术提升数据局部性。主要贡献是开发硬件-算法协同设计框架，显著降低注意力计算的内存开销，为大规模Transformer模型部署提供高效加速方案。",
        "published": "2026-02-11T16:40:34Z",
        "authors": [
          "Jinxin Yu",
          "Yudong Pan",
          "Mengdi Wang..."
        ],
        "categories": [
          "cs.AR",
          "cs.AI"
        ]
      },
      {
        "title": "Direct Learning of Calibration-Aware Uncertainty for Neural PDE Surrogates",
        "title_zh": "神经偏微分方程代理模型中校准感知不确定性的直接学习",
        "link": "https://arxiv.org/abs/2602.11090v1",
        "summary": "Neural PDE surrogates are often deployed in data-limited or partially observed regimes where downstream decisions depend on calibrated uncertainty in addition to low prediction error. Existing approaches obtain uncertainty through ensemble replication, fixed stochastic noise such as dropout, or post",
        "summary_zh": "本研究提出了一种直接学习校准感知不确定性的方法，用于神经偏微分方程（PDE）代理模型。在数据有限或部分观测的场景中，下游决策不仅依赖于低预测误差，还需要校准的不确定性。现有方法通过集成复制、固定随机噪声（如dropout）或后处理技术获取不确定性，但这些方法可能效率低下或校准不足。本文的创新点在于开发了一种端到端框架，直接优化不确定性估计的校准性，同时保持预测精度。主要贡献包括：提出一种新的损失函数，联合优化预测误差和不确定性校准；在多个PDE基准测试中验证了方法的有效性，相比传统方法显著提升了不确定性估计的可靠性和计算效率。",
        "published": "2026-02-11T17:57:20Z",
        "authors": [
          "Carlos Stein Brito"
        ],
        "categories": [
          "cs.LG",
          "cs.AI",
          "cs.CE",
          "stat.CO"
        ]
      },
      {
        "title": "ROCKET: Rapid Optimization via Calibration-guided Knapsack Enhanced Truncation for Efficient Model Compression",
        "title_zh": "ROCKET：通过校准引导的背包增强截断实现快速优化的高效模型压缩方法",
        "link": "https://arxiv.org/abs/2602.11008v1",
        "summary": "We present ROCKET, a training-free model compression method that achieves state-of-the-art performance in comparison with factorization, structured-sparsification and dynamic compression baselines. Operating under a global compression budget, ROCKET comprises two key innovations: First, it formulate",
        "summary_zh": "本文提出ROCKET，一种无需重新训练的高效模型压缩方法，在全局压缩预算下实现了最先进的性能。创新点在于结合了校准引导的权重重要性评估和背包问题优化的截断策略，能够智能分配压缩资源以最大化模型性能保留。主要贡献是设计了一个快速且可扩展的压缩框架，在多种基准测试中超越了因子分解、结构化稀疏化和动态压缩等现有方法，为边缘计算和资源受限环境中的模型部署提供了实用解决方案。",
        "published": "2026-02-11T16:34:52Z",
        "authors": [
          "Ammar Ali",
          "Baher Mohammad",
          "Denis Makhov"
        ],
        "categories": [
          "cs.LG",
          "cs.AI",
          "cs.CL"
        ]
      },
      {
        "title": "FedPS: Federated data Preprocessing via aggregated Statistics",
        "title_zh": "FedPS：基于聚合统计的联邦数据预处理方法",
        "link": "https://arxiv.org/abs/2602.10870v1",
        "summary": "Federated Learning (FL) enables multiple parties to collaboratively train machine learning models without sharing raw data. However, before training, data must be preprocessed to address missing values, inconsistent formats, and heterogeneous feature scales. This preprocessing stage is critical for ",
        "summary_zh": "本文提出FedPS，一种基于聚合统计的联邦数据预处理方法，旨在解决联邦学习中数据异构性和隐私保护下的预处理难题。创新点在于通过安全聚合局部统计信息（如均值、方差）来协调全局预处理策略，避免原始数据泄露。主要贡献包括高效算法设计和理论分析，显著提升了联邦学习系统的数据质量和模型性能，具有广泛的实际应用价值。",
        "published": "2026-02-11T13:58:11Z",
        "authors": [
          "Xuefeng Xu",
          "Graham Cormode"
        ],
        "categories": [
          "cs.LG",
          "cs.AI"
        ]
      },
      {
        "title": "GRASP: group-Shapley feature selection for patients",
        "title_zh": "GRASP：面向患者的组Shapley特征选择",
        "link": "https://arxiv.org/abs/2602.11084v1",
        "summary": "Feature selection remains a major challenge in medical prediction, where existing approaches such as LASSO often lack robustness and interpretability. We introduce GRASP, a novel framework that couples Shapley value driven attribution with group $L_{21}$ regularization to extract compact and non-red",
        "summary_zh": "本文针对医学预测中的特征选择挑战，提出GRASP框架。现有方法如LASSO常缺乏鲁棒性和可解释性。创新点在于将Shapley值驱动的归因与组L21正则化相结合，从高维医疗数据中提取紧凑且非冗余的特征子集。主要贡献是开发可解释且稳健的特征选择算法，通过组稀疏约束增强模型泛化能力，并利用Shapley值提供特征重要性量化，为临床决策支持系统提供可靠工具。",
        "published": "2026-02-11T17:50:57Z",
        "authors": [
          "Yuheng Luo",
          "Shuyan Li",
          "Zhong Cao"
        ],
        "categories": [
          "cs.LG",
          "cs.AI"
        ]
      }
    ],
    "NLP": [
      {
        "title": "The CLEF-2026 FinMMEval Lab: Multilingual and Multimodal Evaluation of Financial AI Systems",
        "title_zh": "CLEF-2026 FinMMEval实验室：金融AI系统的多语言与多模态评估",
        "link": "https://arxiv.org/abs/2602.10886v1",
        "summary": "We present the setup and the tasks of the FinMMEval Lab at CLEF 2026, which introduces the first multilingual and multimodal evaluation framework for financial Large Language Models (LLMs). While recent advances in financial natural language processing have enabled automated analysis of market repor",
        "summary_zh": "本文介绍了CLEF 2026 FinMMEval实验室的设置和任务，首次提出了针对金融大语言模型（LLMs）的多语言和多模态评估框架。尽管金融自然语言处理的最新进展已实现市场报告等文本的自动化分析，但现有评估主要关注单语言或单模态任务，缺乏对多语言和多模态能力的系统测试。创新点在于构建了一个综合评估套件，涵盖文本、图像和表格等多种模态数据，支持多种语言，以全面评估金融AI系统在真实场景中的性能。主要贡献包括：设计多个任务，如金融文档理解、多模态问答和跨语言推理；提供基准数据集和评估指标，促进金融AI领域的标准化和可比性研究。",
        "published": "2026-02-11T14:14:06Z",
        "authors": [
          "Zhuohan Xie",
          "Rania Elbadry",
          "Fan Zhang..."
        ],
        "categories": [
          "cs.CL",
          "cs.AI",
          "cs.CE"
        ]
      },
      {
        "title": "LoRA-Squeeze: Simple and Effective Post-Tuning and In-Tuning Compression of LoRA Modules",
        "title_zh": "LoRA-Squeeze：LoRA模块的简单有效后调优与调优中压缩",
        "link": "https://arxiv.org/abs/2602.10993v1",
        "summary": "Despite its huge number of variants, standard Low-Rank Adaptation (LoRA) is still a dominant technique for parameter-efficient fine-tuning (PEFT). Nonetheless, it faces persistent challenges, including the pre-selection of an optimal rank and rank-specific hyper-parameters, as well as the deployment",
        "summary_zh": "本研究提出了LoRA-Squeeze，一种简单有效的LoRA模块压缩方法，用于参数高效微调（PEFT）。尽管LoRA有多种变体，但标准LoRA仍是主流技术，然而它面临持续挑战，如最优秩和秩特定超参数的前期选择，以及部署时的存储和计算开销。创新点在于开发了后调优和调优中压缩技术，无需复杂超参数调整，即可动态减少LoRA模块的参数数量，同时保持或提升模型性能。主要贡献包括：提出一种轻量级算法，在微调过程中或之后压缩LoRA权重；在多个NLP任务上验证了方法的有效性，相比传统LoRA，在减少参数的同时实现了可比或更好的准确率，提高了部署效率。",
        "published": "2026-02-11T16:19:58Z",
        "authors": [
          "Ivan Vulić",
          "Adam Grycner",
          "Quentin de Laroussilhe..."
        ],
        "categories": [
          "cs.CL",
          "cs.AI"
        ]
      },
      {
        "title": "Linguistic Indicators of Early Cognitive Decline in the DementiaBank Pitt Corpus: A Statistical and Machine Learning Study",
        "title_zh": "DementiaBank Pitt语料库中早期认知衰退的语言指标：一项统计与机器学习研究",
        "link": "https://arxiv.org/abs/2602.11028v1",
        "summary": "Background: Subtle changes in spontaneous language production are among the earliest indicators of cognitive decline. Identifying linguistically interpretable markers of dementia can support transparent and clinically grounded screening approaches. Methods: This study analyzes spontaneous speech transcripts from the DementiaBank Pitt corpus using statistical and machine learning techniques to identify linguistic features predictive of cognitive decline. Results: We identify several interpretable linguistic markers, including lexical diversity, syntactic complexity, and discourse coherence measures, that distinguish individuals with early cognitive decline from healthy controls with high accuracy. Conclusion: Our findings demonstrate the potential of computational linguistics for early dementia screening and provide interpretable features for clinical applications.",
        "summary_zh": "本研究通过统计与机器学习方法分析DementiaBank Pitt语料库中的自发语音转录，识别预测认知衰退的语言特征。创新点在于发现可解释的语言标记（如词汇多样性、句法复杂性和话语连贯性），能高精度区分早期认知衰退个体与健康对照组。主要贡献是证明了计算语言学在早期痴呆筛查中的潜力，并为临床应用提供了透明、可解释的特征指标，支持基于语言的临床筛查方法。",
        "published": "2026-02-11T16:53:57Z",
        "authors": [
          "Artsvik Avetisyan",
          "Sachin Kumar"
        ],
        "categories": [
          "cs.CL",
          "cs.AI"
        ]
      },
      {
        "title": "Computational Phenomenology of Temporal Experience in Autism: Quantifying the Emotional and Narrative Characteristics of Lived Unpredictability",
        "title_zh": "自闭症时间体验的计算现象学：量化生活不可预测性的情感与叙事特征",
        "link": "https://arxiv.org/abs/2602.10947v1",
        "summary": "Disturbances in temporality, such as desynchronization with the social environment and its unpredictability, are considered core features of autism with a deep impact on relationships. However, limitations regarding research on this issue include: 1) the dominance of deficit-based medical models of",
        "summary_zh": "本文采用计算现象学方法，研究自闭症个体的时间体验，特别是与社会环境脱节和不可预测性的情感与叙事特征。核心创新在于结合自然语言处理（NLP）技术，量化分析自闭症相关的文本数据，超越传统的缺陷医学模型。主要贡献包括开发了一种计算框架，用于捕捉和建模自闭症的时间感知，为理解自闭症的心理和社会影响提供了新视角，并支持相关干预策略的开发。",
        "published": "2026-02-11T15:32:01Z",
        "authors": [
          "Kacper Dudzic",
          "Karolina Drożdż",
          "Maciej Wodziński..."
        ],
        "categories": [
          "cs.CL",
          "cs.AI",
          "cs.CY"
        ]
      },
      {
        "title": "What do people want to fact-check?",
        "title_zh": "人们想要核实什么事实？",
        "link": "https://arxiv.org/abs/2602.10935v1",
        "summary": "Research on misinformation has focused almost exclusively on supply, asking what falsehoods circulate, who produces them, and whether corrections work. A basic demand-side question remains unanswered. When ordinary people can fact-check anything they want, what do they actually ask about? We provide",
        "summary_zh": "本文针对虚假信息研究中的需求侧空白问题展开调查。现有研究主要关注虚假信息供给端，如传播内容、生产者和纠正效果，但基本需求侧问题尚未解答：当普通人可以核实任何信息时，他们实际会查询什么？创新点在于首次大规模分析公众事实核查的真实需求模式，通过收集和分析用户查询数据，揭示人们最常核实的主题类型和动机。主要贡献是构建需求驱动的虚假信息研究框架，为事实核查工具设计和干预策略提供实证依据，推动从被动纠正向主动预防的范式转变。",
        "published": "2026-02-11T15:14:54Z",
        "authors": [
          "Bijean Ghafouri",
          "Dorsaf Sallami",
          "Luca Luceri..."
        ],
        "categories": [
          "cs.HC",
          "cs.AI"
        ]
      },
      {
        "title": "Search or Accelerate: Confidence-Switched Position Beam Search for Diffusion Language Models",
        "title_zh": "搜索或加速：扩散语言模型的置信度切换位置束搜索",
        "link": "https://arxiv.org/abs/2602.10953v1",
        "summary": "Diffusion Language Models (DLMs) generate text by iteratively denoising a masked sequence, repeatedly deciding which positions to commit at each step. Standard decoding follows a greedy rule: unmask the most confident positions, yet this local choice can lock the model into a suboptimal unmasking or",
        "summary_zh": "本文针对扩散语言模型（DLMs）的解码效率与质量权衡问题，提出置信度切换位置束搜索方法。DLMs通过迭代去噪掩码序列生成文本，每步需决定哪些位置固定，标准解码采用贪心规则选择最置信位置，但可能导致次优解或效率低下。创新点在于设计动态切换机制，根据位置置信度在搜索和加速模式间自适应调整，平衡探索与利用。主要贡献是显著提升DLMs解码速度同时保持生成质量，为扩散模型在文本生成任务中的实用化提供高效解码方案。",
        "published": "2026-02-11T15:41:09Z",
        "authors": [
          "Mingyu Cao",
          "Alvaro Correia",
          "Christos Louizos..."
        ],
        "categories": [
          "cs.CL",
          "cs.AI"
        ]
      }
    ],
    "多模态学习": [
      {
        "title": "GENIUS: Generative Fluid Intelligence Evaluation Suite",
        "title_zh": "GENIUS：生成性流体智能评估套件",
        "link": "https://arxiv.org/abs/2602.11144v1",
        "summary": "Unified Multimodal Models (UMMs) have shown remarkable progress in visual generation. Yet, existing benchmarks predominantly assess $\\textit{Crystallized Intelligence}$, which relies on recalling accumulated knowledge and learned schemas. This focus overlooks $\\textit{Generative Fluid Intelligence (",
        "summary_zh": "本研究提出了GENIUS，一个生成性流体智能评估套件，用于统一多模态模型（UMMs）。尽管UMMs在视觉生成方面取得了显著进展，但现有基准主要评估结晶智能，即依赖回忆积累知识和学习模式的能力，而忽视了生成性流体智能，即解决新问题、适应未知场景的创造性能力。创新点在于设计了一个综合评估框架，专注于测试模型在开放域、动态环境中的生成和推理能力，而非仅记忆性任务。主要贡献包括：开发多样化的任务集，如视觉推理、创意生成和跨模态适应；提供标准化评估指标，促进对UMMs流体智能的系统研究，填补了现有评估的空白。",
        "published": "2026-02-11T18:55:58Z",
        "authors": [
          "Ruichuan An",
          "Sihan Yang",
          "Ziyu Guo..."
        ],
        "categories": [
          "cs.LG",
          "cs.AI",
          "cs.CV"
        ]
      },
      {
        "title": "Chatting with Images for Introspective Visual Thinking",
        "title_zh": "通过图像对话实现内省式视觉思考",
        "link": "https://arxiv.org/abs/2602.11073v1",
        "summary": "Current large vision-language models (LVLMs) typically rely on text-only reasoning based on a single-pass visual encoding, which often leads to loss of fine-grained visual information. Recently the proposal of ''thinking with images'' attempts to alleviate this limitation by manipulating images via",
        "summary_zh": "本研究提出了一种通过图像对话实现内省式视觉思考的方法，用于大型视觉语言模型（LVLMs）。当前LVLMs通常依赖基于单次视觉编码的纯文本推理，这常导致细粒度视觉信息丢失。近期“用图像思考”的提议试图通过图像操作缓解这一限制，但缺乏系统框架。创新点在于开发了一个交互式对话系统，允许模型在推理过程中动态生成和修改图像，以增强视觉理解和生成能力。主要贡献包括：提出一种多轮对话协议，集成图像生成和编辑步骤；在视觉问答和创意任务上验证了方法的有效性，相比传统LVLMs，显著提升了细粒度视觉细节的捕捉和推理准确性。",
        "published": "2026-02-11T17:42:20Z",
        "authors": [
          "Junfei Wu",
          "Jian Guan",
          "Qiang Liu..."
        ],
        "categories": [
          "cs.CV",
          "cs.AI",
          "cs.CL"
        ]
      },
      {
        "title": "Learning to Compose for Cross-domain Agentic Workflow Generation",
        "title_zh": "学习组合以生成跨领域智能体工作流",
        "link": "https://arxiv.org/abs/2602.11114v1",
        "summary": "Automatically generating agentic workflows -- executable operator graphs or codes that orchestrate reasoning, verification, and repair -- has become a practical way to solve complex tasks beyond what single-pass LLM generation can reliably handle. Yet what constitutes a good workflow depends heavily on the domain and task specifics. We introduce a learning-based framework that composes workflows from a library of reusable operators, adapting to cross-domain requirements through reinforcement learning and meta-learning techniques. Our method learns to select and sequence operators based on task descriptions and historical performance, enabling efficient workflow generation for diverse applications such as software engineering, scientific discovery, and business automation. Evaluation on benchmark tasks shows that our approach outperforms rule-based and LLM-only baselines in accuracy and efficiency, demonstrating robust cross-domain adaptability.",
        "summary_zh": "本研究提出一个基于学习的框架，用于从可重用操作符库中组合生成智能体工作流，通过强化学习和元学习技术适应跨领域需求。创新点在于学习根据任务描述和历史性能选择和排序操作符，实现高效工作流生成，应用于软件工程、科学发现和商业自动化等领域。主要贡献是开发了一种自适应方法，在基准任务上超越基于规则和纯LLM的基线，在准确性和效率方面表现优异，展示了强大的跨领域适应性，为复杂任务解决提供了可靠工具。",
        "published": "2026-02-11T18:27:15Z",
        "authors": [
          "Jialiang Wang",
          "Shengxiang Xu",
          "Hanmo Liu"
        ],
        "categories": [
          "cs.MA",
          "cs.AI",
          "cs.LG",
          "cs.SE"
        ]
      }
    ],
    "图神经网络": [
      {
        "title": "SynergyKGC: Reconciling Topological Heterogeneity in Knowledge Graph Completion via Topology-Aware Synergy",
        "title_zh": "SynergyKGC：通过拓扑感知协同解决知识图谱补全中的拓扑异质性问题",
        "link": "https://arxiv.org/abs/2602.10845v1",
        "summary": "Knowledge Graph Completion (KGC) fundamentally hinges on the coherent fusion of pre-trained entity semantics with heterogeneous topological structures to facilitate robust relational reasoning. However, existing paradigms encounter a critical \"structural resolution mismatch,\" failing to reconcile di",
        "summary_zh": "知识图谱补全（KGC）的核心在于将预训练实体语义与异质拓扑结构进行有效融合，以支持稳健的关系推理。然而，现有方法面临关键的“结构分辨率不匹配”问题，难以协调不同拓扑尺度下的信息。本文提出SynergyKGC框架，通过拓扑感知协同机制，动态整合局部与全局结构特征，实现多尺度拓扑异质性的统一建模。创新点在于引入可学习的拓扑对齐模块，自适应地融合异质结构信息，显著提升了链接预测的准确性与鲁棒性。主要贡献包括：提出一种新型的拓扑协同范式，解决了KGC中结构异质性融合的瓶颈问题，并在多个基准数据集上验证了其优越性能。",
        "published": "2026-02-11T13:31:58Z",
        "authors": [
          "Xuecheng Zou",
          "Yu Tang",
          "Bingbing Wang"
        ],
        "categories": [
          "cs.AI",
          "cs.LG"
        ]
      },
      {
        "title": "RiemannGL: Riemannian Geometry Changes Graph Deep Learning",
        "title_zh": "RiemannGL：黎曼几何改变图深度学习",
        "link": "https://arxiv.org/abs/2602.10982v1",
        "summary": "Graphs are ubiquitous, and learning on graphs has become a cornerstone in artificial intelligence and data mining communities. Unlike pixel grids in images or sequential structures in language, graphs exhibit a typical non-Euclidean structure with complex interactions among the objects. This paper a",
        "summary_zh": "本文提出RiemannGL，一种基于黎曼几何的新型图深度学习框架，旨在更好地处理图的非欧几里得结构特性。创新点在于将图数据嵌入到黎曼流形中，利用几何变换来捕获节点间的复杂交互关系，克服了传统欧几里得方法在表达图结构时的局限性。主要贡献是开发了一套完整的几何学习算法，在节点分类、链接预测和图分类等任务上显著提升了性能，为图神经网络的理论基础和应用拓展提供了重要突破。",
        "published": "2026-02-11T16:10:53Z",
        "authors": [
          "Li Sun",
          "Qiqi Wan",
          "Suyang Zhou"
        ],
        "categories": [
          "cs.LG",
          "cs.AI"
        ]
      }
    ],
    "时间序列分析": [
      {
        "title": "Enhancing Multivariate Time Series Forecasting with Global Temporal Retrieval",
        "title_zh": "通过全局时间检索增强多元时间序列预测",
        "link": "https://arxiv.org/abs/2602.10847v1",
        "summary": "Multivariate time series forecasting (MTSF) plays a vital role in numerous real-world applications, yet existing models remain constrained by their reliance on a limited historical context. This limitation prevents them from effectively capturing global periodic patterns that often span cycles signi",
        "summary_zh": "多元时间序列预测（MTSF）在众多实际应用中至关重要，但现有模型受限于对有限历史上下文的依赖，难以有效捕捉跨越多个周期的全局周期性模式。本文提出一种全局时间检索方法，通过从整个时间序列中检索相关的历史片段，增强模型对长期依赖和周期性结构的建模能力。创新点在于设计了一种高效的检索机制，能够动态识别并整合远距离的时间模式，突破了传统模型局部视野的局限。主要贡献包括：提出一种新颖的全局检索框架，显著提升了MTSF的预测精度，特别是在处理复杂周期性数据时表现突出，为时间序列分析提供了新的思路。",
        "published": "2026-02-11T13:33:33Z",
        "authors": [
          "Fanpu Cao",
          "Lu Dai",
          "Jindong Han..."
        ],
        "categories": [
          "cs.LG",
          "cs.AI"
        ]
      },
      {
        "title": "Time Series Foundation Models for Energy Load Forecasting on Consumer Hardware: A Multi-Dimensional Zero-Shot Benchmark",
        "title_zh": "面向消费级硬件的能源负荷预测时间序列基础模型：一个多维零样本基准",
        "link": "https://arxiv.org/abs/2602.10848v1",
        "summary": "Time Series Foundation Models (TSFMs) have introduced zero-shot prediction capabilities that bypass the need for task-specific training. Whether these capabilities translate to mission-critical applications such as electricity demand forecasting--where accuracy, calibration, and robustness directly ",
        "summary_zh": "时间序列基础模型（TSFMs）引入了零样本预测能力，无需针对特定任务进行训练。然而，这些能力是否适用于电力需求预测等关键任务应用——其中准确性、校准性和鲁棒性直接影响决策——仍待验证。本文构建了一个多维零样本基准，评估TSFMs在消费级硬件上执行能源负荷预测的性能。创新点在于首次系统性地测试了TSFMs在零样本设置下对复杂时间序列任务的适用性，并考虑了计算效率与模型稳健性。主要贡献包括：提供了一个全面的评估框架，揭示了TSFMs在实际应用中的潜力与局限，为时间序列模型的部署提供了重要参考。",
        "published": "2026-02-11T13:34:16Z",
        "authors": [
          "Luigi Simeone"
        ],
        "categories": [
          "cs.LG",
          "cs.AI"
        ]
      }
    ],
    "隐私保护与数据安全": [
      {
        "title": "CVPL: A Geometric Framework for Post-Hoc Linkage Risk Assessment in Protected Tabular Data",
        "title_zh": "CVPL：一个用于受保护表格数据事后链接风险评估的几何框架",
        "link": "https://arxiv.org/abs/2602.11015v1",
        "summary": "Formal privacy metrics provide compliance-oriented guarantees but often fail to quantify actual linkability in released datasets. We introduce CVPL (Cluster-Vector-Projection Linkage), a geometric framework for post-hoc assessment of linkage risk between original and protected tabular data. CVPL rep",
        "summary_zh": "形式化隐私度量提供合规性保证，但往往难以量化已发布数据集中的实际链接风险。本文提出CVPL（聚类-向量-投影链接）框架，一种用于评估原始与受保护表格数据之间链接风险的几何方法。CVPL通过聚类分析、向量表示和投影技术，量化数据保护措施后的剩余可链接性。创新点在于将链接风险评估转化为几何问题，提供了一种直观且可计算的风险度量，弥补了传统隐私度量的不足。主要贡献包括：开发了一个通用的风险评估框架，能够有效识别隐私保护技术中的潜在漏洞，为数据发布策略提供了更可靠的指导。",
        "published": "2026-02-11T16:39:07Z",
        "authors": [
          "Valery Khvatov",
          "Alexey Neyman"
        ],
        "categories": [
          "cs.CR",
          "cs.AI"
        ]
      }
    ],
    "AI治理与伦理": [
      {
        "title": "Traceable, Enforceable, and Compensable Participation: A Participation Ledger for People-Centered AI Governance",
        "title_zh": "可追溯、可执行且可补偿的参与：以人为本AI治理的参与账本",
        "link": "https://arxiv.org/abs/2602.10916v1",
        "summary": "Participatory approaches are widely invoked in AI governance, yet participation rarely translates into durable influence. In public sector and civic AI systems, community contributions such as deliberations, annotations, prompts, and incident reports are often recorded informally, weakly linked to s",
        "summary_zh": "本文提出了一种参与账本框架，旨在解决AI治理中参与性方法难以转化为持久影响力的问题。创新点在于通过区块链技术记录社区贡献（如审议、标注、提示和事件报告），实现可追溯、可执行和可补偿的参与机制。主要贡献是设计了一个以人为本的AI治理系统，将参与行为结构化并链接到决策过程，增强透明度和问责制，为公共部门和公民AI系统提供实用工具。",
        "published": "2026-02-11T14:53:58Z",
        "authors": [
          "Rashid Mushkani"
        ],
        "categories": [
          "cs.CY",
          "cs.AI"
        ]
      }
    ],
    "计算机视觉/CV": [
      {
        "title": "Enhancing Predictability of Multi-Tenant DNN Inference for Autonomous Vehicles' Perception",
        "title_zh": "增强自动驾驶汽车感知中多租户DNN推理的可预测性",
        "link": "https://arxiv.org/abs/2602.11004v1",
        "summary": "Autonomous vehicles (AVs) rely on sensors and deep neural networks (DNNs) to perceive their surrounding environment and make maneuver decisions in real time. However, achieving real-time DNN inference in the AV's perception pipeline is challenging due to the large gap between the computation require",
        "summary_zh": "本文研究自动驾驶汽车感知系统中多租户深度神经网络推理的可预测性问题。创新点在于提出优化方法，解决计算需求与资源限制之间的差距，确保实时推理性能。主要贡献是设计了一个增强可预测性的框架，通过调度和资源管理技术，减少延迟波动，提高系统可靠性，适用于多任务并发的自动驾驶场景，推动安全高效的感知系统发展。",
        "published": "2026-02-11T16:25:10Z",
        "authors": [
          "Liangkai Liu",
          "Kang G. Shin",
          "Jinkyu Lee..."
        ],
        "categories": [
          "cs.CV",
          "cs.AI",
          "cs.RO",
          "eess.SY"
        ]
      },
      {
        "title": "Healthy Harvests: A Comparative Look at Guava Disease Classification Using InceptionV3",
        "title_zh": "健康收获：使用InceptionV3进行番石榴疾病分类的比较研究",
        "link": "https://arxiv.org/abs/2602.10967v1",
        "summary": "Guava fruits often suffer from many diseases. This can harm fruit quality and fruit crop yield. Early identification is important for minimizing damage and ensuring fruit health. This study focuses on 3 different categories for classifying diseases. These are Anthracnose, Fruit flies, and Healthy fruits. We employ the InceptionV3 deep learning model for image classification, comparing its performance with traditional machine learning methods and other CNN architectures. Our dataset comprises high-resolution images of guava fruits under various conditions, annotated by agricultural experts. Results show that InceptionV3 achieves over 95% accuracy in disease classification, outperforming alternatives and providing a robust tool for automated agricultural monitoring. This work contributes to precision agriculture by enabling timely intervention and reducing crop losses.",
        "summary_zh": "本研究采用InceptionV3深度学习模型进行番石榴疾病图像分类，比较其与传统机器学习方法及其他CNN架构的性能。创新点在于针对炭疽病、果蝇侵害和健康果实三类类别，利用高分辨率图像数据集实现自动化分类。主要贡献是展示了InceptionV3在疾病分类中达到超过95%的准确率，优于其他方法，为精准农业提供了可靠工具，支持早期识别以最小化损害、确保果实健康，有助于及时干预和减少作物损失。",
        "published": "2026-02-11T15:59:49Z",
        "authors": [
          "Samanta Ghosh",
          "Shaila Afroz Anika",
          "Umma Habiba Ahmed"
        ],
        "categories": [
          "cs.CV",
          "cs.AI",
          "cs.LG"
        ]
      },
      {
        "title": "Chain-of-Look Spatial Reasoning for Dense Surgical Instrument Counting",
        "title_zh": "用于密集手术器械计数的链式视觉空间推理方法",
        "link": "https://arxiv.org/abs/2602.11024v1",
        "summary": "Accurate counting of surgical instruments in Operating Rooms (OR) is a critical prerequisite for ensuring patient safety during surgery. Despite recent progress of large visual-language models and agentic AI, accurately counting such instruments remains highly challenging, particularly in dense scen",
        "summary_zh": "本文提出链式视觉空间推理方法，用于解决手术室中密集场景下的器械精确计数问题。创新点在于结合大视觉语言模型和智能体AI，通过多步空间推理链提升对重叠、遮挡器械的识别能力。主要贡献包括设计了一个高效的计数框架，在真实手术数据上验证了其准确性和鲁棒性，为医疗安全提供了可靠的技术支持。",
        "published": "2026-02-11T16:49:11Z",
        "authors": [
          "Rishikesh Bhyri",
          "Brian R Quaranto",
          "Philip J Seger..."
        ],
        "categories": [
          "cs.CV",
          "cs.AI"
        ]
      },
      {
        "title": "Beyond VLM-Based Rewards: Diffusion-Native Latent Reward Modeling",
        "title_zh": "超越基于VLM的奖励：扩散原生潜在奖励建模",
        "link": "https://arxiv.org/abs/2602.11146v1",
        "summary": "Preference optimization for diffusion and flow-matching models relies on reward functions that are both discriminatively robust and computationally efficient. Vision-Language Models (VLMs) have emerged as the primary reward provider, leveraging their rich multimodal priors to guide alignment. Howeve",
        "summary_zh": "本文研究扩散和流匹配模型的偏好优化问题，重点关注奖励函数设计。当前视觉语言模型（VLMs）因其丰富多模态先验成为主要奖励提供者，但存在计算效率低和判别鲁棒性不足的局限。创新点在于提出扩散原生潜在奖励建模框架，直接在扩散模型的潜在空间构建奖励函数，避免依赖外部VLMs。主要贡献是开发高效且判别力强的奖励机制，显著提升生成模型对齐人类偏好的能力，为图像生成和编辑任务的优化提供新范式。",
        "published": "2026-02-11T18:57:26Z",
        "authors": [
          "Gongye Liu",
          "Bo Yang",
          "Yida Zhi..."
        ],
        "categories": [
          "cs.CV",
          "cs.AI"
        ]
      }
    ],
    "机器人": [
      {
        "title": "ContactGaussian-WM: Learning Physics-Grounded World Model from Videos",
        "title_zh": "ContactGaussian-WM：从视频中学习物理基础的世界模型",
        "link": "https://arxiv.org/abs/2602.11021v1",
        "summary": "Developing world models that understand complex physical interactions is essential for advancing robotic planning and simulation.However, existing methods often struggle to accurately model the environment under conditions of data scarcity and complex contact-rich dynamic motion.To address these cha",
        "summary_zh": "开发理解复杂物理交互的世界模型对推进机器人规划和仿真至关重要。然而，现有方法常在数据稀缺和复杂接触丰富动态运动条件下难以准确建模环境。为解决这些挑战，本文提出ContactGaussian-WM，一种从视频中学习物理基础世界模型的方法。创新点在于结合高斯过程与接触动力学，以无监督方式从视觉输入推断物理参数和交互。主要贡献包括设计可扩展框架，在模拟和真实世界数据上验证其生成逼真轨迹和提升机器人任务性能的能力，为数据高效机器人学习提供新途径。",
        "published": "2026-02-11T16:48:13Z",
        "authors": [
          "Meizhong Wang",
          "Wanxin Jin",
          "Kun Cao"
        ],
        "categories": [
          "cs.RO",
          "cs.AI",
          "cs.CV"
        ]
      },
      {
        "title": "Blind Gods and Broken Screens: Architecting a Secure, Intent-Centric Mobile Agent Operating System",
        "title_zh": "盲神与破碎屏幕：构建一个安全、意图中心的移动智能体操作系统",
        "link": "https://arxiv.org/abs/2602.10915v1",
        "summary": "The evolution of Large Language Models (LLMs) has shifted mobile computing from App-centric interactions to system-level autonomous agents. Current implementations predominantly rely on a \"Screen-as-Interface\" paradigm, which inherits structural vulnerabilities and conflicts with the mobile ecosyste",
        "summary_zh": "本文探讨了基于大语言模型（LLM）的移动计算向系统级自主智能体转型的背景下，提出了一种安全、意图中心的移动智能体操作系统架构。核心创新在于摒弃传统的“屏幕即接口”范式，设计了一个更安全的系统框架，减少结构漏洞并与移动生态系统兼容。主要贡献包括提出了一种新型操作系统模型，支持智能体在移动设备上的高效、安全运行，为未来机器人技术和移动自动化应用奠定了基础。",
        "published": "2026-02-11T14:52:01Z",
        "authors": [
          "Zhenhua Zou",
          "Sheng Guo",
          "Qiuyang Zhan..."
        ],
        "categories": [
          "cs.CR",
          "cs.AI"
        ]
      }
    ]
  },
  "category_summaries": {
    "大语言模型/LLM": "今日研究聚焦于提升LLM的推理能力和效率，多篇论文探讨了模型压缩、知识蒸馏和少样本学习技术，以降低计算成本并增强泛化性能。亮点包括新型架构设计如稀疏注意力机制，以及针对特定领域（如代码生成和科学文献）的微调方法，显示出向更轻量化和专业化发展的趋势。",
    "强化学习/RL": "研究重点在于改进RL算法的稳定性和样本效率，特别是结合离线学习与在线探索的混合方法。多模态环境下的策略优化和基于模型的规划成为热点，亮点包括使用图神经网络处理复杂状态空间，以及针对机器人控制任务的新奖励函数设计。",
    "优化算法": "今日论文关注分布式优化和自适应学习率算法，以应对大规模AI训练中的挑战。趋势包括二阶优化方法的改进和针对非凸问题的收敛性分析，亮点在于结合元学习自动调整超参数，提升模型训练速度和性能。",
    "NLP": "研究侧重于预训练模型的细粒度应用，如情感分析、文本摘要和问答系统。趋势包括多语言模型的扩展和低资源语言处理，亮点在于利用对比学习增强语义表示，以及针对偏见检测的伦理导向方法。",
    "多模态学习": "热点集中在视觉-语言模型的联合训练和跨模态对齐，如图像描述和视频理解。趋势是增强模型对复杂多模态数据的融合能力，亮点包括新型注意力机制和自监督学习框架，推动更自然的AI交互。",
    "图神经网络": "研究聚焦于动态图学习和异构图处理，以应用于社交网络和生物信息学。趋势包括改进图卷积网络的可扩展性和解释性，亮点在于结合时间序列分析预测图结构变化，以及隐私保护下的图数据训练。",
    "时间序列分析": "论文探讨了基于Transformer和RNN的混合模型，用于预测和异常检测。趋势是整合外部因素（如天气或经济数据）提升准确性，亮点在于自监督预训练方法减少标注依赖，适用于金融和医疗领域。",
    "隐私保护与数据安全": "研究重点为联邦学习和差分隐私技术在AI模型中的应用，以平衡数据效用与安全。趋势包括针对对抗攻击的防御机制和可验证计算，亮点在于新型加密协议实现高效安全的多方协作训练。",
    "AI治理与伦理": "今日论文关注算法公平性、可解释性和问责制，趋势是开发标准化评估框架和监管工具。亮点包括针对偏见缓解的自动化检测方法，以及跨文化伦理准则的讨论，推动负责任AI发展。",
    "计算机视觉/CV": "研究热点为自监督学习和3D视觉，如目标检测和场景重建。趋势是提升模型在低光照或遮挡环境下的鲁棒性，亮点包括轻量化网络设计和实时视频分析技术，应用于自动驾驶和医疗影像。",
    "机器人": "论文侧重于机器人感知与决策的集成，如SLAM和抓取操作。趋势是结合强化学习优化运动控制，亮点在于多机器人协作系统和模拟到现实的迁移学习，加速实际部署。"
  },
  "highlights": [
    "研究亮点1：从缓冲区到寄存器：通过混合键合3D NPU协同设计实现细粒度FlashAttention——核心创新在于硬件-算法协同优化，将存储层级从缓冲区提升到寄存器，结合3D堆叠技术大幅降低Transformer注意力计算的内存瓶颈，为大规模模型部署提供突破性加速方案。",
    "研究亮点2：通过端到端微分实现语言模型反演——核心创新在于首次系统性地形式化语言模型反演问题，并开发可扩展的端到端微分方法，能够为任意语言模型生成匹配目标输出的输入提示，显著提升模型的可解释性和可控性。",
    "研究亮点1：LoRA-Squeeze：LoRA模块的简单有效后调优与调优中压缩 - 核心创新在于提出轻量级压缩算法，动态减少LoRA参数，无需复杂超参数调整，在保持性能的同时提升部署效率，对参数高效微调领域有重要实用价值。",
    "研究亮点2：GENIUS：生成性流体智能评估套件 - 核心创新在于设计专注于生成性流体智能的评估框架，测试模型在开放域中的创造性和适应性，填补了现有多模态模型评估的空白，具有高学术价值。",
    "研究亮点1：SynergyKGC：通过拓扑感知协同解决知识图谱补全中的拓扑异质性问题——创新性地提出可学习的拓扑对齐模块，动态整合局部与全局结构特征，显著提升了链接预测的准确性与鲁棒性，为图神经网络在复杂关系推理中的应用提供了新范式。",
    "研究亮点2：CVPL：一个用于受保护表格数据事后链接风险评估的几何框架——将链接风险评估转化为几何问题，开发了一种直观且可计算的风险度量，弥补了传统隐私度量的不足，对数据安全与隐私保护领域具有重要的理论与实践价值。",
    "研究亮点1：ROCKET论文提出了一种无需重新训练的模型压缩方法，通过校准引导的背包优化策略，在保持高性能的同时实现快速压缩，具有很高的实用价值，适用于资源受限的部署场景。",
    "研究亮点2：FormalJudge论文针对LLM智能体的行为安全问题，创新性地结合神经与符号方法，提出可解释的监督范式，为高风险AI应用的安全保障提供了重要的理论框架。",
    "研究亮点3：RiemannGL论文将黎曼几何引入图深度学习，通过几何变换更好地建模非欧几里得图结构，在多个图任务上取得性能提升，具有显著的学术创新性。",
    "研究亮点1：GraphSeek：基于LLM的下一代图分析——创新地将大语言模型与图分析结合，解决大规模异构图处理难题，显著降低使用门槛，推动图数据在跨领域的普及应用。"
  ],
  "daily_summary": "今日AI研究动态显示，大语言模型和强化学习仍是核心热点，但研究趋势正从通用模型向轻量化、专业化方向演进。多篇论文探讨了模型压缩、知识蒸馏和少样本学习技术，旨在降低计算成本并提升效率，同时隐私保护与AI伦理议题受到更多关注，联邦学习和差分隐私方法被广泛整合以应对数据安全挑战。这反映了AI领域在追求性能突破的同时，日益重视可持续性和社会责任。\n\n创新突破方面，多模态学习和图神经网络的进展显著，新型注意力机制和自监督框架增强了跨模态数据融合能力，而动态图学习技术则拓展了社交网络和生物信息学应用。整体上，研究呈现出跨学科融合的特点，如优化算法与元学习结合、时间序列分析与外部因素整合，推动AI向更鲁棒、可解释和实用的方向发展，为未来智能系统部署奠定基础。"
}