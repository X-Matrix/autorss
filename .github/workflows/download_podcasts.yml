name: Download Pending Podcasts

on:
  workflow_run:
    workflows: ["Generate Daily Podcast"]
    types:
      - completed
  schedule:
    # 每天运行一次，检查是否有待下载的 podcast
    - cron: '0 12 * * *'  # 每天中午12点运行一次
  workflow_dispatch:  # 允许手动触发
    inputs:
      date:
        description: '指定日期 (YYYY-MM-DD), 留空自动检测'
        required: false
        type: string

jobs:
  download-pending:
    runs-on: ubuntu-latest
    
    steps:
      - name: Wait 30 minutes for podcast generation
        if: github.event_name == 'workflow_run'
        run: |
          echo "Waiting 30 minutes for podcast generation to complete..."
          sleep 1800
      
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
      
      - name: Setup NotebookLM storage state
        env:
          NOTEBOOKLM_STORAGE_STATE_CONTENT: ${{ secrets.NOTEBOOKLM_STORAGE_STATE }}
        run: |
          mkdir -p ~/.notebooklm
          echo "$NOTEBOOKLM_STORAGE_STATE_CONTENT" > ~/.notebooklm/storage_state.json
          chmod 600 ~/.notebooklm/storage_state.json
      
      - name: Check and download pending podcasts
        run: |
          # 创建下载脚本
          cat > /tmp/check_and_download.py << 'EOF'
          #!/usr/bin/env python3
          import json
          import asyncio
          import sys
          from pathlib import Path
          from datetime import datetime, timedelta
          
          ROOT = Path.cwd()
          PODCASTS_DIR = ROOT / 'data' / 'podcasts'
          
          async def check_and_download(target_date=None):
              """检查待下载的 podcast
              
              Args:
                  target_date: 指定日期(YYYY-MM-DD)，如果为None则检查最近两天
              """
              if not PODCASTS_DIR.exists():
                  print("No podcasts directory")
                  return
              
              # 查找元数据文件
              metadata_files = sorted(PODCASTS_DIR.glob('*_metadata.json'), reverse=True)
              downloaded = []
              
              # 如果指定了日期，只处理该日期
              if target_date:
                  target_files = [f for f in metadata_files if f.stem.startswith(target_date)]
                  if not target_files:
                      print(f"No metadata found for date: {target_date}")
                      return []
                  metadata_files = target_files
                  print(f"Processing specified date: {target_date}")
              else:
                  # 只处理最近两天的
                  today = datetime.now()
                  cutoff_date = (today - timedelta(days=2)).strftime('%Y-%m-%d')
                  metadata_files = [f for f in metadata_files 
                                   if f.stem.replace('_metadata', '') >= cutoff_date]
                  print(f"Processing podcasts since {cutoff_date} (last 2 days)")
              
              for metadata_file in metadata_files:
                  with open(metadata_file, 'r', encoding='utf-8') as f:
                      metadata = json.load(f)
                  
                  date = metadata.get('date', 'Unknown')
                  status = metadata.get('status', 'unknown')
                  
                  # 检查是否需要下载
                  audio_file = PODCASTS_DIR / f'{date}_podcast.mp3'
                  if audio_file.exists():
                      print(f"✓ {date}: Already downloaded")
                      continue
                  
                  if status in ['generating', 'timeout_but_generating']:
                      print(f"→ {date}: Attempting to download...")
                      # 导入并运行下载
                      sys.path.insert(0, str(ROOT / 'scripts'))
                      from download_podcast import download_podcast
                      
                      success = await download_podcast(date_str=date)
                      if success:
                          print(f"✓ {date}: Downloaded successfully")
                          downloaded.append(date)
                      else:
                          print(f"✗ {date}: Download failed or still generating")
                  else:
                      print(f"- {date}: Status {status}, skipping")
              
              return downloaded
          
          if __name__ == '__main__':
              import sys
              target_date = sys.argv[1] if len(sys.argv) > 1 else None
              downloaded = asyncio.run(check_and_download(target_date))
              if downloaded:
                  print(f"\n✓ Downloaded {len(downloaded)} podcasts: {', '.join(downloaded)}")
              else:
                  print("\nNo podcasts downloaded")
          EOF
          
          chmod +x /tmp/check_and_download.py
          python /tmp/check_and_download.py ${{ inputs.date || '' }}
      
      - name: Generate static data
        run: |
          python scripts/generate_static_data.py
      
      - name: Upload podcasts to R2
        run: |
          npm install -g wrangler
          for file in data/podcasts/*_podcast.mp3; do
            if [ -f "$file" ]; then
              filename=$(basename "$file")
              echo "Uploading $filename to R2..."
              wrangler r2 object put "autorss-podcast/$filename" --file "$file" --remote
            fi
          done
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_R2_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
      
      - name: Check if files changed
        id: check_changes
        run: |
          git add -A
          if git diff --staged --quiet; then
            echo "changed=false" >> $GITHUB_OUTPUT
          else
            echo "changed=true" >> $GITHUB_OUTPUT
          fi
      
      - name: Commit and push if changed
        if: steps.check_changes.outputs.changed == 'true'
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git commit -m "Download pending podcasts $(date +'%Y-%m-%d %H:%M')"
          git push
      
      - name: Upload artifacts
        if: steps.check_changes.outputs.changed == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: downloaded-podcasts
          path: data/podcasts/*.mp3
          retention-days: 30
      
      - name: Slack Notify — Success
        if: ${{ success() }}
        uses: slackapi/slack-github-action@v2.0.0
        with:
          webhook: ${{ secrets.SLACK_WEBHOOK }}
          webhook-type: incoming-webhook
          payload: |
            text: "*Download Pending Podcasts*: ${{ job.status }}\nRepository: ${{ github.repository }}\nRun: <${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}|View run>"
            blocks:
              - type: "section"
                text:
                  type: "mrkdwn"
                  text: "Download Pending Podcasts: ${{ job.status }}\nRepository: ${{ github.repository }}\nRun: <${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}|View run>"
        env:
          SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK }}

      - name: Slack Notify — Failure
        if: ${{ failure() }}
        uses: slackapi/slack-github-action@v2.0.0
        with:
          webhook: ${{ secrets.SLACK_WEBHOOK }}
          webhook-type: incoming-webhook
          payload: |
            text: "*Download Pending Podcasts*: ${{ job.status }}\nRepository: ${{ github.repository }}\nRun: <${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}|View run>"
            blocks:
              - type: "section"
                text:
                  type: "mrkdwn"
                  text: "Download Pending Podcasts: ${{ job.status }}\nRepository: ${{ github.repository }}\nRun: <${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}|View run>"
        env:
          SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK }}
