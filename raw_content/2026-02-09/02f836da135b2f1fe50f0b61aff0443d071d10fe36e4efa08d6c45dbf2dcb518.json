{
  "title": "Skills vs Dynamic MCP Loadouts",
  "link": "https://lucumr.pocoo.org/2025/12/13/skills-vs-mcp/",
  "published": "2025-12-13T00:00:00+00:00",
  "summary": "<p>I&#8217;ve been moving all my MCPs to skills, including the remaining one I still\nused: the Sentry MCP<sup class=\"footnote-ref\" id=\"fnref-1\"><a href=\"#fn-1\">1</a></sup>.  Previously I had already moved entirely away from\nPlaywright to a Playwright skill.</p>\n<p>In the last month or so there have been discussions about using <a href=\"https://www.anthropic.com/engineering/advanced-tool-use\">dynamic tool\nloadouts</a> to defer\nloading of tool definitions until later.  Anthropic has also been toying around\nwith the idea of wiring together MCP calls via code, something <a href=\"/2025/7/3/tools/\">I have\nexperimented with</a>.</p>\n<p>I want to share my updated findings with all of this and why the deferred tool\nloading that Anthropic came up with does not fix my lack of love for MCP.  Maybe\nthey are useful for someone else.</p>\n<h2>What is a Tool?</h2>\n<p>When the agent encounters a tool definition through reinforcement learning or\notherwise, it is encouraged to emit tool calls through special tokens when it\nencounters a situation where that tool call would be appropriate.  For all\nintents and purposes, tool definitions can only appear between special tool\ndefinition tokens in a system prompt.  Historically this means that you cannot\nemit tool definitions later in the conversation state.  So your only real option\nis for a tool to be loaded when the conversation starts.</p>\n<p>In agentic uses, you can of course compress your conversation state or change\nthe tool definitions in the system message at any point.  But the consequence is\nthat you will lose the reasoning traces and also the cache.  In the case of\nAnthropic, for instance, this will make your conversation significantly more\nexpensive.  You would basically start from scratch and pay full token rates plus\ncache write cost, compared to cache read.</p>\n<p>One recent innovation from Anthropic is deferred tool loading.  You still\ndeclare tools ahead of time in the system message, but they are not injected\ninto the conversation when the initial system message is emitted.  Instead they\nappear at a later point.  The tool definitions however still have to be static\nfor the entire conversation, as far as I know.  So the tools that could exist\nare defined when the conversation starts.  The way Anthropic discovers the tools\nis purely by regex search.</p>\n<h2>Contrasting with Skills</h2>\n<p>This is all quite relevant because even though MCP with deferred loading feels\nlike it should perform better, it actually requires quite a bit of engineering\non the LLM API side.  The skill system gets away without any of that and, at\nleast from my experience, still outperforms it.</p>\n<p>Skills are really just short summaries of which skills exist and in which file\nthe agent can learn more about them.  These are proactively loaded into the\ncontext.  So the agent understands in the system context (or maybe somewhere\nlater in the context) what capabilities it has and gets a link to the manual for\nhow to use them.</p>\n<p>Crucially, skills do not actually load a tool definition into the context.  The\ntools remain the same: bash and the other tools the agent already has.  All it\nlearns from the skill are tips and tricks for how to use these tools more\neffectively.</p>\n<p>Because the main thing it learns is how to use other command line tools and\nsimilar utilities, the fundamentals of how to chain and coordinate them together\ndo not actually change.  The reinforcement learning that made the Claude family\nof models very good tool callers just helps with these newly discovered tools.</p>\n<h2>MCP as Skills?</h2>\n<p>So that obviously raises the question: if skills work so well, can I move the\nMCP outside of the context entirely and invoke it through the CLI in a similar\nway as Anthropic proposes?  The answer is yes, you can, but it doesn&#8217;t work\nwell.  One option here is Peter Steinberger&#8217;s\n<a href=\"https://github.com/steipete/mcporter\">mcporter</a>.  In short, it reads the\n<code>.mcp.json</code> files and exposes the MCPs behind it as callable tools:</p>\n<div class=\"highlight\"><pre><span></span>npx mcporter call 'linear.create_comment(issueId: &quot;ENG-123&quot;, body: &quot;Looks good!&quot;)'\n</pre></div>\n<p>And yes, it looks very much like a command line tool that the LLM can invoke.\nThe problem however is that the LLM does not have any idea about what tools are\navailable, and now you need to teach it that.  So you might think: why not make\nsome skills that teach the LLM about the MCPs?  Here the issue for me comes from\nthe fact that MCP servers have no desire to maintain API stability.  They are\nincreasingly starting to trim down tool definitions to the bare minimum to\npreserve tokens.  This makes sense, but for the skill pattern it&#8217;s not what you\nwant.  For instance, the Sentry MCP server at one point switched the query\nsyntax entirely to natural language.  A great improvement for the agent, but my\nsuggestions for how to use it became a hindrance and I did not discover the\nissue straight away.</p>\n<p>This is in fact quite similar to Anthropic&#8217;s deferred tool loading: there is no\ninformation about the tool in the context at all.  You <em>need</em> to create a\nsummary.  The eager loading of MCP tools we have done in the past now has ended\nup with an awkward compromise: the description is both too long to eagerly load\nit, and too short to really tell the agent how to use it.  So at least\nfrom my experience, you end up maintaining these manual skill summaries for MCP\ntools exposed via mcporter or similar.</p>\n<h2>Path Of Least Resistance</h2>\n<p>This leads me to my current conclusion: I tend to go with what is easiest, which\nis to ask the agent to write its own tools as a skill.  Not only does it not\ntake all that long, but the biggest benefit is that the tool is largely under my\ncontrol.  Whenever it breaks or needs some other functionality, I ask the agent\nto adjust it.  The Sentry MCP is a great example.  I think it&#8217;s probably one of\nthe better designed MCPs out there, but I don&#8217;t use it anymore.  In part because\nwhen I load it into the context right away I lose around 8k tokens out of the\nbox, and I could not get it to work via mcporter.  On the other hand, I have\nClaude maintain a skill for me.  And yes, that skill is probably quite buggy and\nneeds to be updated, but because the agent maintains it, it works out better.</p>\n<p>It&#8217;s quite likely that all of this will change, but at the moment manually\nmaintained skills and agents writing their own tools have become my preferred\nway.  I suspect that dynamic tool loading with MCP will become a thing, but it\nwill probably quite some protocol changes to bring in skill-like summaries and\nbuilt-in manuals for the tools.  I also suspect that MCP would greatly benefit\nof protocol stability.  The fact that MCP servers keep changing their tool\ndescriptions at will does not work well with materialized calls and external\ntool descriptions in READMEs and skill files.</p>\n<div class=\"footnotes\">\n<ol>\n<li id=\"fn-1\">\n<p>Keen readers will remember that last time, the last MCP I used was\nPlaywright.  In the meantime I added and removed two more MCPs: Linear and\nSentry, mostly because of authentication issues and neither having a great\ncommand line interface.<a class=\"footnote\" href=\"#fnref-1\">&#8617;</a></p></li>\n</ol>\n</div>",
  "id": "https://lucumr.pocoo.org/2025/12/13/skills-vs-mcp/"
}