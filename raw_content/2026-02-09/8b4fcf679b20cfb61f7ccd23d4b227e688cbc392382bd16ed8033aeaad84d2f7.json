{
  "title": "Notes on blog future-proofing",
  "link": "https://maurycyz.com/misc/futureproofing/",
  "published": "Fri, 23 Jan 2026 00:00:00 +0000",
  "summary": "<!-- mksite: start of content -->\n<p class=\"dropcap\">\n\n<em>One of the great things about <a href=\"/misc/starting_a_blog/\">web pages</a> is that they are long-lived and mutable</em>.\nThere's no need to aim for perfection on the first draft:\nA page can continue to be improved for years after its original publication.\n</p><p>\nHowever, this mutability comes at a cost:\n</p><p>\n<a href=\"https://commons.wikimedia.org/wiki/File:First_Web_Server.jpg\"><img src=\"/misc/futureproofing/first_server.jpg\" /></a>\n<center>DO NOT POWER [IT] DOWN!! &mdash; The first web server.</center>\n</p><p>\nServers are just computers:\nIf they ever break or are turned off, the web site vanishes off the internet. \n</p><p>\n<!-- snip -->\n</p>\n<p>\n</p>\n\n<p>\n<!--  External links: 3rd party archiving services -->\n<em>If you've ever been reading something more than a few years old</em>, you've probably noticed that <a href=\"https://en.wikipedia.org/wiki/Link_rot\">none of the links work</a>.\nEven if the destination site still exists, It's common for them to have <a href=\"https://www.w3.org/Provider/Style/URI\">changed the URL format</a> so that old links don't work. \n</p><p>\nTo be clear, links are a good thing: \nThey allow readers to look deeper into a topic, and <a href=\"/real_pages/\">external links</a> are how we find new places on the internet. \n</p><p>\n<h1>Preserving external links:</h1>\n</p><p>\n<em>3rd party are services like <a href=\"https://archive.org/\">archive.org</a> are hit-and-miss</em>:\nBy most accounts, only <a href=\"https://arxiv.org/abs/1212.6177\">around 50%</a> of pages ever make it to the archive, and even if they have a copy, it's still just a web site:\nMany other archiving services <!--like peeep.us--> have vanished or lost data.\nThese services are good for archiving one's own site, but aren't great at defending against link rot.\n</p><p>\n<em>If I want to be sure links will always work, they have to be archived locally.</em>\n</p><p>\nI don't want to run a <a href=\"https://en.wikipedia.org/wiki/Web_crawler\">crawler:</a>\n</p><p>\nUnless carefully watched,\nthese can place a lot of <a href=\"https://lwn.net/Articles/1008897/\">load on the target</a> server or/and fill up my disk with infinite dynamic pages:\nThese could be intentional <a href=\"/babble/entry-point\">honeypots</a> or something as harmless as a web based calendar.\n</p><p>\nI'd spend more time putting out fires than actually writing. \n</p><p>\nWith that in mind, I decided to use Chromium's \"save\" feature to archive single pages.\nThis has one huge benefit over something like recursive wget:\n</p><p>\nIt saves the final DOM, not what was served over HTTP.\n</p><p>\n<em>A lot of sites use Javascript to render content</em>:\nFor example, Substack uses it render math, and despite popular belief, there's more then just Nazis on there:\nIt's also home to <a href=\"https://lcamtuf.substack.com/\">Lcamtuf's</a> excellent blog.\nOther sites go further by delivering all content as JSON and rendering it client side.\nYou might think that only large corporate sites do this...\n<a href=\"https://kristoff.it/blog/static-site-paradox/\">but that's just not the case</a>. \n</p><p>\nThese types of pages could be preserved with a caching proxy,\nbut the odds that fifty megabytes of Javascript work in ten years are not good:\n</p><p>\nIt's better to run the Javascript now and save the results for later. \n</p><p>\n</p>\n<details>\nFormat choice\n<p>\nChrome supports saving in two formats: MHTML and standard HTML with a directory to store the resources. \n</p><p>\nOn paper, <a href=\"https://datatracker.ietf.org/doc/html/rfc2557\">MHTML</a> very nice &mdash;\nit's a standardized, single-file web archive with browser support\n&mdash; unfortunately it's only really supported by Chrome: \ndepending on a single application is not great for long-term preservation.\n</p><p>\nRight now, I have enough space to store both formats:\nWhen a link breaks, I'll either serve MHTML (faster, more faithful) or the multi-file archives (more compatible) depending on the current state of support.\n</p>\n</details>\n<p>\n<h1>This site itself:</h1>\n</p><p>\nThis blog uses an <a href=\"/misc/new_ssg/\">(almost) zero-dependency site generator</a>: \nThe only thing it needs is a C compiler.\n</p><p>\n<em>When it does break, all the previously generated HTML can be served as-is</em>:\nIt's only used to update the site.\n</p><p>\nAll the blog posts have URLs beginning with /projects, /misc, /tutorials or /astro:\nIf I reorganize things, it won't take up a lot of namespace to keep the old URLs working. \n<!--\n</p><p>\n<h1>The hit-by-a-bus scenario:</h1>\n</p><p>\nI do have redundant backups of the server, but they do require manual intervention to restore.\nThe server might continue to run for a while, but it's only a matter of time until something goes wrong. \n</p><p>\nIn that case, a locally hosted copy won't do much good. \nThis is where 3rd party services like <a href=https://archive.org>archive.org</a> shine: \nMy site is popular enough for them to have a fairly complete crawl, and I manually submit new posts.\n</p><p>\nIf archive.org vanishes, this <h-n>wget</h-n> command will download everything:\n</p><p>\n<pre>\n<h-c># Recursive wget command to download everything from maurycyz.com, including</h-c>\n<h-c># images hosted on a subdomain. Excludes crawler trap and gzip bomb.</h-c>\n<h-c># Please don't spam unless you want to be firewalled.</h-c>\n<h-n>wget</h-n> --recursive -l inf -N                     \\\n     --span-hosts                              \\\n     --domains=<h-v>maurycyz.com</h-v>,<h-v>large.maurycyz.com</h-v> \\\n     -X <h-v>/babble/</h-v> -X <h-v>/bomb/</h-v>                     \\\n     --force-directories                       \\\n     <h-v>https://maurycyz.com/</h-v>\n</pre>\n</p><p>\n... but please don't host a copy while this server is up:\nI don't need outdated versions floating around on the internet. \n</p><p>\nAs of 2026-01-20, this website is around 1.6 GB.\n-->\n</p>\n<!-- mksite: end of content -->",
  "id": "http://maurycyz.com/misc/futureproofing/"
}