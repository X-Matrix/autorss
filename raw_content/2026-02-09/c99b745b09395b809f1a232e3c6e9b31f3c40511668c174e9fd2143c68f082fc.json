{
  "title": "Raspberry Pi's new AI HAT adds 8GB of RAM for local LLMs",
  "link": "https://www.jeffgeerling.com/blog/2026/raspberry-pi-ai-hat-2/",
  "published": "Thu, 15 Jan 2026 02:00:00 -0600",
  "summary": "<figure class=\"insert-image\"><img alt=\"Raspberry Pi AI HAT&#43; 2\" height=\"auto\" src=\"https://www.jeffgeerling.com/blog/2026/raspberry-pi-ai-hat-2/raspberry-pi-ai-hat-2.jpg\" width=\"700\" />\n</figure>\n\n<p>Today Raspberry Pi launched their new <a href=\"https://www.raspberrypi.com/products/ai-hat-plus-2/\">$130 AI HAT+ 2</a> which includes a Hailo 10H and 8 GB of <a href=\"https://www.micron.com/products/memory/dram-components/lpddr4/part-catalog/part-detail/mt53e2g32d4de-046-wt-c\">LPDDR4X RAM</a>.</p>\n<p>With that, the Hailo 10H is capable of running LLMs entirely standalone, freeing the Pi's CPU and system RAM for other tasks. The chip runs at a maximum of 3W, with 40 TOPS of INT8 NPU inference performance in addition to the equivalent 26 TOPS INT4 machine vision performance on the earlier AI HAT with Hailo 8.</p>",
  "id": "https://www.jeffgeerling.com/blog/2026/raspberry-pi-ai-hat-2/"
}