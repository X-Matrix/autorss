{
  "title": "A Year Of Vibes",
  "link": "https://lucumr.pocoo.org/2025/12/22/a-year-of-vibes/",
  "published": "2025-12-22T00:00:00+00:00",
  "summary": "<p>2025 draws to a close and it&#8217;s been quite a year.  Around this time last year, I\nwrote a post that reflected <a href=\"/2024/12/26/reflecting-on-life/\">on my life</a>.  Had\nI written about programming, it might have aged badly, as 2025 has been a year\nlike no other for my profession.</p>\n<h2>2025 Was Different</h2>\n<p>2025 was the year of changes.  Not only did I leave Sentry and start my new\ncompany, it was also the year I stopped programming the way I did before.  <a href=\"/2025/6/4/changes/\">In\nJune</a> I finally felt confident enough to share that my way\nof working was different:</p>\n<blockquote>\n<p>Where I used to spend most of my time in Cursor, I now mostly use Claude Code,\nalmost entirely hands-off. […] If you would have told me even just six months\nago that I&#8217;d prefer being an engineering lead to a virtual programmer intern\nover hitting the keys myself, I would not have believed it.</p>\n</blockquote>\n<p>While I set out last year wanting to write more, that desire had nothing to do\nwith agentic coding.  Yet I published 36 posts — almost 18% of all posts on this\nblog since 2007.  I also had around a hundred conversations with programmers,\nfounders, and others about AI because I was fired up with curiosity after\nfalling into the agent rabbit hole.</p>\n<p>2025 was also a not so great year for the world.  To make my peace with it, I\n<a href=\"https://dark.ronacher.eu/\">started a separate blog</a> to separate out my thoughts\nfrom here.</p>\n<h2>The Year Of Agents</h2>\n<p>It started with a growing obsession with Claude Code in April or May, resulting\nin months of building my own agents and using others&#8217;.  Social media exploded\nwith opinions on AI: some good, some bad.</p>\n<p>Now I feel I have found a new stable status quo for how I reason about where we\nare and where we are going.  I&#8217;m doubling down on code generation, file systems,\nprogrammatic tool invocation via an interpreter glue, and skill-based learning.\nBasically: what Claude Code innovated is still state of the art for me.  That\nhas worked very well over the last few months, and seeing foundation model\nproviders double down on skills reinforces my belief in this approach.</p>\n<p>I&#8217;m still perplexed by how TUIs made such a strong comeback.  At the moment I&#8217;m\nusing <a href=\"https://ampcode.com/\">Amp</a>, <a href=\"https://claude.com/product/claude-code\">Claude\nCode</a>, and\n<a href=\"https://shittycodingagent.ai/\">Pi</a>, all from the command line.  Amp feels like\nthe Apple or Porsche of agentic coding tools, Claude Code is the affordable\nVolkswagen, and Pi is the Hacker&#8217;s Open Source choice for me.  They all feel\nlike projects built by people who, like me, use them to an unhealthy degree to\nbuild their own products, but with different trade-offs.</p>\n<p>I continue to be blown away by what LLMs paired with tool execution can do. At\nthe beginning of the year I mostly used them for code generation, but now a big\nnumber of my agentic uses are day-to-day things.  I&#8217;m sure we will see some\nexciting pushes towards consumer products in 2026.  LLMs are now helping me with\norganizing my life, and I expect that to grow further.</p>\n<h2>The Machine And Me</h2>\n<p>Because LLMs now not only help me program, I&#8217;m starting to rethink my\nrelationship to those machines.  I increasingly find it harder not to create\nparasocial bonds with some of the tools I use.  I find this odd and\ndiscomforting.  Most agents we use today do not have much of a memory and have\nlittle personality but it&#8217;s easy to build yourself one that does.  An LLM with\nmemory is an experience that is hard to shake off.</p>\n<p>It&#8217;s both fascinating and questionable.  I have tried to train myself for two\nyears, to think of these models as mere token tumblers, but that reductive view\ndoes not work for me any longer.  These systems we now create have human\ntendencies, but elevating them to a human level would be a mistake.  I\nincreasingly take issue with calling these machines &#8220;agents,&#8221; yet I have no\nbetter word for it.  I take issue with &#8220;agent&#8221; as a term because agency and\nresponsibility should remain with humans.  Whatever they are becoming, they can\ntrigger emotional responses in us that <a href=\"https://en.wikipedia.org/wiki/Chatbot_psychosis\">can be\ndetrimental</a> if we are not\ncareful.  Our inability to properly name and place these creations in relation\nto us is a challenge I believe we need to solve.</p>\n<p>Because of all this unintentional anthropomorphization, I&#8217;m really struggling at\ntimes to find the right words for how I&#8217;m working with these machines.  I know\nthat this is not just me; it&#8217;s others too.  It creates even more discomfort when\nworking with people who currently reject these systems outright.  One of the\nmost common comments I read in response to agentic coding tool articles is this\nrejection of giving the machine personality.</p>\n<h2>Opinions Everywhere</h2>\n<p>An unexpected aspect of using AI so much is that we talk far more about vibes\nthan anything else.  This way of working is less than a year old, yet it\nchallenges half a century of software engineering experience.  So there are many\nopinions, and it&#8217;s hard to say which will stand the test of time.</p>\n<p>I found a lot of conventional wisdom I don&#8217;t agree with, but I have nothing to\nback up my opinions.  How would I?  I quite vocally shared my lack of success\nwith <a href=\"https://en.wikipedia.org/wiki/Model_Context_Protocol\">MCP</a> throughout the\nyear, but I had little to back it up beyond &#8220;does not work for me.&#8221;  Others\nswore by it.  Similar with model selection.  <a href=\"https://steipete.me/\">Peter</a>, who\ngot me hooked on Claude early in the year, moved to Codex and is happy with it.\nI don&#8217;t enjoy that experience nearly as much, though I started using it more.  I\nhave nothing beyond vibes to back up my preference for Claude.</p>\n<p>It&#8217;s also important to know that some of the vibes come with intentional\nsignalling.  Plenty of people whose views you can find online have a financial\ninterest in one product over another, for instance because they are\ninvestors in it or they are paid influencers.  They might have become investors\nbecause they liked the product, but it&#8217;s also possible that their views are\naffected and shaped by that relationship.</p>\n<h2>Outsourcing vs Building Yourself</h2>\n<p>Pick up a library from any AI company today and you&#8217;ll notice they&#8217;re built with\nStainless or Fern.  The docs use Mintlify, the site&#8217;s authentication system\nmight be Clerk.  Companies now sell services you would have built yourself\npreviously.  This increase in outsourcing of core services to companies\nspecializing in it meant that the bar for some aspects of the user experience\nhas risen.</p>\n<p>But with our newfound power from agentic coding tools, you can build much of\nthis yourself.  I had Claude build me an SDK generator for Python and TypeScript\n— partly out of curiosity, partly because it felt easy enough.  As you might\nknow, I&#8217;m a proponent of <a href=\"/2025/2/20/ugly-code/\">simple code</a> and <a href=\"/2025/1/24/build-it-yourself/\">building it\nyourself</a>.  This makes me somewhat optimistic\nthat AI has the potential to encourage building on fewer dependencies.  At the\nsame time, it&#8217;s not clear to me that we&#8217;re moving that way given the current\ntrends of outsourcing everything.</p>\n<h2>Learnings and Wishes</h2>\n<p>This brings me not to predictions but to wishes for where we could put our\nenergy next.  I don&#8217;t really know what I&#8217;m looking for here, but I want to point\nat my pain points and give some context and food for thought.</p>\n<h3>New Kind Of Version Control</h3>\n<p>My biggest unexpected finding: we&#8217;re hitting limits of traditional tools for\nsharing code.  The pull request model on GitHub doesn&#8217;t carry enough information\nto review AI generated code properly — I wish I could see the prompts that led\nto changes.  It&#8217;s not just GitHub, it&#8217;s also git that is lacking.</p>\n<p>With agentic coding, part of what makes the models work today is knowing the\nmistakes.  If you steer it back to an earlier state, you want the tool to\nremember what went wrong.  There is, for lack of a better word, value in\nfailures.  As humans we might also benefit from knowing the paths that did not\nlead us anywhere, but for machines this is critical information.  You notice\nthis when you are trying to compress the conversation history.  Discarding the\npaths that led you astray means that the model will try the same mistakes again.</p>\n<p>Some agentic coding tools have begun spinning up worktrees or creating\ncheckpoints in git for restore, in-conversation branch and undo features.\nThere&#8217;s room for UX innovation that could make these tools easier to work with.\nThis is probably why we&#8217;re seeing discussions about stacked diffs and\nalternative version control systems like <a href=\"https://www.jj-vcs.dev/\">Jujutsu</a>.</p>\n<p>Will this change GitHub or will it create space for some new competition?  I\nhope so.  I increasingly want to better understand genuine human input and tell\nit apart from machine output.  I want to see the prompts and the attempts that\nfailed along the way.  And then somehow I want to squash and compress it all on\nmerge, but with a way to retrieve the full history if needed.</p>\n<h3>New Kind Of Review</h3>\n<p>This is related to the version control piece: current code review tools assign\nstrict role definitions that just don&#8217;t work with AI.  Take the GitHub code\nreview UI: I regularly want to use comments on the PR view to leave notes for\nmy own agents, but there is no guided way to do that.  The review interface\nrefuses to let me review my own code, I can only comment, but that does not\nhave quite the same intention.</p>\n<p>There is also the problem that an increased amount of code review now happens\nbetween me and my agents locally.  For instance, the Codex code review feature\non GitHub stopped working for me because it can only be bound to one\norganization at a time.  So I now use Codex on the command line to do reviews,\nbut that means a whole part of my iteration cycles is invisible to other\nengineers on the team.  That doesn&#8217;t work for me.</p>\n<p>Code review to me feels like it needs to become part of the VCS.</p>\n<h3>New Observability</h3>\n<p>I also believe that observability is up for grabs again.  We now have both the\nneed and opportunity to take advantage of it on a whole new level.  Most people\nwere not in a position where they could build their own\n<a href=\"https://en.wikipedia.org/wiki/EBPF\">eBPF</a> programs, but LLMs can.  Likewise,\nmany observability tools shied away from SQL because of its complexity, but LLMs\nare better at it than any proprietary query language.  They can write queries,\nthey can grep, they can map-reduce, they remote-control LLDB.  Anything that has\nsome structure and text is suddenly fertile ground for agentic coding tools to\nsucceed.  I don&#8217;t know what the observability of the future looks like, but my\nstrong hunch is that we will see plenty of innovation here.  The better the\nfeedback loop to the machine, the better the results.</p>\n<p>I&#8217;m not even sure what I&#8217;m asking for here, but I think that one of the\nchallenges in the past was that many cool ideas for better observability —\nspecifically dynamic reconfiguration of services for more targeted filtering —\nwere user-unfriendly because they were complex and hard to use.  But now those\nmight be the right solutions in light of LLMs because of their increased\ncapabilities for doing this grunt work.  For instance Python 3.14 landed <a href=\"https://docs.python.org/3/whatsnew/3.14.html#whatsnew314-remote-debugging\">an\nexternal debugger\ninterface</a>\nwhich is an amazing capability for an agentic coding tool.</p>\n<h3>Working With Slop</h3>\n<p>This may be a little more controversial, but what I haven&#8217;t managed this year is\nto give in to the machine.  I still treat it like regular software engineering\nand review a lot.  I also recognize that an increasing number of people are not\nworking with this model of engineering but instead completely given in to the\nmachine.  As crazy as that sounds, I have seen some people be quite successful\nwith this.  I don&#8217;t yet know how to reason about this, but it is clear to me\nthat even though code is being generated in the end, the way of working in that\nnew world is very different from the world that I&#8217;m comfortable with.  And my\nsuspicion is that because that world is here to stay, we might need some new\nsocial contracts to separate these out.</p>\n<p>The most obvious version of this is the increased amount of these types of\ncontributions to Open Source projects, which are quite frankly an insult to\nanyone who is not working in that model.  I find reading such pull requests\nquite rage-inducing.</p>\n<p>Personally, I&#8217;ve tried to attack this problem with contribution guidelines and\npull request templates.  But this seems a little like a fight against windmills.\nThis might be something where the solution will not come from changing what\nwe&#8217;re doing.  Instead, it might come from vocal people who are also pro-AI\nengineering speaking out on what good behavior in an agentic codebase looks\nlike.  And it is not just to throw up unreviewed code and then have another\nperson figure the shit out.</p>",
  "id": "https://lucumr.pocoo.org/2025/12/22/a-year-of-vibes/"
}