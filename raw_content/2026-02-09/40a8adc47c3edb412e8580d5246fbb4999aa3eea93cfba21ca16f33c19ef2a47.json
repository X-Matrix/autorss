{
  "title": "Flock and Urban Surveillance",
  "link": "https://computer.rip/2025-12-26-Flock-and-Urban-Surveillance.html",
  "published": "26 Dec 2025 00:00:00 UT",
  "summary": "<p>Some years ago, I had a frustrating and largely fruitless encounter with the\npolitics of policing. As a member of an oversight commission, I was\nparticularly interested in the regulation of urban surveillance. The Albuquerque\nPolice Department, for reasons good and bad, has often been an early adopter\nof surveillance technology. APD deployed automated license plate readers,\nmounted on patrol cars and portable trailers, in 2013. Initially, the department\nkept a six-month history of license plate data. For six months, police could\nretrospectively search the database to reconstruct a vehicle, or person's,\nmovements—at least, those movements that happened near select patrol cars and\n&quot;your speed is&quot; trailers. Lobbying by the American Civil Liberties Union and\npublic pressure on APD and city council lead to a policy change to retain data\nfor only 14 days, a privacy-preserving measure that the ACLU lauded as one of\nthe best ALPR policies in the nation.</p>\n<p>Today, ALPR is far more common in Albuquerque. Lowering costs and a continuing\nappetite for solving social problems with surveillance technology means that\nsome parts of the city have ALPR installed at every signalized\nintersection—every person's movements cataloged at a resolution of four\nblocks. The data is retained for a full year. Some of it is offered, as a\nservice, to law enforcement agencies across the country.</p>\n<p>One of the most frustrating parts of the mass surveillance debate is the ability\nof law enforcement agencies and municipal governments to advance wide-scale\nmonitoring programs, weather the controversy, and then ratchet up retention and\nsharing after public attention fades. For years, expansive ALPR programs spread\nthrough most American cities with little objection. In my part of the country,\nit seemed that the controversy over ALPR had been completely forgotten until\none particularly significant ALPR vendor—Flock Safety—started repeatedly\nstepping in long-festering controversies with such wild abandon that they are\nclearly either idiots or entirely unconcerned about public perception.</p>\n<p><img alt=\"PTZ camera on light pole\" src=\"https://computer.rip/f/flock/1.jpg\" /></p>\n<p>I try not to be too cynical but I am, unfortunately, more inclined to the\nlatter. Companies like Flock know that they are in treacherous territory,\nmorally and legally. They know that their customers are mostly governments\nor organizations with elected leaders that are subject to popular opinion.\nThey know that helping Texas law enforcement track down abortion seekers in\nother states is a &quot;bad look.&quot; They know all of these things, but they do not\nparticularly care. They don't have to care: decades of incipient corruption,\nlegal and political maneuvering, and the routine inefficacy of municipal\npolitics has created an environment where public opinion doesn't matter.</p>\n<p>I can't definitely tell you where public opinion lies on ALPR, although it\nseems like the average person might be mildly in support. From at least my\nexperience, in my corner of the world, I will tell you this: it doesn't\nmatter. Police departments and the means by which they purchase and field\ntechnology are so isolated from the political process that it is extremely\ndifficult to imagine a scenario where voters could affect change. Year by\nyear, city by city, the police become more dug in. Law enforcement agencies\nacross the country have found that the most straightforward way to address\nprivacy concerns around surveillance technology is to keep the department's\npurchase and deployment of that technology a secret. Most city governments\nat least passively support this approach. The vendors of surveillance\nsystems facilitate, support, and even demand secrecy through their\ncontract terms.</p>\n<p>More recently, Las Vegas and the Bay Area have offered a\nmodel even more opaque to public scrutiny: law enforcement surveillance\ntechnology is simply purchased by wealthy private donors, almost invariably\nfrom the software industry, and then either the systems or their use are\ndonated to the city. If carefully designed, these programs can be completely\nexempt from public information rules. They can take the form, for example, of\na business association that runs its own private surveillance state, involving\nthe public and ostensibly accountable police only when an arrest is made. We\nare privatizing mass surveillance.</p>\n<p>Flock continues to generate enormous press, mostly on the back of persistent\ninvestigation by 404 Media. More recently, security researchers have published\nsignificant defects in the design of Flock's technology that can make the\noriginal video publicly accessible. Just about every time that someone looks\ninto Flock, the company turns out to be less ethical, the users less concerned\nabout compliance, the design of the system itself less competent than charitable\nviewers had assumed.</p>\n<p>I'm trying not to be a doomer for Christmas, but I am sometimes frustrated with\nFlock coverage because it can miss the entire history of this issue. I think\nthat a more contextually complete discussion of urban surveillance could be\nuseful. And I am sitting in a coffee shop, in a trendy part of town, looking\nout the window at a PTZ camera on the side of a traffic light. That camera, I\nknow, is owned and operated by APD's Real Time Crime Center (RTCC). Between the\npolice department itself, city agencies that participate in the RTCC, and\nbusinesses that volunteer real-time access to their surveillance, there are\nthousands of others like it. Courtesy of a transit station, there are at\nleast a dozen within my view.</p>\n<p>Whether or not this is a good or bad idea, whether or not it is effective in\nreducing crime, whether or not it will be leveraged against political opposition;\nthese are tricky questions. I suppose what worries me is that it feels like hardly\nanyone is asking them any more. It took Flock's remarkable ability to step on\nrakes and the apparent victory of fascism in national politics for anyone to\nremember that the construction of ubiquitous surveillance is a project that started\nmany years ago, and that has proceeded largely unhindered ever since.</p>\n<h2>Domestic Signals Intelligence</h2>\n<p>Within the tech community, there has historically been much attention to the\nability to track people by passively observing Bluetooth traffic. This technique\nhas been widely used, both in commercial and government applications. There are\npopular &quot;smart city&quot; street lighting systems, for example, that allow every\nstreet light to passively collect signatures of the people passing underneath it.\nTo my knowledge, these techniques are not actually very widely used by law\nenforcement. There are, perhaps, two reasons: one of mechanisms of government,\nthe other of countermeasures.</p>\n<p>First, &quot;smart city&quot; data collection systems are usually funded and deployed by\nmunicipal works or environmental departments. While police could make arrangements\nfor access to that data, those arrangements would require the kind of inter-agency\nMemoranda of Understanding that tend to lead to far more public scrutiny than\npolice acquisitions of surveillance products. Besides, since they aren't deployed\nfor law enforcement purposes, they're often not useful sources for the areas that\nlaw enforcement find most interesting: higher-crime areas that are usually\nlower-income and, thus, less likely to have working street lights at all—much\nless &quot;smart&quot; ones. Besides, smartphones have widely adopted randomization of Bluetooth and WiFi\nidentifiers, and protocol revisions have reduced the number of identifiers\ntransmitted in plaintext. Passive signals intelligence just doesn't work as well\nas it used to, at least at the capability level of a municipality.</p>\n<p>Talking about Bluetooth and WiFi on phones does raise the question of the\n&quot;phone&quot; part, the cellular interface, which is targeted by the family of devices\noften known as &quot;Stingrays&quot; after the trademark of a particular manufacturer.\nFortunately, improvements in the security design of cellular protocols is making\nthese less effective over time. Unfortunately, the technology continues to\nadvance, sometimes undoing the improvements of newer GSM revisions. Federal and\nlocal law enforcement continue to purchase and use these devices, largely in\nsecret, benefiting from a particular model of federal ownership/local use that\nmakes it especially difficult to get a police department to even confirm or deny\nthat they have ever deployed them. &quot;Stingrays&quot; or IMSI surveillance is mostly a\nshadow world of rumors and carefully worded non-denials. Despite technical measures\nagainst them, they are clearly still in use, and thus clearly still useful.</p>\n<h2>Optics</h2>\n<p>Out in the rest of the world, visual surveillance is more salient than radio.\nEarly rollouts of police-operated surveillance, dating back to at least the\n1970s, generated some controversy over privacy implications. Two things have\nsince happened: first, law enforcement have relied on an increasing number of\npublic-private partnerships and commercial vendors to gain access to surveillance\nwithout directly owning it. Second, police video surveillance has largely been\nnormalized, and no longer faces much opposition or even public notice.</p>\n<p>One of the interesting changes here is one of visibility: police video surveillance\nhas often edged in and out of public awareness to fit the politics. In periods of\npro-privacy, anti-surveillance sentiment, departments rely more on voluntary\narrangements for access to cameras installed by others. In periods of pro-police,\nanti-crime sentiment, departments install cameras with flashing lights and police\nbadges. Both types tend to persist after the next change in the tide.</p>\n<p>The public usually knows little about these systems, a result of intentional\nopacity by police departments and a general lack of interest by the press. That\nleads to a lot of confusion. Where I live, we <em>do</em> have an extensive network of\npolice-operated cameras on intersection traffic signal arms. And yet, if you ask\nthe average person to identify a police surveillance camera, they will point to\nthe camera for the traffic signal's video-based lane occupancy sensing every single\ntime. That's not a a police camera, it's barely even a camera as the video is\nrarely retained. All of these people, it seems, have worked themselves into a sort\nparanoia where they think that every camera is an eye of the police. Well, the\npolice <em>are</em> watching them, from about ten feet over. The &quot;speed dome&quot; PTZ\ncameras get so much less attention, perhaps because they are usually mounted on\nthe pole further from sightline, or perhaps because they are of a type more\ncommon for commercial surveillance systems that we have learned to simply ignore.</p>\n<p>Video surveillance is an interesting topic to me, philosophically. I am largely\nunconcerned with the privacy implications of most video surveillance installations\n(such as the one on my own house) because, historically, the video was recorded\nlocally and generally reviewed only when there was a specific reason. The simple\nfact that reviewing large amounts of video is so time consuming meant that the\npervasive surveillance potential of video surveillance was, at one time not so\nlong ago, quite limited.</p>\n<p><img alt=\"Motorola ALPR on signal arm\" src=\"https://computer.rip/f/flock/2.jpg\" /></p>\n<p>Of course, the age of the computer has somewhat changed that situation. There\nare two phenomenon of the automation of surveillance that I think should be\nconsidered separately: first, machine vision has improved to an extent that\ncomputers can automatically process surveillance video to extract events and\nidentities. Second, the appified, everything-social-media attitude of\nconsumer products creates new dynamics in access to surveillance data, and\nthose dynamics are spreading upwards into the commercial segment.</p>\n<h2>Machine Vision</h2>\n<p>Historically, much of the attention to video pervasive surveillance has\ncentered around facial recognition. Facial recognition has indeed been applied\nto video surveillance for years, but I think that the average person vastly\noverestimates how effective and widely used facial recognition is.</p>\n<p>The vast majority of currently installed surveillance cameras do not produce\nvideo of sufficient quality for facial recognition. That has less to do with\nthe quality of the video itself (although that is poorer than you think for\nmost real systems) and more to do with the way that surveillance cameras are\nused and installed. Most cameras are positioned high up with wide coverage of\na room; this perspective is ideal for reconstructing a series of events but\njust about the worst case for facial recognition. For most surveillance cameras,\nhuman faces are small and at indirect angles. There is little geometry that you\ncan extract from a face that is about ten pixels wide and subjected to aggressive\nh264 compression, which is how most surveillance video comes out.</p>\n<p>Practical facial recognition systems involve cameras installed specifically for\nthat purpose, roughly at eye level where they will get close-up, straight-on\nimages of people who pass by. Next time you visit a bank branch, look by the\nexit doors for a conspicuously thick height strip. Height strips by exit doors\nwere invented to allow clerks to give police a more accurate description of a\nrobber, but they have since evolved to serve largely as subterfuge. Somewhere\naround 5' 6&quot;, you will notice a small hole, and behind that hole is a camera.\nSeveral manufacturers offer these and they seem very popular in financial\nservices.</p>\n<p>Kroger is more to the point: they've just been installing dome cameras right\nat eye height on their exit doors, for at least a decade.</p>\n<p>When discussing surveillance, it's important to remember that the vast majority\nof real-world video surveillance systems are old, inexpensive, and poorly\nmaintained. Even where cameras are installed specifically for a good view of\nfaces, there probably isn't any facial recognition in use, most of the time.\nFacial recognition products are expensive and don't currently manifest many\nbenefits unless the organization is large enough to have a security department\nto work with the resulting data, which requires a degree of operational maturity\nbeyond most surveillance users (e.g. gas stations).</p>\n<p>All of that said, there are plenty of real-world facial recognition deployments.\nRite Aid, for example, prominently rolled out facial recognition to flag known\nshoplifters at their stores... a rollout that went so poorly that it lead to a\nlawsuit and an FTC settlement including the end of the facial recognition\nprogram and a five-year moratorium on further attempts. This is not to say that\nfacial recognition on video surveillance isn't legal (although in some states\nit isn't or at least requires a lot of disclosure), but there is definitely a\ndegree of legal and reputational hazard involved.</p>\n<p>The ACLU has periodically conducted call-around surveys on use of facial\nrecognition. The most notable trend is that most large chains now refuse to talk\nabout it. I could be wrong, but my experience with corporate communications\nbehavior leads to me to interpret a refusal to comment along these lines: Home\nDepot, for example, is a very large company that will have various initiatives\nunderway, and either confirming or denying their use of facial recognition would\nprobably be wrong in some cases and expose them to compliance or legal risk in others.\nI would bet good money that Home Depot has some facial recognition\ntechnology deployed at some locations, but knowing how slowly security technology\ntends to roll out in that kind of company and how complicated the legal and\ncompliance situation can become, it's probably limited. They are probably acutely\naware of the controversy surrounding this type of surveillance and, given the\nexample of Rite Aid, the ways a rollout could go wrong. That means that surveillance\nwill spread slowly.</p>\n<p>But it will spread. At this point, I think it is inevitable that facial recognition\nwill become widely used in video surveillance. I just think the point at which\n&quot;facial recognition is everywhere&quot; remains some years away, due to all the normal\nreasons: technical limitations, slow-moving bureaucracies, and a somewhat complex\nand unclear regulatory situation. It will inevitably happen, for the same reasons\nas well: aggressive sales by facial recognition vendors.</p>\n<p>There are some sectors where facial recognition is very common, although I don't\nget the impression that retail is one of these yet. Casinos, for example—some\nof the larger Las Vegas casinos have reportedly had facial recognition systems\nin use for decades, and Nevada law is very permissive of them. Casinos are, of\ncourse, pretty much ideal users. Large institutions with a lot of financial risk\nand large, sophisticated security departments. Few other businesses outside of\nTarget can compete with the size and sophistication of casino security\ndepartments. There's a whole lot of money flying around, and they can spend\nsome of it on expensive per-camera licensing without much leadership objection.</p>\n<h2>License Plate Reading</h2>\n<p>Popular attention to facial recognition has mostly fallen away as industry and\nmedia focus has shifted to another application of machine vision that is, it\nturns out, a whole lot easier: license plates. License plates are designed for\nreadability, and most states use retroreflective paints that give you an\nabsolutely beautiful high-contrast image under coaxial (i.e. mounted alongside\nthe camera) infrared illumination. There's not much that is easier to read by\nmachine vision. Automated license plate readers have been available for quite\na long time: US CBP had an experimental ALPR installation at a Texas border crossing\nin 1994. That system was actually deemed a failure and removed, but technology\nimproved and there were permanent installations at larger border crossings by\nthe end of the 1990s.</p>\n<p>For a long time, the dominant vendor of ALPR equipment in the US was Motorola.\nMotorola's product line remains popular for vehicle-mounted systems, but the\nhigh price of the cameras, controllers, and software package had a side benefit\nof limiting the pervasiveness of ALPR. The equipment was just too expensive to\nput up all over the place.</p>\n<p>In Albuquerque, for example, the ALPR program long consisted of Motorola systems\nmounted on portable &quot;your speed is&quot; trailers. The portable nature of these\nsetups made the expense more worthwhile, and besides, portability has its own\nutilities: an APD detective once told me, for example, of how they would leave\nALPR trailers in front of the houses of people suspected to lead criminal gangs.\nWhile there was value in the intelligence collection, the main motivation was\nintimidation: while you might call the &quot;your speed is&quot; trailers a concealed\nsystem, they're not all that subtle, and one supposes that most vehicle-based\ncriminals (the main kind here) are aware that they function as the eyes of the\npolice.</p>\n<p>At some point, in response to growing budgets or lowered costs I'm not sure, APD\nbegan installing fixed Motorola ALPR systems on the light arms of major\nintersections. I know of around a dozen installations of this type in\nAlbuquerque, which is the beginning of a widespread capability to monitor\npublic movements but not exactly the dystopian pervasive surveillance of <em>Minority\nReport.</em></p>\n<p>ALPR works pretty well, but it is not perfect. Cameras need to be installed with\nfairly narrow optics aimed at the right spot, and infrared illumination makes\nreading far more reliable. Speaking of Las Vegas, I used to use a certain casino\nparking garage with an ALPR-based payment system with some regularity. It printed\nthe license plate, as read by the ALPR, on the parking ticket, which is why I know\nthat it was almost comically inept at reading my very legible California plate.\nIt always got about half the characters wrong. I have gotten much better results\nin my own home experiments with budget equipment, so I figure that system must\nhave been very poorly installed or maintained, but I'm sure there are plenty of\nothers out there just like it.</p>\n<p>That's the tricky thing about video surveillance, from the &quot;blue team&quot; side of\nthe house: people don't tend to pay a lot of attention to it until there's been\nan incident, at which point they find out that the lens has had mud on it for\nthe last three months (a much bigger problem with ALPR cameras that used to be\nmounted pretty low to the ground for a better look angle). I bring this up\nbecause I think that people tend to vastly overestimate the quality of real-world\nvideo surveillance, and I like to take every opportunity to remind people that\nthe main failure case of retail video surveillance used to be failure to replace\nthe continuous-loop tape cassette before it was completely demagnetized by\nrepeated recording. Now, in 2025, the continuous-loop tape cassettes are pretty\nmuch gone, but maintenance practices haven't improved. Lots of the cameras you\nsee in public only barely work or don't work at all. So it goes.</p>\n<h2>Flock</h2>\n<p>In 2017, though, a VC-backed (and specifically YCombinator) company called Flock\nSafety introduced a bold new idea to ALPR: a Silicon Valley sales model. Flock's\nsystem is built to be low-cost, and the sensors are smaller, simpler, and cheaper\nthan Motorola's. I suppose they might be less effective as a result, but a reduced\n&quot;catch&quot; rate doesn't really detract from mass-surveillance ALPR installations\nthat much. Flock has also greatly expanded their customer base, emphasizing sales\nto private organizations as well as law enforcement and government. Speaking of\nHome Depot, for example, Home Depot seems to have installed their own Flock cameras\nin all of their parking lots. Lowes Home Improvement has done the same.</p>\n<p>I wanted to know more definitely how much Flock systems cost, because I suspected\nthey were making significant inroads just through low pricing. It's a little\ntricky to say definitively because Flock is a &quot;call for quote&quot; kind of company and\nI think they offer contracts on different price bases. Scouring contracting\ndocuments, meeting notes, etc., it seems like a &quot;typical&quot; cost for a Flock camera\nis around $4,000 with about $3,000 a year in per-camera software licensing fees.</p>\n<p>That might seem expensive but it compares well to the five-figure prices I have\nheard associated with Motorola systems, especially since the Flock offering is\nmore &quot;white glove&quot; with installation and maintenance packaged. Motorola systems\nare usually purchased through an integrator who adds their own considerable\nmargin.</p>\n<p><img alt=\"Flock camera on light pole\" src=\"https://computer.rip/f/flock/3.jpg\" /></p>\n<p>Flock also designs their cameras to be\namenable to solar power, which radically reduces install costs compared to Motorola\nsystems that usually need a utility worker out to splice power from a streetlight.\nMore even than a price reduction, it makes Flock cameras much more available to\norganizations like HOAs that control territory in a sense but do not have the full\nbucket truck or utility work order capabilities of a municipal government.</p>\n<p>Another recent innovation in ALPR is less traceable to Flock but certainly seems\nassociated with them: flexible funding sources. Police departments have limited\nbudgets with which to acquire new technology, and technology vendors have to\ncompete with other budget priorities like salaries, vehicles, and black-on-black\ntactical vinyl jobs for those vehicles. ALPR seems especially attractive for\npublic-private partnership mechanisms, so there are a lot of Flock installations\nthat were funded by business associations, HOAs, neighborhood associations, and\nother &quot;indirect&quot; sources. Some of these systems are owned and operated by the\npolice with only the funding donated, others are owned and operated by the private\ngroup that paid for them. This can result in curious deployment decisions: sometimes\nthe lowest-crime neighborhoods are the most replete with ALPR, as they tend to\nbe wealthier and more politically organized communities with the wherewithall to\nput up the money.</p>\n<p>The most important thing to understand about Flock, though, is that it has built\non Amazon's concept of &quot;Ring neighbors&quot; to build a sort of nationwide, ALPR-centric\nNextdoor. Flock customers can basically check a box that allows other Flock\ncustomers to access data from their sensors, and of course Flock strongly encourages\nusers to turn sharing on. While there are some audit and access controls available\non Flock data sharing, they seem like pretty minimal efforts that are often\nignored.</p>\n<p>Flock sharing has generated a lot of press, especially with some dramatic examples\nlike use by a Texas sheriff to locate an abortion patient and use by ICE/CBP to\ntrack suspects. These are both examples that raise one of the most alarming aspects\nof the Flock situation: many states and municipalities have laws in place that limit\nor at least monitor collaboration of local police with other police agencies and\nfederal law enforcement. Some people find this surprising, but it's important to\nunderstand that the United States is a republic of nominally independent governments.\nLaws, policies, and priorities can vary greatly from jurisdiction to jurisdiction.\nThere is a specific historical thread, related to the tracing of escaped slaves, that\nhas made resource sharing between different law enforcement agencies a known area of\nmoral and legal treachery for a very long time.</p>\n<p>And yet, it turns out, most Flock customers seem to have sharing turned on, possibly\nentirely without their knowledge. There are now multiple well-established cases of\nlocal law enforcement agencies violating state laws by having data sharing with\nICE/CBP enabled. It is possible for Flock users to turn off or restrict sharing,\nbut I think a lot of them honestly don't know that. Some state Attorneys General\nhave ordered Flock users to disable sharing, some have restricted or banned Flock\nproducts entirely, but in general it's a very messy situation. It appears that a\nlack of care by law enforcement and other Flock customers, facilitate and no\ndoubt encouraged by Flock's motivation towards &quot;network effect&quot; lock-in, has\nresulted in widespread and brazen violation of privacy laws that is only now\nmaking its way to the courts.</p>\n<p>In other words, the tech industry happened.</p>\n<h2>Acoustics</h2>\n<p>I will not spend much time here discussing wide-area acoustic surveillance\nlike ShotSpotter, in part because <a href=\"https://computer.rip/2024-03-01-listening-in-on-the-neighborhood.html\">I have written a bit about it before</a>.\nIt's a complex issue: a well-designed gunshot detection system would probably\nbe a good thing, but I find SoundThinking (manufacturer of the ShotSpotter\nsystem) to be profoundly untrustworthy.</p>\n<h2>Futures</h2>\n<p>The changes we are already seeing will continue: ALPR will become more ubiquitous,\nfacial recognition will advance further into the public sphere, and the tech\nindustry will continue to centralize data and facilitate queries by law enforcement.\nThere's a lot of money to me made out of the whole thing, and funding towards law\nenforcement or public safety purchases are usually politically safe. Pretty much\neverything is stacked in the direction of more pervasive surveillance in the United\nStates.</p>\n<p>Do you find that upsetting? It seems that some people do, and some people do not.\nI am probably not as opposed to surveillance of public spaces as the most vocal\nprivacy advocates, but I am also convinced that vendor-enabled mass surveillance\ntechnology like Flock is subject to enormous abuse and will inevitably undermine\nconstitutional protections. Unfortunately, vocal organizing against mass\nsurveillance has become pretty limited. The ACLU is doing a lot of good work\nin this area, but I don't see much public organizing.</p>\n<p>The best thing you can do is probably to advocate for transparency. The most\nalarming part of this whole thing, to me, is the way that police departments\nhave brazenly structured purchases of surveillance technology to get around\npublic record and approval requirements. Companies like Flock and SoundThinking\nencourage this, and write it into their contracts. The end result is that\nmany police departments have installed cameras and microphones in all kinds of\nplaces, and will not disclose when, where, how many, or how they are used.\nWe should not allow that kind of secrecy, but preventing it seems to require\nlegislation. The federal situation seems like a loss, so the best pressure\npoint might be to lobby for municipal or state legislation that will require\npolice departments to disclose their surveillance programs. Even better would\nbe a requirement for review and approval of surveillance purchases, but\nunfortunately that kind of rule often already exists and police departments\nstill structure their purchase arrangements to avoid invoking it.</p>\n<p>I suppose the bottom line is this: keep bringing it up. Mass surveillance in\nthe US often feels like a lost cause, but I suppose it's only lost if we\ngive up. It doesn't take that many people showing up at a city council\nmeeting to make something a priority to the councilors; and perhaps the\npolice can only stonewall for so long. It's worth a shot.</p>",
  "id": "https://computer.rip/2025-12-26-Flock-and-Urban-Surveillance.html"
}