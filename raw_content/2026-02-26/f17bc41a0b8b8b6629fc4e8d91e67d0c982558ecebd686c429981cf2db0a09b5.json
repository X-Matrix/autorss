{
  "title": "Conformalized Neural Networks for Federated Uncertainty Quantification under Dual Heterogeneity",
  "link": "https://arxiv.org/abs/2602.23296v1",
  "published": "2026-02-26T18:07:45Z",
  "updated": "2026-02-26T18:07:45Z",
  "summary": "Federated learning (FL) faces challenges in uncertainty quantification (UQ). Without reliable UQ, FL systems risk deploying overconfident models at under-resourced agents, leading to silent local failures despite seemingly satisfactory global performance. Existing federated UQ approaches often address data heterogeneity or model heterogeneity in isolation, overlooking their joint effect on coverage reliability across agents. Conformal prediction is a widely used distribution-free UQ framework, yet its applications in heterogeneous FL settings remains underexplored. We provide FedWQ-CP, a simple yet effective approach that balances empirical coverage performance with efficiency at both global and agent levels under the dual heterogeneity. FedWQ-CP performs agent-server calibration in a single communication round. On each agent, conformity scores are computed on calibration data and a local quantile threshold is derived. Each agent then transmits only its quantile threshold and calibration sample size to the server. The server simply aggregates these thresholds through a weighted average to produce a global threshold. Experimental results on seven public datasets for both classification and regression demonstrate that FedWQ-CP empirically maintains agent-wise and global coverage while producing the smallest prediction sets or intervals.",
  "id": "http://arxiv.org/abs/2602.23296v1",
  "authors": [
    "Quang-Huy Nguyen",
    "Jiaqi Wang",
    "Wei-Shinn Ku"
  ],
  "categories": [
    "cs.LG",
    "cs.AI"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.23296v1"
}