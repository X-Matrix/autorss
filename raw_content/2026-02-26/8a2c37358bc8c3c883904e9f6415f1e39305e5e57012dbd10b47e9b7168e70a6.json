{
  "title": "Mitigating Legibility Tax with Decoupled Prover-Verifier Games",
  "link": "https://arxiv.org/abs/2602.23248v1",
  "published": "2026-02-26T17:25:22Z",
  "updated": "2026-02-26T17:25:22Z",
  "summary": "As large language models become increasingly capable, it is critical that their outputs can be easily checked by less capable systems. Prover-verifier games can be used to improve checkability of model outputs, but display a degradation in accuracy compared to a baseline trained only to maximize correctness -- a phenonemon named legibility tax. We propose a solution by decoupling the correctness from the checkability condition and instead training a \"translator\" model that turns a fixed solver model's solution into a checkable form. This allows us to first train the solver to maximize correctness, and then train the translator to translate the solver into a checkable form while retaining the solver's answer. To accommodate this new objective of translation, we formulate a decoupled prover-verifier game where the equilibria correspond to faithful and checkable translators.",
  "id": "http://arxiv.org/abs/2602.23248v1",
  "authors": [
    "Yegon Kim",
    "Juho Lee"
  ],
  "categories": [
    "cs.AI"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.23248v1"
}