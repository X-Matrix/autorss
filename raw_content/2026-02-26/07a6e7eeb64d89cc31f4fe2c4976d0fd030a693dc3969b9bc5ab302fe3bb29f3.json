{
  "title": "Devling into Adversarial Transferability on Image Classification: Review, Benchmark, and Evaluation",
  "link": "https://arxiv.org/abs/2602.23117v1",
  "published": "2026-02-26T15:30:36Z",
  "updated": "2026-02-26T15:30:36Z",
  "summary": "Adversarial transferability refers to the capacity of adversarial examples generated on the surrogate model to deceive alternate, unexposed victim models. This property eliminates the need for direct access to the victim model during an attack, thereby raising considerable security concerns in practical applications and attracting substantial research attention recently. In this work, we discern a lack of a standardized framework and criteria for evaluating transfer-based attacks, leading to potentially biased assessments of existing approaches. To rectify this gap, we have conducted an exhaustive review of hundreds of related works, organizing various transfer-based attacks into six distinct categories. Subsequently, we propose a comprehensive framework designed to serve as a benchmark for evaluating these attacks. In addition, we delineate common strategies that enhance adversarial transferability and highlight prevalent issues that could lead to unfair comparisons. Finally, we provide a brief review of transfer-based attacks beyond image classification.",
  "id": "http://arxiv.org/abs/2602.23117v1",
  "authors": [
    "Xiaosen Wang",
    "Zhijin Ge",
    "Bohan Liu",
    "Zheng Fang",
    "Fengfan Zhou",
    "Ruixuan Zhang",
    "Shaokang Wang",
    "Yuyang Luo"
  ],
  "categories": [
    "cs.CV",
    "cs.AI"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.23117v1"
}