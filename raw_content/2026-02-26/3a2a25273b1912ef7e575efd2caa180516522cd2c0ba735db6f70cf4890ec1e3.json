{
  "title": "Obscure but Effective: Classical Chinese Jailbreak Prompt Optimization via Bio-Inspired Search",
  "link": "https://arxiv.org/abs/2602.22983v1",
  "published": "2026-02-26T13:25:35Z",
  "updated": "2026-02-26T13:25:35Z",
  "summary": "As Large Language Models (LLMs) are increasingly used, their security risks have drawn increasing attention. Existing research reveals that LLMs are highly susceptible to jailbreak attacks, with effectiveness varying across language contexts. This paper investigates the role of classical Chinese in jailbreak attacks. Owing to its conciseness and obscurity, classical Chinese can partially bypass existing safety constraints, exposing notable vulnerabilities in LLMs. Based on this observation, this paper proposes a framework, CC-BOS, for the automatic generation of classical Chinese adversarial prompts based on multi-dimensional fruit fly optimization, facilitating efficient and automated jailbreak attacks in black-box settings. Prompts are encoded into eight policy dimensions-covering role, behavior, mechanism, metaphor, expression, knowledge, trigger pattern and context; and iteratively refined via smell search, visual search, and cauchy mutation. This design enables efficient exploration of the search space, thereby enhancing the effectiveness of black-box jailbreak attacks. To enhance readability and evaluation accuracy, we further design a classical Chinese to English translation module. Extensive experiments demonstrate that effectiveness of the proposed CC-BOS, consistently outperforming state-of-the-art jailbreak attack methods.",
  "id": "http://arxiv.org/abs/2602.22983v1",
  "authors": [
    "Xun Huang",
    "Simeng Qin",
    "Xiaoshuang Jia",
    "Ranjie Duan",
    "Huanqian Yan",
    "Zhitao Zeng",
    "Fei Yang",
    "Yang Liu",
    "Xiaojun Jia"
  ],
  "categories": [
    "cs.AI",
    "cs.CR"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.22983v1"
}