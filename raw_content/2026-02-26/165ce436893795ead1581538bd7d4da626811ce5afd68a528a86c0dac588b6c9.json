{
  "title": "On Sample-Efficient Generalized Planning via Learned Transition Models",
  "link": "https://arxiv.org/abs/2602.23148v1",
  "published": "2026-02-26T16:13:46Z",
  "updated": "2026-02-26T16:13:46Z",
  "summary": "Generalized planning studies the construction of solution strategies that generalize across families of planning problems sharing a common domain model, formally defined by a transition function $γ: S \\times A \\rightarrow S$. Classical approaches achieve such generalization through symbolic abstractions and explicit reasoning over $γ$. In contrast, recent Transformer-based planners, such as PlanGPT and Plansformer, largely cast generalized planning as direct action-sequence prediction, bypassing explicit transition modeling. While effective on in-distribution instances, these approaches typically require large datasets and model sizes, and often suffer from state drift in long-horizon settings due to the absence of explicit world-state evolution. In this work, we formulate generalized planning as a transition-model learning problem, in which a neural model explicitly approximates the successor-state function $\\hatγ \\approx γ$ and generates plans by rolling out symbolic state trajectories. Instead of predicting actions directly, the model autoregressively predicts intermediate world states, thereby learning the domain dynamics as an implicit world model. To study size-invariant generalization and sample efficiency, we systematically evaluate multiple state representations and neural architectures, including relational graph encodings. Our results show that learning explicit transition models yields higher out-of-distribution satisficing-plan success than direct action-sequence prediction in multiple domains, while achieving these gains with significantly fewer training instances and smaller models. This is an extended version of a short paper accepted at ICAPS 2026 under the same title.",
  "id": "http://arxiv.org/abs/2602.23148v1",
  "authors": [
    "Nitin Gupta",
    "Vishal Pallagani",
    "John A. Aydin",
    "Biplav Srivastava"
  ],
  "categories": [
    "cs.AI"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.23148v1"
}