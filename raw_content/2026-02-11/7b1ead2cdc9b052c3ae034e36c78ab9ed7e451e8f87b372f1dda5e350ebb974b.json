{
  "title": "Language Model Inversion through End-to-End Differentiation",
  "link": "https://arxiv.org/abs/2602.11044v1",
  "published": "2026-02-11T17:14:41Z",
  "updated": "2026-02-11T17:14:41Z",
  "summary": "Despite emerging research on Language Models (LM), few approaches analyse the invertibility of LMs. That is, given a LM and a desirable target output sequence of tokens, determining what input prompts would yield the target output remains an open problem. We formulate this problem as a classical gradient-based optimisation. First, we propose a simple algorithm to achieve end-to-end differentiability of a given (frozen) LM and then find optimised prompts via gradient descent. Our central insight is to view LMs as functions operating on sequences of distributions over tokens (rather than the traditional view as functions on sequences of tokens). Our experiments and ablations demonstrate that our DLM-powered inversion can reliably and efficiently optimise prompts of lengths $10$ and $80$ for targets of length $20$, for several white-box LMs (out-of-the-box).",
  "id": "http://arxiv.org/abs/2602.11044v1",
  "authors": [
    "Kevin Yandoka Denamgana√Ø",
    "Kartic Subr"
  ],
  "categories": [
    "cs.CL",
    "cs.AI"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.11044v1"
}