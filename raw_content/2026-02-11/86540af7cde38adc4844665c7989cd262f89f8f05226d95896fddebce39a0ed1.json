{
  "title": "Direct Learning of Calibration-Aware Uncertainty for Neural PDE Surrogates",
  "link": "https://arxiv.org/abs/2602.11090v1",
  "published": "2026-02-11T17:57:20Z",
  "updated": "2026-02-11T17:57:20Z",
  "summary": "Neural PDE surrogates are often deployed in data-limited or partially observed regimes where downstream decisions depend on calibrated uncertainty in addition to low prediction error. Existing approaches obtain uncertainty through ensemble replication, fixed stochastic noise such as dropout, or post hoc calibration. Cross-regularized uncertainty learns uncertainty parameters during training using gradients routed through a held-out regularization split. The predictor is optimized on the training split for fit, while low-dimensional uncertainty controls are optimized on the regularization split to reduce train-test mismatch, yielding regime-adaptive uncertainty without per-regime noise tuning. The framework can learn continuous noise levels at the output head, within hidden features, or within operator-specific components such as spectral modes. We instantiate the approach in Fourier Neural Operators and evaluate on APEBench sweeps over observed fraction and training-set size. Across these sweeps, the learned predictive distributions are better calibrated on held-out splits and the resulting uncertainty fields concentrate in high-error regions in one-step spatial diagnostics.",
  "id": "http://arxiv.org/abs/2602.11090v1",
  "authors": [
    "Carlos Stein Brito"
  ],
  "categories": [
    "cs.LG",
    "cs.AI",
    "cs.CE",
    "stat.CO"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.11090v1"
}