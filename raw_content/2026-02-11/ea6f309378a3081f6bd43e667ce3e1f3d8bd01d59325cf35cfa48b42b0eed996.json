{
  "title": "Search or Accelerate: Confidence-Switched Position Beam Search for Diffusion Language Models",
  "link": "https://arxiv.org/abs/2602.10953v1",
  "published": "2026-02-11T15:41:09Z",
  "updated": "2026-02-11T15:41:09Z",
  "summary": "Diffusion Language Models (DLMs) generate text by iteratively denoising a masked sequence, repeatedly deciding which positions to commit at each step. Standard decoding follows a greedy rule: unmask the most confident positions, yet this local choice can lock the model into a suboptimal unmasking order, especially on reasoning-heavy prompts. We present SOAR, a training-free decoding algorithm that adapts its behavior to the model's uncertainty. When confidence is low, SOAR briefly widens the search over alternative unmasking decisions to avoid premature commitments; when confidence is high, it collapses the search and decodes many positions in parallel to reduce the number of denoising iterations. Across mathematical reasoning and code generation benchmarks (GSM8K, MBPP, HumanEval) on Dream-7B and LLaDA-8B, SOAR improves generation quality while maintaining competitive inference speed, offering a practical way to balance quality and efficiency in DLM decoding.",
  "id": "http://arxiv.org/abs/2602.10953v1",
  "authors": [
    "Mingyu Cao",
    "Alvaro Correia",
    "Christos Louizos",
    "Shiwei Liu",
    "Lu Yin"
  ],
  "categories": [
    "cs.CL",
    "cs.AI"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.10953v1"
}