{
  "title": "Resource-Efficient Model-Free Reinforcement Learning for Board Games",
  "link": "https://arxiv.org/abs/2602.10894v1",
  "published": "2026-02-11T14:25:38Z",
  "updated": "2026-02-11T14:25:38Z",
  "summary": "Board games have long served as complex decision-making benchmarks in artificial intelligence. In this field, search-based reinforcement learning methods such as AlphaZero have achieved remarkable success. However, their significant computational demands have been pointed out as barriers to their reproducibility. In this study, we propose a model-free reinforcement learning algorithm designed for board games to achieve more efficient learning. To validate the efficiency of the proposed method, we conducted comprehensive experiments on five board games: Animal Shogi, Gardner Chess, Go, Hex, and Othello. The results demonstrate that the proposed method achieves more efficient learning than existing methods across these environments. In addition, our extensive ablation study shows the importance of core techniques used in the proposed method. We believe that our efficient algorithm shows the potential of model-free reinforcement learning in domains traditionally dominated by search-based methods.",
  "id": "http://arxiv.org/abs/2602.10894v1",
  "authors": [
    "Kazuki Ota",
    "Takayuki Osa",
    "Motoki Omura",
    "Tatsuya Harada"
  ],
  "categories": [
    "cs.LG",
    "cs.AI"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.10894v1"
}