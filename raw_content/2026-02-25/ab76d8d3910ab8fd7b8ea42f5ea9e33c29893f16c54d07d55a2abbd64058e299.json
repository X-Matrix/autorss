{
  "title": "ProactiveMobile: A Comprehensive Benchmark for Boosting Proactive Intelligence on Mobile Devices",
  "link": "https://arxiv.org/abs/2602.21858v1",
  "published": "2026-02-25T12:32:37Z",
  "updated": "2026-02-25T12:32:37Z",
  "summary": "Multimodal large language models (MLLMs) have made significant progress in mobile agent development, yet their capabilities are predominantly confined to a reactive paradigm, where they merely execute explicit user commands. The emerging paradigm of proactive intelligence, where agents autonomously anticipate needs and initiate actions, represents the next frontier for mobile agents. However, its development is critically bottlenecked by the lack of benchmarks that can address real-world complexity and enable objective, executable evaluation. To overcome these challenges, we introduce ProactiveMobile, a comprehensive benchmark designed to systematically advance research in this domain. ProactiveMobile formalizes the proactive task as inferring latent user intent across four dimensions of on-device contextual signals and generating an executable function sequence from a comprehensive function pool of 63 APIs. The benchmark features over 3,660 instances of 14 scenarios that embrace real-world complexity through multi-answer annotations. To ensure quality, a team of 30 experts conducts a final audit of the benchmark, verifying factual accuracy, logical consistency, and action feasibility, and correcting any non-compliant entries. Extensive experiments demonstrate that our fine-tuned Qwen2.5-VL-7B-Instruct achieves a success rate of 19.15%, outperforming o1 (15.71%) and GPT-5 (7.39%). This result indicates that proactivity is a critical competency widely lacking in current MLLMs, yet it is learnable, emphasizing the importance of the proposed benchmark for proactivity evaluation.",
  "id": "http://arxiv.org/abs/2602.21858v1",
  "authors": [
    "Dezhi Kong",
    "Zhengzhao Feng",
    "Qiliang Liang",
    "Hao Wang",
    "Haofei Sun",
    "Changpeng Yang",
    "Yang Li",
    "Peng Zhou",
    "Shuai Nie",
    "Hongzhen Wang",
    "Linfeng Zhou",
    "Hao Jia",
    "Jiaming Xu",
    "Runyu Shi",
    "Ying Huang"
  ],
  "categories": [
    "cs.AI"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.21858v1"
}