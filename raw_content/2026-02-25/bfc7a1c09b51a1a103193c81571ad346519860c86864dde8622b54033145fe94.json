{
  "title": "SWE-Protégé: Learning to Selectively Collaborate With an Expert Unlocks Small Language Models as Software Engineering Agents",
  "link": "https://arxiv.org/abs/2602.22124v1",
  "published": "2026-02-25T17:11:49Z",
  "updated": "2026-02-25T17:11:49Z",
  "summary": "Small language models (SLMs) offer compelling advantages in cost, latency, and adaptability, but have so far lagged behind larger models on long-horizon software engineering tasks such as SWE-bench, where they suffer from pervasive action looping and low resolution rates. We introduce SWE-Protégé, a post-training framework that reframes software repair as an expert-protégé collaboration problem. In SWE-Protégé, an SLM remains the sole decision-maker while learning to selectively seek guidance from a strong expert model, recognize stalled states, and follow through on expert feedback. Our approach combines supervised fine-tuning on expert-augmented trajectories with agentic reinforcement learning that explicitly discourages degenerative looping and unproductive expert collaboration. We lightly post-train Qwen2.5-Coder-7B-Instruct to achieve 42.4% Pass@1 on SWE-bench Verified, a +25.4% improvement over the prior SLM state of the art, while using expert assistance sparsely (~4 calls per task and 11% of total tokens).",
  "id": "http://arxiv.org/abs/2602.22124v1",
  "authors": [
    "Patrick Tser Jern Kon",
    "Archana Pradeep",
    "Ang Chen",
    "Alexander P. Ellis",
    "Warren Hunt",
    "Zijian Wang",
    "John Yang",
    "Samuel Thompson"
  ],
  "categories": [
    "cs.SE",
    "cs.AI",
    "cs.CL",
    "cs.LG"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.22124v1"
}