{
  "title": "UniWhisper: Efficient Continual Multi-task Training for Robust Universal Audio Representation",
  "link": "https://arxiv.org/abs/2602.21772v1",
  "published": "2026-02-25T10:47:20Z",
  "updated": "2026-02-25T10:47:20Z",
  "summary": "A universal audio representation should capture fine-grained speech cues and high-level semantics for environmental sounds and music in a single encoder. Existing encoders often excel in one domain but degrade in others. We propose UniWhisper, an efficient continual multi-task training framework that casts heterogeneous audio tasks into a unified instruction and answer format. This enables standard next-token training without task-specific heads and losses. We train it on 38k hours of public audio and assess the encoder using shallow MLP probes and k-nearest neighbors (kNN) on 20 tasks spanning speech, environmental sound, and music. UniWhisper reaches normalized weighted averages of 0.81 with MLP probes and 0.61 with kNN, compared to 0.64 and 0.46 for Whisper, while retaining strong speech performance.",
  "id": "http://arxiv.org/abs/2602.21772v1",
  "authors": [
    "Yuxuan Chen",
    "Peize He",
    "Haoyuan Xu",
    "Junzi Zhang"
  ],
  "categories": [
    "cs.SD",
    "cs.AI"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.21772v1"
}