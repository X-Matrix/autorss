{
  "title": "HeatPrompt: Zero-Shot Vision-Language Modeling of Urban Heat Demand from Satellite Images",
  "link": "https://arxiv.org/abs/2602.20066v1",
  "published": "2026-02-23T17:22:54Z",
  "updated": "2026-02-23T17:22:54Z",
  "summary": "Accurate heat-demand maps play a crucial role in decarbonizing space heating, yet most municipalities lack detailed building-level data needed to calculate them. We introduce HeatPrompt, a zero-shot vision-language energy modeling framework that estimates annual heat demand using semantic features extracted from satellite images, basic Geographic Information System (GIS), and building-level features. We feed pretrained Large Vision Language Models (VLMs) with a domain-specific prompt to act as an energy planner and extract the visual attributes such as roof age, building density, etc, from the RGB satellite image that correspond to the thermal load. A Multi-Layer Perceptron (MLP) regressor trained on these captions shows an $R^2$ uplift of 93.7% and shrinks the mean absolute error (MAE) by 30% compared to the baseline model. Qualitative analysis shows that high-impact tokens align with high-demand zones, offering lightweight support for heat planning in data-scarce regions.",
  "id": "http://arxiv.org/abs/2602.20066v1",
  "authors": [
    "Kundan Thota",
    "Xuanhao Mu",
    "Thorsten Schlachter",
    "Veit Hagenmeyer"
  ],
  "categories": [
    "cs.CV",
    "cs.AI"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.20066v1"
}