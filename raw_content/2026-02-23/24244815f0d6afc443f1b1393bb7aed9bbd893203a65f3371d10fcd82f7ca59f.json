{
  "title": "Align When They Want, Complement When They Need! Human-Centered Ensembles for Adaptive Human-AI Collaboration",
  "link": "https://arxiv.org/abs/2602.20104v1",
  "published": "2026-02-23T18:22:58Z",
  "updated": "2026-02-23T18:22:58Z",
  "summary": "In human-AI decision making, designing AI that complements human expertise has been a natural strategy to enhance human-AI collaboration, yet it often comes at the cost of decreased AI performance in areas of human strengths. This can inadvertently erode human trust and cause them to ignore AI advice precisely when it is most needed. Conversely, an aligned AI fosters trust yet risks reinforcing suboptimal human behavior and lowering human-AI team performance. In this paper, we start by identifying this fundamental tension between performance-boosting (i.e., complementarity) and trust-building (i.e., alignment) as an inherent limitation of the traditional approach for training a single AI model to assist human decision making. To overcome this, we introduce a novel human-centered adaptive AI ensemble that strategically toggles between two specialist AI models - the aligned model and the complementary model - based on contextual cues, using an elegantly simple yet provably near-optimal Rational Routing Shortcut mechanism. Comprehensive theoretical analyses elucidate why the adaptive AI ensemble is effective and when it yields maximum benefits. Moreover, experiments on both simulated and real-world data show that when humans are assisted by the adaptive AI ensemble in decision making, they can achieve significantly higher performance than when they are assisted by single AI models that are trained to either optimize for their independent performance or even the human-AI team performance.",
  "id": "http://arxiv.org/abs/2602.20104v1",
  "authors": [
    "Hasan Amin",
    "Ming Yin",
    "Rajiv Khanna"
  ],
  "categories": [
    "cs.AI",
    "cs.HC",
    "cs.LG"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.20104v1"
}