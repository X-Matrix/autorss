{
  "title": "AgenticSum: An Agentic Inference-Time Framework for Faithful Clinical Text Summarization",
  "link": "https://arxiv.org/abs/2602.20040v1",
  "published": "2026-02-23T16:49:37Z",
  "updated": "2026-02-23T16:49:37Z",
  "summary": "Large language models (LLMs) offer substantial promise for automating clinical text summarization, yet maintaining factual consistency remains challenging due to the length, noise, and heterogeneity of clinical documentation. We present AgenticSum, an inference-time, agentic framework that separates context selection, generation, verification, and targeted correction to reduce hallucinated content. The framework decomposes summarization into coordinated stages that compress task-relevant context, generate an initial draft, identify weakly supported spans using internal attention grounding signals, and selectively revise flagged content under supervisory control. We evaluate AgenticSum on two public datasets, using reference-based metrics, LLM-as-a-judge assessment, and human evaluation. Across various measures, AgenticSum demonstrates consistent improvements compared to vanilla LLMs and other strong baselines. Our results indicate that structured, agentic design with targeted correction offers an effective inference time solution to improve clinical note summarization using LLMs.",
  "id": "http://arxiv.org/abs/2602.20040v1",
  "authors": [
    "Fahmida Liza Piya",
    "Rahmatollah Beheshti"
  ],
  "categories": [
    "cs.CL",
    "cs.AI"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.20040v1"
}