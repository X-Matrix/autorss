{
  "title": "Universal Algorithm-Implicit Learning",
  "link": "https://arxiv.org/abs/2602.14761v1",
  "published": "2026-02-16T14:05:07Z",
  "updated": "2026-02-16T14:05:07Z",
  "summary": "Current meta-learning methods are constrained to narrow task distributions with fixed feature and label spaces, limiting applicability. Moreover, the current meta-learning literature uses key terms like \"universal\" and \"general-purpose\" inconsistently and lacks precise definitions, hindering comparability. We introduce a theoretical framework for meta-learning which formally defines practical universality and introduces a distinction between algorithm-explicit and algorithm-implicit learning, providing a principled vocabulary for reasoning about universal meta-learning methods. Guided by this framework, we present TAIL, a transformer-based algorithm-implicit meta-learner that functions across tasks with varying domains, modalities, and label configurations. TAIL features three innovations over prior transformer-based meta-learners: random projections for cross-modal feature encoding, random injection label embeddings that extrapolate to larger label spaces, and efficient inline query processing. TAIL achieves state-of-the-art performance on standard few-shot benchmarks while generalizing to unseen domains. Unlike other meta-learning methods, it also generalizes to unseen modalities, solving text classification tasks despite training exclusively on images, handles tasks with up to 20$\\times$ more classes than seen during training, and provides orders-of-magnitude computational savings over prior transformer-based approaches.",
  "id": "http://arxiv.org/abs/2602.14761v1",
  "authors": [
    "Stefano Woerner",
    "Seong Joon Oh",
    "Christian F. Baumgartner"
  ],
  "categories": [
    "cs.LG",
    "cs.AI",
    "cs.CV"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.14761v1"
}