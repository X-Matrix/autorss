{
  "title": "Debiasing Central Fixation Confounds Reveals a Peripheral \"Sweet Spot\" for Human-like Scanpaths in Hard-Attention Vision",
  "link": "https://arxiv.org/abs/2602.14834v1",
  "published": "2026-02-16T15:25:26Z",
  "updated": "2026-02-16T15:25:26Z",
  "summary": "Human eye movements in visual recognition reflect a balance between foveal sampling and peripheral context. Task-driven hard-attention models for vision are often evaluated by how well their scanpaths match human gaze. However, common scanpath metrics can be strongly confounded by dataset-specific center bias, especially on object-centric datasets. Using Gaze-CIFAR-10, we show that a trivial center-fixation baseline achieves surprisingly strong scanpath scores, approaching many learned policies. This makes standard metrics optimistic and blurs the distinction between genuine behavioral alignment and mere central tendency. We then analyze a hard-attention classifier under constrained vision by sweeping foveal patch size and peripheral context, revealing a peripheral sweet spot: only a narrow range of sensory constraints yields scanpaths that are simultaneously (i) above the center baseline after debiasing and (ii) temporally human-like in movement statistics. To address center bias, we propose GCS (Gaze Consistency Score), a center-debiased composite metric augmented with movement similarity. GCS uncovers a robust sweet spot at medium patch size with both foveal and peripheral vision, that is not obvious from raw scanpath metrics or accuracy alone, and also highlights a \"shortcut regime\" when the field-of-view becomes too large. We discuss implications for evaluating active perception on object-centric datasets and for designing gaze benchmarks that better separate behavioral alignment from center bias.",
  "id": "http://arxiv.org/abs/2602.14834v1",
  "authors": [
    "Pengcheng Pan",
    "Yonekura Shogo",
    "Yasuo Kuniyosh"
  ],
  "categories": [
    "cs.CV",
    "cs.AI"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.14834v1"
}