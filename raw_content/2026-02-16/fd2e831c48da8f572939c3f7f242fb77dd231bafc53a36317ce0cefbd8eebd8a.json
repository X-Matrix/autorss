{
  "title": "The Potential of CoT for Reasoning: A Closer Look at Trace Dynamics",
  "link": "https://arxiv.org/abs/2602.14903v1",
  "published": "2026-02-16T16:38:47Z",
  "updated": "2026-02-16T16:38:47Z",
  "summary": "Chain-of-thought (CoT) prompting is a de-facto standard technique to elicit reasoning-like responses from large language models (LLMs), allowing them to spell out individual steps before giving a final answer. While the resemblance to human-like reasoning is undeniable, the driving forces underpinning the success of CoT reasoning still remain largely unclear. In this work, we perform an in-depth analysis of CoT traces originating from competition-level mathematics questions, with the aim of better understanding how, and which parts of CoT actually contribute to the final answer. To this end, we introduce the notion of a potential, quantifying how much a given part of CoT increases the likelihood of a correct completion. Upon examination of reasoning traces through the lens of the potential, we identify surprising patterns including (1) its often strong non-monotonicity (due to reasoning tangents), (2) very sharp but sometimes tough to interpret spikes (reasoning insights and jumps) as well as (3) at times lucky guesses, where the model arrives at the correct answer without providing any relevant justifications before. While some of the behaviours of the potential are readily interpretable and align with human intuition (such as insights and tangents), others remain difficult to understand from a human perspective. To further quantify the reliance of LLMs on reasoning insights, we investigate the notion of CoT transferability, where we measure the potential of a weaker model under the partial CoT from another, stronger model. Indeed aligning with our previous results, we find that as little as 20% of partial CoT can ``unlock'' the performance of the weaker model on problems that were previously unsolvable for it, highlighting that a large part of the mechanics underpinning CoT are transferable.",
  "id": "http://arxiv.org/abs/2602.14903v1",
  "authors": [
    "Gregor Bachmann",
    "Yichen Jiang",
    "Seyed Mohsen Moosavi Dezfooli",
    "Moin Nabi"
  ],
  "categories": [
    "cs.AI"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.14903v1"
}