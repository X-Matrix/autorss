{
  "title": "Color-based Emotion Representation for Speech Emotion Recognition",
  "link": "https://arxiv.org/abs/2602.16256v1",
  "published": "2026-02-18T08:11:49Z",
  "updated": "2026-02-18T08:11:49Z",
  "summary": "Speech emotion recognition (SER) has traditionally relied on categorical or dimensional labels. However, this technique is limited in representing both the diversity and interpretability of emotions. To overcome this limitation, we focus on color attributes, such as hue, saturation, and value, to represent emotions as continuous and interpretable scores. We annotated an emotional speech corpus with color attributes via crowdsourcing and analyzed them. Moreover, we built regression models for color attributes in SER using machine learning and deep learning, and explored the multitask learning of color attribute regression and emotion classification. As a result, we demonstrated the relationship between color attributes and emotions in speech, and successfully developed color attribute regression models for SER. We also showed that multitask learning improved the performance of each task.",
  "id": "http://arxiv.org/abs/2602.16256v1",
  "authors": [
    "Ryotaro Nagase",
    "Ryoichi Takashima",
    "Yoichi Yamashita"
  ],
  "categories": [
    "eess.AS",
    "cs.AI",
    "cs.SD"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.16256v1"
}