{
  "title": "Toward Scalable Verifiable Reward: Proxy State-Based Evaluation for Multi-turn Tool-Calling LLM Agents",
  "link": "https://arxiv.org/abs/2602.16246v1",
  "published": "2026-02-18T07:49:47Z",
  "updated": "2026-02-18T07:49:47Z",
  "summary": "Interactive large language model (LLM) agents operating via multi-turn dialogue and multi-step tool calling are increasingly used in production. Benchmarks for these agents must both reliably compare models and yield on-policy training data. Prior agentic benchmarks (e.g., tau-bench, tau2-bench, AppWorld) rely on fully deterministic backends, which are costly to build and iterate. We propose Proxy State-Based Evaluation, an LLM-driven simulation framework that preserves final state-based evaluation without a deterministic database. Specifically, a scenario specifies the user goal, user/system facts, expected final state, and expected agent behavior, and an LLM state tracker infers a structured proxy state from the full interaction trace. LLM judges then verify goal completion and detect tool/user hallucinations against scenario constraints. Empirically, our benchmark produces stable, model-differentiating rankings across families and inference-time reasoning efforts, and its on-/off-policy rollouts provide supervision that transfers to unseen scenarios. Careful scenario specification yields near-zero simulator hallucination rates as supported by ablation studies. The framework also supports sensitivity analyses over user personas. Human-LLM judge agreement exceeds 90%, indicating reliable automated evaluation. Overall, proxy state-based evaluation offers a practical, scalable alternative to deterministic agentic benchmarks for industrial LLM agents.",
  "id": "http://arxiv.org/abs/2602.16246v1",
  "authors": [
    "Yun-Shiuan Chuang",
    "Chaitanya Kulkarni",
    "Alec Chiu",
    "Avinash Thangali",
    "Zijie Pan",
    "Shivani Shekhar",
    "Yirou Ge",
    "Yixi Li",
    "Uma Kona",
    "Linsey Pang",
    "Prakhar Mehrotra"
  ],
  "categories": [
    "cs.AI"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.16246v1"
}