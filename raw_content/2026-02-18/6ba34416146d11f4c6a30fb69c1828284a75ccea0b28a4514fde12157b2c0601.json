{
  "title": "Team of Thoughts: Efficient Test-time Scaling of Agentic Systems through Orchestrated Tool Calling",
  "link": "https://arxiv.org/abs/2602.16485v1",
  "published": "2026-02-18T14:19:01Z",
  "updated": "2026-02-18T14:19:01Z",
  "summary": "Existing Multi-Agent Systems (MAS) typically rely on static, homogeneous model configurations, limiting their ability to exploit the distinct strengths of differently post-trained models. To address this, we introduce Team-of-Thoughts, a novel MAS architecture that leverages the complementary capabilities of heterogeneous agents via an orchestrator-tool paradigm. Our framework introduces two key mechanisms to optimize performance: (1) an orchestrator calibration scheme that identifies models with superior coordination capabilities, and (2) a self-assessment protocol where tool agents profile their own domain expertise to account for variations in post-training skills. During inference, the orchestrator dynamically activates the most suitable tool agents based on these proficiency profiles. Experiments on five reasoning and code generation benchmarks show that Team-of-Thoughts delivers consistently superior task performance. Notably, on AIME24 and LiveCodeBench, our approach achieves accuracies of 96.67% and 72.53%, respectively, substantially outperforming homogeneous role-play baselines, which score 80% and 65.93%.",
  "id": "http://arxiv.org/abs/2602.16485v1",
  "authors": [
    "Jeffrey T. H. Wong",
    "Zixi Zhang",
    "Junyi Liu",
    "Yiren Zhao"
  ],
  "categories": [
    "cs.CL",
    "cs.AI",
    "cs.MA"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.16485v1"
}