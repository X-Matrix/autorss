{
  "title": "GenAI-LA: Generative AI and Learning Analytics Workshop (LAK 2026), April 27--May 1, 2026, Bergen, Norway",
  "link": "https://arxiv.org/abs/2602.15531v1",
  "published": "2026-02-17T12:11:49Z",
  "updated": "2026-02-17T12:11:49Z",
  "summary": "This work introduces EduEVAL-DB, a dataset based on teacher roles designed to support the evaluation and training of automatic pedagogical evaluators and AI tutors for instructional explanations. The dataset comprises 854 explanations corresponding to 139 questions from a curated subset of the ScienceQA benchmark, spanning science, language, and social science across K-12 grade levels. For each question, one human-teacher explanation is provided and six are generated by LLM-simulated teacher roles. These roles are inspired by instructional styles and shortcomings observed in real educational practice and are instantiated via prompt engineering. We further propose a pedagogical risk rubric aligned with established educational standards, operationalizing five complementary risk dimensions: factual correctness, explanatory depth and completeness, focus and relevance, student-level appropriateness, and ideological bias. All explanations are annotated with binary risk labels through a semi-automatic process with expert teacher review. Finally, we present preliminary validation experiments to assess the suitability of EduEVAL-DB for evaluation. We benchmark a state-of-the-art education-oriented model (Gemini 2.5 Pro) against a lightweight local Llama 3.1 8B model and examine whether supervised fine-tuning on EduEVAL-DB supports pedagogical risk detection using models deployable on consumer hardware.",
  "id": "http://arxiv.org/abs/2602.15531v1",
  "authors": [
    "Javier Irigoyen",
    "Roberto Daza",
    "Aythami Morales",
    "Julian Fierrez",
    "Francisco Jurado",
    "Alvaro Ortigosa",
    "Ruben Tolosana"
  ],
  "categories": [
    "cs.AI",
    "cs.DB"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.15531v1"
}