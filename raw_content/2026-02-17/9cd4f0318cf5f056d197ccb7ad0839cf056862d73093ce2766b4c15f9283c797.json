{
  "title": "VLM-DEWM: Dynamic External World Model for Verifiable and Resilient Vision-Language Planning in Manufacturing",
  "link": "https://arxiv.org/abs/2602.15549v1",
  "published": "2026-02-17T12:54:18Z",
  "updated": "2026-02-17T12:54:18Z",
  "summary": "Vision-language model (VLM) shows promise for high-level planning in smart manufacturing, yet their deployment in dynamic workcells faces two critical challenges: (1) stateless operation, they cannot persistently track out-of-view states, causing world-state drift; and (2) opaque reasoning, failures are difficult to diagnose, leading to costly blind retries. This paper presents VLM-DEWM, a cognitive architecture that decouples VLM reasoning from world-state management through a persistent, queryable Dynamic External World Model (DEWM). Each VLM decision is structured into an Externalizable Reasoning Trace (ERT), comprising action proposal, world belief, and causal assumption, which is validated against DEWM before execution. When failures occur, discrepancy analysis between predicted and observed states enables targeted recovery instead of global replanning. We evaluate VLM-DEWM on multi-station assembly, large-scale facility exploration, and real-robot recovery under induced failures. Compared to baseline memory-augmented VLM systems, VLM DEWM improves state-tracking accuracy from 56% to 93%, increases recovery success rate from below 5% to 95%, and significantly reduces computational overhead through structured memory. These results establish VLM-DEWM as a verifiable and resilient solution for long-horizon robotic operations in dynamic manufacturing environments.",
  "id": "http://arxiv.org/abs/2602.15549v1",
  "authors": [
    "Guoqin Tang",
    "Qingxuan Jia",
    "Gang Chen",
    "Tong Li",
    "Zeyuan Huang",
    "Zihang Lv",
    "Ning Ji"
  ],
  "categories": [
    "cs.RO",
    "cs.AI"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.15549v1"
}