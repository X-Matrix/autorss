{
  "title": "Beyond Static Pipelines: Learning Dynamic Workflows for Text-to-SQL",
  "link": "https://arxiv.org/abs/2602.15564v1",
  "published": "2026-02-17T13:24:56Z",
  "updated": "2026-02-17T13:24:56Z",
  "summary": "Text-to-SQL has recently achieved impressive progress, yet remains difficult to apply effectively in real-world scenarios. This gap stems from the reliance on single static workflows, fundamentally limiting scalability to out-of-distribution and long-tail scenarios. Instead of requiring users to select suitable methods through extensive experimentation, we attempt to enable systems to adaptively construct workflows at inference time. Through theoretical and empirical analysis, we demonstrate that optimal dynamic policies consistently outperform the best static workflow, with performance gains fundamentally driven by heterogeneity across candidate workflows. Motivated by this, we propose SquRL, a reinforcement learning framework that enhances LLMs' reasoning capability in adaptive workflow construction. We design a rule-based reward function and introduce two effective training mechanisms: dynamic actor masking to encourage broader exploration, and pseudo rewards to improve training efficiency. Experiments on widely-used Text-to-SQL benchmarks demonstrate that dynamic workflow construction consistently outperforms the best static workflow methods, with especially pronounced gains on complex and out-of-distribution queries. The codes are available at https://github.com/Satissss/SquRL",
  "id": "http://arxiv.org/abs/2602.15564v1",
  "authors": [
    "Yihan Wang",
    "Peiyu Liu",
    "Runyu Chen",
    "Wei Xu"
  ],
  "categories": [
    "cs.CL",
    "cs.AI"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.15564v1"
}