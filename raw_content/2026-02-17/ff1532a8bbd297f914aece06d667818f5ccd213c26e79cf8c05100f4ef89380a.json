{
  "title": "Beyond Binary Classification: Detecting Fine-Grained Sexism in Social Media Videos",
  "link": "https://arxiv.org/abs/2602.15757v1",
  "published": "2026-02-17T17:45:28Z",
  "updated": "2026-02-17T17:45:28Z",
  "summary": "Online sexism appears in various forms, which makes its detection challenging. Although automated tools can enhance the identification of sexist content, they are often restricted to binary classification. Consequently, more subtle manifestations of sexism may remain undetected due to the lack of fine-grained, context-sensitive labels. To address this issue, we make the following contributions: (1) we present FineMuSe, a new multimodal sexism detection dataset in Spanish that includes both binary and fine-grained annotations; (2) we introduce a comprehensive hierarchical taxonomy that encompasses forms of sexism, non-sexism, and rhetorical devices of irony and humor; and (3) we evaluate a wide range of LLMs for both binary and fine-grained sexism detection. Our findings indicate that multimodal LLMs perform competitively with human annotators in identifying nuanced forms of sexism; however, they struggle to capture co-occurring sexist types when these are conveyed through visual cues.",
  "id": "http://arxiv.org/abs/2602.15757v1",
  "authors": [
    "Laura De Grazia",
    "Danae Sánchez Villegas",
    "Desmond Elliott",
    "Mireia Farrús",
    "Mariona Taulé"
  ],
  "categories": [
    "cs.CL",
    "cs.AI"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.15757v1"
}