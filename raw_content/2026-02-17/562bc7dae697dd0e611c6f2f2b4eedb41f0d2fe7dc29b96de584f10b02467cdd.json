{
  "title": "Dynamic Training-Free Fusion of Subject and Style LoRAs",
  "link": "https://arxiv.org/abs/2602.15539v1",
  "published": "2026-02-17T12:42:30Z",
  "updated": "2026-02-17T12:42:30Z",
  "summary": "Recent studies have explored the combination of multiple LoRAs to simultaneously generate user-specified subjects and styles. However, most existing approaches fuse LoRA weights using static statistical heuristics that deviate from LoRA's original purpose of learning adaptive feature adjustments and ignore the randomness of sampled inputs. To address this, we propose a dynamic training-free fusion framework that operates throughout the generation process. During the forward pass, at each LoRA-applied layer, we dynamically compute the KL divergence between the base model's original features and those produced by subject and style LoRAs, respectively, and adaptively select the most appropriate weights for fusion. In the reverse denoising stage, we further refine the generation trajectory by dynamically applying gradient-based corrections derived from objective metrics such as CLIP and DINO scores, providing continuous semantic and stylistic guidance. By integrating these two complementary mechanisms-feature-level selection and metric-guided latent adjustment-across the entire diffusion timeline, our method dynamically achieves coherent subject-style synthesis without any retraining. Extensive experiments across diverse subject-style combinations demonstrate that our approach consistently outperforms state-of-the-art LoRA fusion methods both qualitatively and quantitatively.",
  "id": "http://arxiv.org/abs/2602.15539v1",
  "authors": [
    "Qinglong Cao",
    "Yuntian Chen",
    "Chao Ma",
    "Xiaokang Yang"
  ],
  "categories": [
    "cs.CV",
    "cs.AI",
    "cs.SC"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.15539v1"
}