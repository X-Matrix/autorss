{
  "title": "DynaHOI: Benchmarking Hand-Object Interaction for Dynamic Target",
  "link": "https://arxiv.org/abs/2602.11919v1",
  "published": "2026-02-12T13:19:41Z",
  "updated": "2026-02-12T13:19:41Z",
  "summary": "Most existing hand motion generation benchmarks for hand-object interaction (HOI) focus on static objects, leaving dynamic scenarios with moving targets and time-critical coordination largely untested. To address this gap, we introduce the DynaHOI-Gym, a unified online closed-loop platform with parameterized motion generators and rollout-based metrics for dynamic capture evaluation. Built on DynaHOI-Gym, we release DynaHOI-10M, a large-scale benchmark with 10M frames and 180K hand capture trajectories, whose target motions are organized into 8 major categories and 22 fine-grained subcategories. We also provide a simple observe-before-act baseline (ObAct) that integrates short-term observations with the current frame via spatiotemporal attention to predict actions, achieving an 8.1% improvement in location success rate.",
  "id": "http://arxiv.org/abs/2602.11919v1",
  "authors": [
    "BoCheng Hu",
    "Zhonghan Zhao",
    "Kaiyue Zhou",
    "Hongwei Wang",
    "Gaoang Wang"
  ],
  "categories": [
    "cs.CV",
    "cs.AI"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.11919v1"
}