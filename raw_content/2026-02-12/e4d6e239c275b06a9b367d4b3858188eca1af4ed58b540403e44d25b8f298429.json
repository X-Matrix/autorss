{
  "title": "Differentiable Modal Logic for Multi-Agent Diagnosis, Orchestration and Communication",
  "link": "https://arxiv.org/abs/2602.12083v1",
  "published": "2026-02-12T15:39:18Z",
  "updated": "2026-02-12T15:39:18Z",
  "summary": "As multi-agent AI systems evolve from simple chatbots to autonomous swarms, debugging semantic failures requires reasoning about knowledge, belief, causality, and obligation, precisely what modal logic was designed to formalize. However, traditional modal logic requires manual specification of relationship structures that are unknown or dynamic in real systems. This tutorial demonstrates differentiable modal logic (DML), implemented via Modal Logical Neural Networks (MLNNs), enabling systems to learn trust networks, causal chains, and regulatory boundaries from behavioral data alone.   We present a unified neurosymbolic debugging framework through four modalities: epistemic (who to trust), temporal (when events cause failures), deontic (what actions are permitted), and doxastic (how to interpret agent confidence). Each modality is demonstrated on concrete multi-agent scenarios, from discovering deceptive alliances in diplomacy games to detecting LLM hallucinations, with complete implementations showing how logical contradictions become learnable optimization objectives. Key contributions for the neurosymbolic community: (1) interpretable learned structures where trust and causality are explicit parameters, not opaque embeddings; (2) knowledge injection via differentiable axioms that guide learning with sparse data (3) compositional multi-modal reasoning that combines epistemic, temporal, and deontic constraints; and (4) practical deployment patterns for monitoring, active control and communication of multi-agent systems. All code provided as executable Jupyter notebooks.",
  "id": "http://arxiv.org/abs/2602.12083v1",
  "authors": [
    "Antonin Sulc"
  ],
  "categories": [
    "cs.AI",
    "cs.LO"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.12083v1"
}