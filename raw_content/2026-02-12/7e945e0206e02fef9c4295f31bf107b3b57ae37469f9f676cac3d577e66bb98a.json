{
  "title": "Intrinsic-Energy Joint Embedding Predictive Architectures Induce Quasimetric Spaces",
  "link": "https://arxiv.org/abs/2602.12245v1",
  "published": "2026-02-12T18:30:27Z",
  "updated": "2026-02-12T18:30:27Z",
  "summary": "Joint-Embedding Predictive Architectures (JEPAs) aim to learn representations by predicting target embeddings from context embeddings, inducing a scalar compatibility energy in a latent space. In contrast, Quasimetric Reinforcement Learning (QRL) studies goal-conditioned control through directed distance values (cost-to-go) that support reaching goals under asymmetric dynamics. In this short article, we connect these viewpoints by restricting attention to a principled class of JEPA energy functions : intrinsic (least-action) energies, defined as infima of accumulated local effort over admissible trajectories between two states. Under mild closure and additivity assumptions, any intrinsic energy is a quasimetric. In goal-reaching control, optimal cost-to-go functions admit exactly this intrinsic form ; inversely, JEPAs trained to model intrinsic energies lie in the quasimetric value class targeted by QRL. Moreover, we observe why symmetric finite energies are structurally mismatched with one-way reachability, motivating asymmetric (quasimetric) energies when directionality matters.",
  "id": "http://arxiv.org/abs/2602.12245v1",
  "authors": [
    "Anthony Kobanda",
    "Waris Radji"
  ],
  "categories": [
    "cs.LG",
    "cs.AI"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.12245v1"
}