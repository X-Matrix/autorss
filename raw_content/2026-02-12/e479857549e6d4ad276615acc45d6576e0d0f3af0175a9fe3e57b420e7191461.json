{
  "title": "InjectRBP: Steering Large Language Model Reasoning Behavior via Pattern Injection",
  "link": "https://arxiv.org/abs/2602.12013v1",
  "published": "2026-02-12T14:44:40Z",
  "updated": "2026-02-12T14:44:40Z",
  "summary": "Reasoning can significantly enhance the performance of Large Language Models. While recent studies have exploited behavior-related prompts adjustment to enhance reasoning, these designs remain largely intuitive and lack a systematic analysis of the underlying behavioral patterns. Motivated by this, we investigate how models' reasoning behaviors shape reasoning from the perspective of behavioral patterns. We observe that models exhibit adaptive distributions of reasoning behaviors when responding to specific types of questions, and that structurally injecting these patterns can substantially influence the quality of the models' reasoning processes and outcomes. Building on these findings, we propose two optimization methods that require no parameter updates: InjectCorrect and InjectRLOpt. InjectCorrect guides the model by imitating behavioral patterns derived from its own past correct answers. InjectRLOpt learns a value function from historical behavior-pattern data and, via our proposed Reliability-Aware Softmax Policy, generates behavioral injectant during inference to steer the reasoning process. Our experiments demonstrate that both methods can improve model performance across various reasoning tasks without requiring any modifications to model parameters, achieving gains of up to 5.34% and 8.67%, respectively.",
  "id": "http://arxiv.org/abs/2602.12013v1",
  "authors": [
    "Xiuping Wu",
    "Zhao Yu",
    "Yuxin Cheng",
    "Ngai Wong",
    "Liangjun Ke",
    "Tapas Mishra",
    "Konstantinos V. Katsikopoulos"
  ],
  "categories": [
    "cs.AI"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.12013v1"
}