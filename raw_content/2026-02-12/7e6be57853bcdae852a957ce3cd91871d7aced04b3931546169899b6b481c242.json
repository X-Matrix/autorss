{
  "title": "Bandit Learning in Matching Markets with Interviews",
  "link": "https://arxiv.org/abs/2602.12224v1",
  "published": "2026-02-12T18:03:37Z",
  "updated": "2026-02-12T18:03:37Z",
  "summary": "Two-sided matching markets rely on preferences from both sides, yet it is often impractical to evaluate preferences. Participants, therefore, conduct a limited number of interviews, which provide early, noisy impressions and shape final decisions. We study bandit learning in matching markets with interviews, modeling interviews as \\textit{low-cost hints} that reveal partial preference information to both sides. Our framework departs from existing work by allowing firm-side uncertainty: firms, like agents, may be unsure of their own preferences and can make early hiring mistakes by hiring less preferred agents. To handle this, we extend the firm's action space to allow \\emph{strategic deferral} (choosing not to hire in a round), enabling recovery from suboptimal hires and supporting decentralized learning without coordination. We design novel algorithms for (i) a centralized setting with an omniscient interview allocator and (ii) decentralized settings with two types of firm-side feedback. Across all settings, our algorithms achieve time-independent regret, a substantial improvement over the $O(\\log T)$ regret bounds known for learning stable matchings without interviews. Also, under mild structured markets, decentralized performance matches the centralized counterpart up to polynomial factors in the number of agents and firms.",
  "id": "http://arxiv.org/abs/2602.12224v1",
  "authors": [
    "Amirmahdi Mirfakhar",
    "Xuchuang Wang",
    "Mengfan Xu",
    "Hedyeh Beyhaghi",
    "Mohammad Hajiesmaili"
  ],
  "categories": [
    "cs.GT",
    "cs.AI",
    "econ.TH"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.12224v1"
}