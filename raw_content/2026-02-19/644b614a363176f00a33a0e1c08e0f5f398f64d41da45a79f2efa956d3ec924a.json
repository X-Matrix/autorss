{
  "title": "ODESteer: A Unified ODE-Based Steering Framework for LLM Alignment",
  "link": "https://arxiv.org/abs/2602.17560v1",
  "published": "2026-02-19T17:13:44Z",
  "updated": "2026-02-19T17:13:44Z",
  "summary": "Activation steering, or representation engineering, offers a lightweight approach to align large language models (LLMs) by manipulating their internal activations at inference time. However, current methods suffer from two key limitations: \\textit{(i)} the lack of a unified theoretical framework for guiding the design of steering directions, and \\textit{(ii)} an over-reliance on \\textit{one-step steering} that fail to capture complex patterns of activation distributions. In this work, we propose a unified ordinary differential equations (ODEs)-based \\textit{theoretical} framework for activation steering in LLM alignment. We show that conventional activation addition can be interpreted as a first-order approximation to the solution of an ODE. Based on this ODE perspective, identifying a steering direction becomes equivalent to designing a \\textit{barrier function} from control theory. Derived from this framework, we introduce ODESteer, a kind of ODE-based steering guided by barrier functions, which shows \\textit{empirical} advancement in LLM alignment. ODESteer identifies steering directions by defining the barrier function as the log-density ratio between positive and negative activations, and employs it to construct an ODE for \\textit{multi-step and adaptive} steering. Compared to state-of-the-art activation steering methods, ODESteer achieves consistent empirical improvements on diverse LLM alignment benchmarks, a notable $5.7\\%$ improvement over TruthfulQA, $2.5\\%$ over UltraFeedback, and $2.4\\%$ over RealToxicityPrompts. Our work establishes a principled new view of activation steering in LLM alignment by unifying its theoretical foundations via ODEs, and validating it empirically through the proposed ODESteer method.",
  "id": "http://arxiv.org/abs/2602.17560v1",
  "authors": [
    "Hongjue Zhao",
    "Haosen Sun",
    "Jiangtao Kong",
    "Xiaochang Li",
    "Qineng Wang",
    "Liwei Jiang",
    "Qi Zhu",
    "Tarek Abdelzaher",
    "Yejin Choi",
    "Manling Li",
    "Huajie Shao"
  ],
  "categories": [
    "cs.AI"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.17560v1"
}