{
  "title": "Towards Cross-lingual Values Assessment: A Consensus-Pluralism Perspective",
  "link": "https://arxiv.org/abs/2602.17283v1",
  "published": "2026-02-19T11:41:34Z",
  "updated": "2026-02-19T11:41:34Z",
  "summary": "While large language models (LLMs) have become pivotal to content safety, current evaluation paradigms primarily focus on detecting explicit harms (e.g., violence or hate speech), neglecting the subtler value dimensions conveyed in digital content. To bridge this gap, we introduce X-Value, a novel Cross-lingual Values Assessment Benchmark designed to evaluate LLMs' ability to assess deep-level values of content from a global perspective. X-Value consists of more than 5,000 QA pairs across 18 languages, systematically organized into 7 core domains grounded in Schwartz's Theory of Basic Human Values and categorized into easy and hard levels for discriminative evaluation. We further propose a unique two-stage annotation framework that first identifies whether an issue falls under global consensus (e.g., human rights) or pluralism (e.g., religion), and subsequently conducts a multi-party evaluation of the latent values embedded within the content. Systematic evaluations on X-Value reveal that current SOTA LLMs exhibit deficiencies in cross-lingual values assessment ($Acc < 77\\%$), with significant performance disparities across different languages ($Î”Acc > 20\\%$). This work highlights the urgent need to improve the nuanced, values-aware content assessment capability of LLMs. Our X-Value is available at: https://huggingface.co/datasets/Whitolf/X-Value.",
  "id": "http://arxiv.org/abs/2602.17283v1",
  "authors": [
    "Yukun Chen",
    "Xinyu Zhang",
    "Jialong Tang",
    "Yu Wan",
    "Baosong Yang",
    "Yiming Li",
    "Zhan Qin",
    "Kui Ren"
  ],
  "categories": [
    "cs.CL",
    "cs.AI"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.17283v1"
}