{
  "title": "MedClarify: An information-seeking AI agent for medical diagnosis with case-specific follow-up questions",
  "link": "https://arxiv.org/abs/2602.17308v1",
  "published": "2026-02-19T12:19:12Z",
  "updated": "2026-02-19T12:19:12Z",
  "summary": "Large language models (LLMs) are increasingly used for diagnostic tasks in medicine. In clinical practice, the correct diagnosis can rarely be immediately inferred from the initial patient presentation alone. Rather, reaching a diagnosis often involves systematic history taking, during which clinicians reason over multiple potential conditions through iterative questioning to resolve uncertainty. This process requires considering differential diagnoses and actively excluding emergencies that demand immediate intervention. Yet, the ability of medical LLMs to generate informative follow-up questions and thus reason over differential diagnoses remains underexplored. Here, we introduce MedClarify, an AI agent for information-seeking that can generate follow-up questions for iterative reasoning to support diagnostic decision-making. Specifically, MedClarify computes a list of candidate diagnoses analogous to a differential diagnosis, and then proactively generates follow-up questions aimed at reducing diagnostic uncertainty. By selecting the question with the highest expected information gain, MedClarify enables targeted, uncertainty-aware reasoning to improve diagnostic performance. In our experiments, we first demonstrate the limitations of current LLMs in medical reasoning, which often yield multiple, similarly likely diagnoses, especially when patient cases are incomplete or relevant information for diagnosis is missing. We then show that our information-theoretic reasoning approach can generate effective follow-up questioning and thereby reduces diagnostic errors by ~27 percentage points (p.p.) compared to a standard single-shot LLM baseline. Altogether, MedClarify offers a path to improve medical LLMs through agentic information-seeking and to thus promote effective dialogues with medical LLMs that reflect the iterative and uncertain nature of real-world clinical reasoning.",
  "id": "http://arxiv.org/abs/2602.17308v1",
  "authors": [
    "Hui Min Wong",
    "Philip Heesen",
    "Pascal Janetzky",
    "Martin Bendszus",
    "Stefan Feuerriegel"
  ],
  "categories": [
    "cs.AI",
    "cs.LG"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.17308v1"
}