{
  "title": "Improving LLM-based Recommendation with Self-Hard Negatives from Intermediate Layers",
  "link": "https://arxiv.org/abs/2602.17410v1",
  "published": "2026-02-19T14:37:43Z",
  "updated": "2026-02-19T14:37:43Z",
  "summary": "Large language models (LLMs) have shown great promise in recommender systems, where supervised fine-tuning (SFT) is commonly used for adaptation. Subsequent studies further introduce preference learning to incorporate negative samples into the training process. However, existing methods rely on sequence-level, offline-generated negatives, making them less discriminative and informative when adapting LLMs to recommendation tasks with large negative item spaces. To address these challenges, we propose ILRec, a novel preference fine-tuning framework for LLM-based recommendation, leveraging self-hard negative signals extracted from intermediate layers to improve preference learning. Specifically, we identify self-hard negative tokens from intermediate layers as fine-grained negative supervision that dynamically reflects the model's preference learning process. To effectively integrate these signals into training, we design a two-stage framework comprising cross-layer preference optimization and cross-layer preference distillation, enabling the model to jointly discriminate informative negatives and enhance the quality of negative signals from intermediate layers. In addition, we introduce a lightweight collaborative filtering model to assign token-level rewards for negative signals, mitigating the risk of over-penalizing false negatives. Extensive experiments on three datasets demonstrate ILRec's effectiveness in enhancing the performance of LLM-based recommender systems.",
  "id": "http://arxiv.org/abs/2602.17410v1",
  "authors": [
    "Bingqian Li",
    "Bowen Zheng",
    "Xiaolei Wang",
    "Long Zhang",
    "Jinpeng Wang",
    "Sheng Chen",
    "Wayne Xin Zhao",
    "Ji-rong Wen"
  ],
  "categories": [
    "cs.IR",
    "cs.AI"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.17410v1"
}