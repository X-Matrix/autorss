{
  "title": "Be Wary of Your Time Series Preprocessing",
  "link": "https://arxiv.org/abs/2602.17568v1",
  "published": "2026-02-19T17:23:56Z",
  "updated": "2026-02-19T17:23:56Z",
  "summary": "Normalization and scaling are fundamental preprocessing steps in time series modeling, yet their role in Transformer-based models remains underexplored from a theoretical perspective. In this work, we present the first formal analysis of how different normalization strategies, specifically instance-based and global scaling, impact the expressivity of Transformer-based architectures for time series representation learning. We propose a novel expressivity framework tailored to time series, which quantifies a model's ability to distinguish between similar and dissimilar inputs in the representation space. Using this framework, we derive theoretical bounds for two widely used normalization methods: Standard and Min-Max scaling. Our analysis reveals that the choice of normalization strategy can significantly influence the model's representational capacity, depending on the task and data characteristics. We complement our theory with empirical validation on classification and forecasting benchmarks using multiple Transformer-based models. Our results show that no single normalization method consistently outperforms others, and in some cases, omitting normalization entirely leads to superior performance. These findings highlight the critical role of preprocessing in time series learning and motivate the need for more principled normalization strategies tailored to specific tasks and datasets.",
  "id": "http://arxiv.org/abs/2602.17568v1",
  "authors": [
    "Sofiane Ennadir",
    "Tianze Wang",
    "Oleg Smirnov",
    "Sahar Asadi",
    "Lele Cao"
  ],
  "categories": [
    "cs.LG",
    "cs.AI"
  ],
  "pdf_link": "https://arxiv.org/pdf/2602.17568v1"
}